{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multimodal Movie Recommendation System\n",
        "\n",
        "A comprehensive recommendation system based on MovieLens 100k + TMDB + ViT Image Features + BERT Text Features\n",
        "\n",
        "## Key Features\n",
        "- **Smart Quantity Control**: Set target number of movies with automatic progress management\n",
        "- **Image Feature Extraction**: ViT model for extracting visual features from posters and stills  \n",
        "- **Text Feature Extraction**: BERT model for processing movie overviews and taglines\n",
        "- **Cast & Crew Statistics**: Extract high-frequency actors and directors as features\n",
        "- **Multi-dimensional Feature Engineering**: Fusion of numerical, categorical, text, and image features\n",
        "- **Performance Comparison**: Comprehensive evaluation against traditional recommendation systems\n",
        "\n",
        "## System Architecture\n",
        "1. **Data Preparation**: MovieLens + TMDB + User Filtering\n",
        "2. **Image Processing**: Download → Selection → ViT Feature Extraction\n",
        "3. **Text Processing**: BERT Feature Extraction\n",
        "4. **Feature Engineering**: Multimodal Feature Fusion\n",
        "5. **Recommendation System**: Multi-algorithm Performance Comparison\n",
        "\n",
        "## Innovation Points\n",
        "- Multimodal feature fusion (text + image + traditional features)\n",
        "- Intelligent image selection (5 most diverse images from 10)\n",
        "- Comprehensive performance evaluation (reproducing best HybridRec configuration)\n",
        "\n",
        "## Technical Stack\n",
        "- **Computer Vision**: ViT (Vision Transformer) for image understanding\n",
        "- **Natural Language Processing**: BERT for semantic text analysis\n",
        "- **Recommendation Algorithms**: Collaborative Filtering, Content-based, Hybrid approaches\n",
        "- **Evaluation Metrics**: RMSE, MAE with statistical significance testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (2.32.4)\n",
            "Requirement already satisfied: pandas in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: pillow in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (4.67.1)\n",
            "Requirement already satisfied: transformers in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (4.54.1)\n",
            "Requirement already satisfied: torch in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (2.7.1)\n",
            "Requirement already satisfied: torchvision in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (0.22.1)\n",
            "Requirement already satisfied: scikit-learn in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (1.7.1)\n",
            "Requirement already satisfied: opencv-python in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (4.12.0.88)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: colorama in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Requirement already satisfied: filelock in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: packaging>=20.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from transformers) (2025.7.34)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: scipy>=1.8.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: scikit-image in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-image) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.11.4 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-image) (1.16.1)\n",
            "Requirement already satisfied: networkx>=3.0 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-image) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in z:\\document\\myproject\\3033-061\\.conda\\lib\\site-packages (from scikit-image) (0.4)\n",
            "Enhanced Multimodal Recommendation System\n",
            "============================================================\n",
            "Target movie count: 52\n",
            "Images per movie: 10 -> select 5\n",
            "Image directories: multimodal_images -> selected_images\n",
            "Data directory: multimodal_data\n",
            "API request interval: 0.3 seconds\n",
            "\n",
            "Environment setup completed\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install requests pandas pillow tqdm transformers torch torchvision scikit-learn opencv-python\n",
        "!pip install --upgrade scikit-image\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep learning libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "from transformers import BertTokenizer, BertModel, ViTImageProcessor, ViTModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "print(\"Enhanced Multimodal Recommendation System\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ===================== Core Configuration Parameters =====================\n",
        "# Target movie count - user configurable\n",
        "TARGET_MOVIE_COUNT = 52  # Set the desired number of movies to process\n",
        "\n",
        "# API Configuration\n",
        "TMDB_API_KEY = \"6ba3eb883961b80c06d196906b976afe\"\n",
        "TMDB_BASE_URL = \"https://api.themoviedb.org/3\"\n",
        "TMDB_IMAGE_BASE_URL = \"https://image.tmdb.org/t/p/original\"\n",
        "\n",
        "# File path configuration\n",
        "IMAGE_DIR = \"multimodal_images\"          # Original image directory\n",
        "SELECTED_IMAGE_DIR = \"selected_images\"    # Selected image directory\n",
        "DATA_DIR = \"multimodal_data\"             # Data storage directory\n",
        "PROGRESS_FILE = \"multimodal_progress.json\" # Progress tracking file\n",
        "\n",
        "# Processing parameters\n",
        "IMAGES_PER_MOVIE = 10    # Number of images to download per movie\n",
        "SELECTED_IMAGES = 5      # Number of images to select after filtering\n",
        "DELAY_BETWEEN_REQUESTS = 0.3  # API request interval (seconds)\n",
        "\n",
        "# Create directories\n",
        "for directory in [IMAGE_DIR, SELECTED_IMAGE_DIR, DATA_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(f\"Target movie count: {TARGET_MOVIE_COUNT}\")\n",
        "print(f\"Images per movie: {IMAGES_PER_MOVIE} -> select {SELECTED_IMAGES}\")\n",
        "print(f\"Image directories: {IMAGE_DIR} -> {SELECTED_IMAGE_DIR}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"API request interval: {DELAY_BETWEEN_REQUESTS} seconds\")\n",
        "print(\"\\nEnvironment setup completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Loading and Progress Check\n",
            "==================================================\n",
            "MovieLens movie data loaded: 1682 movies\n",
            "IMDB ID mapping loaded: 52 entries\n",
            "User rating data loaded: 100,000 ratings\n",
            "Number of users: 943\n",
            "Number of movies: 1,682\n",
            "User information loaded: 943 users\n",
            "\n",
            "Target movie processing: 52 / 52 valid movies\n",
            "Data coverage: 100.0%\n",
            "\n",
            "Target movie list:\n",
            "    1.   1. Toy Story (1995) -> tt0114709\n",
            "    2.   2. GoldenEye (1995) -> tt0113189\n",
            "    3.   3. Four Rooms (1995) -> tt0113101\n",
            "    4.   4. Get Shorty (1995) -> tt0113161\n",
            "    5.   5. Copycat (1995) -> tt0112722\n",
            "    6.   6. Shanghai Triad (Yao a yao yao dao waipo qiao) (1995) -> tt0115012\n",
            "    7.   7. Twelve Monkeys (1995) -> tt0114746\n",
            "    8.   8. Babe (1995) -> tt0112431\n",
            "    9.   9. Dead Man Walking (1995) -> tt0112818\n",
            "   10.  10. Richard III (1995) -> tt0114279\n",
            "   ... and 42 more movies\n",
            "\n",
            "Target movie list saved: multimodal_data\\target_movies.csv\n"
          ]
        }
      ],
      "source": [
        "# Data loading and intelligent progress management\n",
        "print(\"Data Loading and Progress Check\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load MovieLens movie data\n",
        "try:\n",
        "    movies_df = pd.read_csv('movielens_movies.csv')\n",
        "    print(f\"MovieLens movie data loaded: {len(movies_df)} movies\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: movielens_movies.csv not found\")\n",
        "    print(\"Please run generate_imdb_mapping.py to generate movie information\")\n",
        "\n",
        "# Load IMDB ID mapping\n",
        "try:\n",
        "    with open('imdb/progress_mapping.json', 'r', encoding='utf-8') as f:\n",
        "        imdb_mapping = json.load(f)\n",
        "    imdb_mapping = {int(k): v for k, v in imdb_mapping.items()}\n",
        "    print(f\"IMDB ID mapping loaded: {len(imdb_mapping)} entries\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: IMDB ID mapping file not found\")\n",
        "\n",
        "# Load user rating data\n",
        "try:\n",
        "    ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', \n",
        "                           names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "    print(f\"User rating data loaded: {len(ratings_df):,} ratings\")\n",
        "    print(f\"Number of users: {ratings_df['user_id'].nunique():,}\")\n",
        "    print(f\"Number of movies: {ratings_df['movie_id'].nunique():,}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: ml-100k/u.data file not found\")\n",
        "\n",
        "# Load user information\n",
        "try:\n",
        "    users_df = pd.read_csv('ml-100k/u.user', sep='|', \n",
        "                         names=['user_id', 'age', 'gender', 'occupation', 'zip_code'])\n",
        "    print(f\"User information loaded: {len(users_df)} users\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: ml-100k/u.user file not found\")\n",
        "\n",
        "# Intelligent target movie selection\n",
        "if 'movies_df' in locals() and 'imdb_mapping' in locals():\n",
        "    valid_movies = movies_df[movies_df['movie_id'].isin(imdb_mapping.keys())].copy()\n",
        "    valid_movies['imdb_id'] = valid_movies['movie_id'].map(imdb_mapping)\n",
        "    \n",
        "    # Select target movies based on TARGET_MOVIE_COUNT\n",
        "    target_movies = valid_movies.head(TARGET_MOVIE_COUNT).copy()\n",
        "    \n",
        "    print(f\"\\nTarget movie processing: {len(target_movies)} / {len(valid_movies)} valid movies\")\n",
        "    print(f\"Data coverage: {len(target_movies)/len(valid_movies)*100:.1f}%\")\n",
        "    \n",
        "    # Display target movie list\n",
        "    print(f\"\\nTarget movie list:\")\n",
        "    for i, (_, movie) in enumerate(target_movies.head(10).iterrows(), 1):\n",
        "        print(f\"   {i:2d}. {movie['movie_id']:3d}. {movie['title']} ({movie['year']}) -> tt{movie['imdb_id']}\")\n",
        "    \n",
        "    if len(target_movies) > 10:\n",
        "        print(f\"   ... and {len(target_movies) - 10} more movies\")\n",
        "        \n",
        "    # Save target movie list\n",
        "    target_file = os.path.join(DATA_DIR, 'target_movies.csv')\n",
        "    target_movies.to_csv(target_file, index=False)\n",
        "    print(f\"\\nTarget movie list saved: {target_file}\")\n",
        "else:\n",
        "    print(\"ERROR: Data loading failed, cannot continue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Data Filtering and Cleaning\n",
            "==================================================\n",
            "Original rating data: 100,000 entries\n",
            "Target movie ratings: 7,157 entries\n",
            "Data filtering rate: 7.2%\n",
            "\n",
            "User activity analysis:\n",
            "   Total users: 791\n",
            "   Average ratings per user: 9.0\n",
            "   Median ratings per user: 7.0\n",
            "   Most active user: 52 ratings\n",
            "   Least active user: 1 ratings\n",
            "\n",
            "Data cleaning results:\n",
            "   Minimum ratings requirement: 3 entries\n",
            "   Users retained: 682 / 791 (86.2%)\n",
            "   Ratings retained: 6,994 / 7,157 (97.7%)\n",
            "\n",
            "Final cleaned dataset:\n",
            "   Rating records: 6,994 entries\n",
            "   Number of users: 682\n",
            "   Number of movies: 52\n",
            "   Average ratings per user: 10.3\n",
            "   Average ratings per movie: 134.5\n",
            "\n",
            "User demographic distribution:\n",
            "   Age range: 7-73 years\n",
            "   Average age: 32.3 years\n",
            "   Gender distribution: {'M': np.int64(5331), 'F': np.int64(1663)}\n",
            "   Top 5 occupations: {'student': np.int64(1635), 'other': np.int64(711), 'educator': np.int64(645), 'engineer': np.int64(609), 'programmer': np.int64(594)}\n",
            "\n",
            "Rating distribution:\n",
            "   1 stars: 267 entries (3.8%)\n",
            "   2 stars: 632 entries (9.0%)\n",
            "   3 stars: 1,708 entries (24.4%)\n",
            "   4 stars: 2,542 entries (36.3%)\n",
            "   5 stars: 1,845 entries (26.4%)\n",
            "   Average rating: 3.72\n",
            "\n",
            "Cleaned data saved: multimodal_data\\cleaned_ratings_data.csv\n",
            "Updated target movie count: 52 movies (with actual rating data)\n",
            "\n",
            "Rating matrix dimensions:\n",
            "   User-Movie matrix: 682 x 52 = 35,464 possible ratings\n",
            "   Actual ratings: 6,994\n",
            "   Sparsity: 80.28% (percentage of missing values)\n",
            "   Density: 19.72% (percentage of observed values)\n"
          ]
        }
      ],
      "source": [
        "# User data filtering and cleaning\n",
        "print(\"User Data Filtering and Cleaning\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'target_movies' in locals() and 'ratings_df' in locals():\n",
        "    # Filter rating data for target movies\n",
        "    target_movie_ids = set(target_movies['movie_id'].values)\n",
        "    filtered_ratings = ratings_df[ratings_df['movie_id'].isin(target_movie_ids)].copy()\n",
        "    \n",
        "    print(f\"Original rating data: {len(ratings_df):,} entries\")\n",
        "    print(f\"Target movie ratings: {len(filtered_ratings):,} entries\")\n",
        "    print(f\"Data filtering rate: {len(filtered_ratings)/len(ratings_df)*100:.1f}%\")\n",
        "    \n",
        "    # Analyze user activity\n",
        "    user_activity = filtered_ratings['user_id'].value_counts()\n",
        "    print(f\"\\nUser activity analysis:\")\n",
        "    print(f\"   Total users: {len(user_activity):,}\")\n",
        "    print(f\"   Average ratings per user: {user_activity.mean():.1f}\")\n",
        "    print(f\"   Median ratings per user: {user_activity.median():.1f}\")\n",
        "    print(f\"   Most active user: {user_activity.max()} ratings\")\n",
        "    print(f\"   Least active user: {user_activity.min()} ratings\")\n",
        "    \n",
        "    # Clean low-activity users (less than 3 ratings)\n",
        "    MIN_RATINGS_PER_USER = 3\n",
        "    active_users = user_activity[user_activity >= MIN_RATINGS_PER_USER].index\n",
        "    cleaned_ratings = filtered_ratings[filtered_ratings['user_id'].isin(active_users)].copy()\n",
        "    \n",
        "    print(f\"\\nData cleaning results:\")\n",
        "    print(f\"   Minimum ratings requirement: {MIN_RATINGS_PER_USER} entries\")\n",
        "    print(f\"   Users retained: {len(active_users):,} / {len(user_activity):,} ({len(active_users)/len(user_activity)*100:.1f}%)\")\n",
        "    print(f\"   Ratings retained: {len(cleaned_ratings):,} / {len(filtered_ratings):,} ({len(cleaned_ratings)/len(filtered_ratings)*100:.1f}%)\")\n",
        "    \n",
        "    # Merge user information and handle missing values\n",
        "    if 'users_df' in locals():\n",
        "        cleaned_ratings_with_users = cleaned_ratings.merge(users_df, on='user_id', how='left')\n",
        "        \n",
        "        # Check and clean missing user information\n",
        "        missing_user_info = cleaned_ratings_with_users['age'].isna().sum()\n",
        "        if missing_user_info > 0:\n",
        "            print(f\"WARNING: Missing user information: {missing_user_info:,} entries ({missing_user_info/len(cleaned_ratings_with_users)*100:.1f}%)\")\n",
        "            # Remove records with missing user information\n",
        "            cleaned_ratings_with_users.dropna(subset=['age', 'gender', 'occupation'], inplace=True)\n",
        "            print(f\"Ratings after cleaning: {len(cleaned_ratings_with_users):,} entries\")\n",
        "        \n",
        "        print(f\"\\nFinal cleaned dataset:\")\n",
        "        print(f\"   Rating records: {len(cleaned_ratings_with_users):,} entries\")\n",
        "        print(f\"   Number of users: {cleaned_ratings_with_users['user_id'].nunique():,}\")\n",
        "        print(f\"   Number of movies: {cleaned_ratings_with_users['movie_id'].nunique():,}\")\n",
        "        print(f\"   Average ratings per user: {len(cleaned_ratings_with_users)/cleaned_ratings_with_users['user_id'].nunique():.1f}\")\n",
        "        print(f\"   Average ratings per movie: {len(cleaned_ratings_with_users)/cleaned_ratings_with_users['movie_id'].nunique():.1f}\")\n",
        "        \n",
        "        # User feature analysis\n",
        "        print(f\"\\nUser demographic distribution:\")\n",
        "        print(f\"   Age range: {cleaned_ratings_with_users['age'].min()}-{cleaned_ratings_with_users['age'].max()} years\")\n",
        "        print(f\"   Average age: {cleaned_ratings_with_users['age'].mean():.1f} years\")\n",
        "        print(f\"   Gender distribution: {dict(cleaned_ratings_with_users['gender'].value_counts())}\")\n",
        "        print(f\"   Top 5 occupations: {dict(cleaned_ratings_with_users['occupation'].value_counts().head())}\")\n",
        "        \n",
        "        # Rating distribution analysis\n",
        "        rating_dist = cleaned_ratings_with_users['rating'].value_counts().sort_index()\n",
        "        print(f\"\\nRating distribution:\")\n",
        "        for rating, count in rating_dist.items():\n",
        "            print(f\"   {rating} stars: {count:,} entries ({count/len(cleaned_ratings_with_users)*100:.1f}%)\")\n",
        "        print(f\"   Average rating: {cleaned_ratings_with_users['rating'].mean():.2f}\")\n",
        "        \n",
        "        # Save cleaned data\n",
        "        cleaned_data_file = os.path.join(DATA_DIR, 'cleaned_ratings_data.csv')\n",
        "        cleaned_ratings_with_users.to_csv(cleaned_data_file, index=False)\n",
        "        print(f\"\\nCleaned data saved: {cleaned_data_file}\")\n",
        "        \n",
        "        # Update target_movies to include only movies with ratings\n",
        "        rated_movie_ids = set(cleaned_ratings_with_users['movie_id'].unique())\n",
        "        target_movies = target_movies[target_movies['movie_id'].isin(rated_movie_ids)].copy()\n",
        "        print(f\"Updated target movie count: {len(target_movies)} movies (with actual rating data)\")\n",
        "        \n",
        "        # Print rating matrix dimension information\n",
        "        n_users = cleaned_ratings_with_users['user_id'].nunique()\n",
        "        n_movies = cleaned_ratings_with_users['movie_id'].nunique()\n",
        "        sparsity = 1 - len(cleaned_ratings_with_users) / (n_users * n_movies)\n",
        "        print(f\"\\nRating matrix dimensions:\")\n",
        "        print(f\"   User-Movie matrix: {n_users} x {n_movies} = {n_users * n_movies:,} possible ratings\")\n",
        "        print(f\"   Actual ratings: {len(cleaned_ratings_with_users):,}\")\n",
        "        print(f\"   Sparsity: {sparsity*100:.2f}% (percentage of missing values)\")\n",
        "        print(f\"   Density: {(1-sparsity)*100:.2f}% (percentage of observed values)\")\n",
        "    \n",
        "else:\n",
        "    print(\"ERROR: Required data missing, cannot perform user data filtering\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TMDB Data Acquisition and Image Download\n",
            "==================================================\n",
            "Progress loaded: 42 processed, 0 failed\n",
            "Remaining to process: 10 movies\n",
            "\n",
            "TMDB processor ready\n"
          ]
        }
      ],
      "source": [
        "# TMDB data acquisition and image download processor\n",
        "print(\"TMDB Data Acquisition and Image Download\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "class EnhancedTMDBProcessor:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.session = requests.Session()\n",
        "        self.processed_movies = set()\n",
        "        self.failed_movies = set()\n",
        "        self.movie_features = {}\n",
        "        self.load_progress()\n",
        "    \n",
        "    def load_progress(self):\n",
        "        \"\"\"Load processing progress\"\"\"\n",
        "        if os.path.exists(PROGRESS_FILE):\n",
        "            try:\n",
        "                with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:\n",
        "                    progress = json.load(f)\n",
        "                self.processed_movies = set(progress.get(\"processed\", []))\n",
        "                self.failed_movies = set(progress.get(\"failed\", []))\n",
        "                self.movie_features = progress.get(\"movie_features\", {})\n",
        "                print(f\"Progress loaded: {len(self.processed_movies)} processed, {len(self.failed_movies)} failed\")\n",
        "            except Exception as e:\n",
        "                print(f\"ERROR: Failed to load progress: {str(e)}\")\n",
        "    \n",
        "    def save_progress(self):\n",
        "        \"\"\"Save processing progress\"\"\"\n",
        "        try:\n",
        "            progress = {\n",
        "                \"processed\": list(self.processed_movies),\n",
        "                \"failed\": list(self.failed_movies),\n",
        "                \"movie_features\": self.movie_features,\n",
        "                \"last_updated\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                \"target_count\": TARGET_MOVIE_COUNT,\n",
        "                \"total_processed\": len(self.processed_movies),\n",
        "                \"total_failed\": len(self.failed_movies)\n",
        "            }\n",
        "            with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:\n",
        "                json.dump(progress, f, ensure_ascii=False, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Failed to save progress: {str(e)}\")\n",
        "    \n",
        "    def find_movie_by_imdb_id(self, imdb_id):\n",
        "        \"\"\"Find TMDB movie by IMDB ID\"\"\"\n",
        "        if not imdb_id.startswith('tt'):\n",
        "            imdb_id = f\"tt{imdb_id}\"\n",
        "        \n",
        "        url = f\"{TMDB_BASE_URL}/find/{imdb_id}\"\n",
        "        params = {\"api_key\": self.api_key, \"external_source\": \"imdb_id\"}\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, params=params, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                if data.get(\"movie_results\"):\n",
        "                    return data[\"movie_results\"][0]\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"     ERROR: Search failed: {str(e)}\")\n",
        "            return None\n",
        "    \n",
        "    def get_movie_details(self, tmdb_id):\n",
        "        \"\"\"Get detailed movie information\"\"\"\n",
        "        url = f\"{TMDB_BASE_URL}/movie/{tmdb_id}\"\n",
        "        params = {\n",
        "            \"api_key\": self.api_key,\n",
        "            \"append_to_response\": \"credits,keywords,videos,images\"\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, params=params, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"     ERROR: Failed to get details: {str(e)}\")\n",
        "            return None\n",
        "    \n",
        "    def clean_filename(self, filename):\n",
        "        \"\"\"Clean filename for safe storage\"\"\"\n",
        "        invalid_chars = '<>:\"/\\\\|?*'\n",
        "        for char in invalid_chars:\n",
        "            filename = filename.replace(char, '_')\n",
        "        return filename[:100]\n",
        "    \n",
        "    def download_image(self, url, save_path):\n",
        "        \"\"\"Download and process image\"\"\"\n",
        "        if os.path.exists(save_path):\n",
        "            return True\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, timeout=15)\n",
        "            if response.status_code == 200:\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "                if img.size[0] < 50 or img.size[1] < 50:\n",
        "                    return False\n",
        "                \n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "                \n",
        "                # Resize to 512x512 for ViT processing\n",
        "                img = img.resize((512, 512), Image.Resampling.LANCZOS)\n",
        "                img.save(save_path, \"JPEG\", quality=90, optimize=True)\n",
        "                return True\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"       ERROR: Download failed: {str(e)}\")\n",
        "            return False\n",
        "    \n",
        "    def download_movie_images(self, movie_id, title, tmdb_movie):\n",
        "        \"\"\"Download movie images - up to 10 images\"\"\"\n",
        "        movie_folder = os.path.join(IMAGE_DIR, f\"{movie_id:04d}_{self.clean_filename(title)}\")\n",
        "        os.makedirs(movie_folder, exist_ok=True)\n",
        "        \n",
        "        downloaded = []\n",
        "        \n",
        "        # 1. Download poster\n",
        "        if tmdb_movie.get(\"poster_path\"):\n",
        "            poster_url = f\"{TMDB_IMAGE_BASE_URL}{tmdb_movie['poster_path']}\"\n",
        "            poster_path = os.path.join(movie_folder, \"poster.jpg\")\n",
        "            if self.download_image(poster_url, poster_path):\n",
        "                downloaded.append((\"poster\", poster_path))\n",
        "        \n",
        "        # 2. Download backdrop\n",
        "        if tmdb_movie.get(\"backdrop_path\"):\n",
        "            backdrop_url = f\"{TMDB_IMAGE_BASE_URL}{tmdb_movie['backdrop_path']}\"\n",
        "            backdrop_path = os.path.join(movie_folder, \"backdrop.jpg\")\n",
        "            if self.download_image(backdrop_url, backdrop_path):\n",
        "                downloaded.append((\"backdrop\", backdrop_path))\n",
        "        \n",
        "        # 3. Download stills (up to 8)\n",
        "        if \"images\" in tmdb_movie and \"backdrops\" in tmdb_movie[\"images\"]:\n",
        "            backdrops = tmdb_movie[\"images\"][\"backdrops\"][:8]\n",
        "            for i, backdrop_info in enumerate(backdrops):\n",
        "                backdrop_url = f\"{TMDB_IMAGE_BASE_URL}{backdrop_info['file_path']}\"\n",
        "                still_path = os.path.join(movie_folder, f\"still_{i+1}.jpg\")\n",
        "                if self.download_image(backdrop_url, still_path):\n",
        "                    downloaded.append((f\"still_{i+1}\", still_path))\n",
        "                    \n",
        "                # Limit to maximum of 10 images\n",
        "                if len(downloaded) >= IMAGES_PER_MOVIE:\n",
        "                    break\n",
        "        \n",
        "        return downloaded\n",
        "    \n",
        "    def extract_movie_features(self, tmdb_movie, movielens_info):\n",
        "        \"\"\"Extract comprehensive movie features\"\"\"\n",
        "        features = {\n",
        "            # MovieLens original information\n",
        "            \"movielens_id\": movielens_info[\"movie_id\"],\n",
        "            \"movielens_title\": movielens_info[\"title\"],\n",
        "            \"movielens_year\": movielens_info[\"year\"],\n",
        "            \"movielens_imdb_id\": movielens_info[\"imdb_id\"],\n",
        "            \n",
        "            # TMDB basic information\n",
        "            \"tmdb_id\": tmdb_movie.get(\"id\"),\n",
        "            \"title\": tmdb_movie.get(\"title\", \"\"),\n",
        "            \"original_title\": tmdb_movie.get(\"original_title\", \"\"),\n",
        "            \"overview\": tmdb_movie.get(\"overview\", \"\"),\n",
        "            \"tagline\": tmdb_movie.get(\"tagline\", \"\"),\n",
        "            \"release_date\": tmdb_movie.get(\"release_date\", \"\"),\n",
        "            \"runtime\": tmdb_movie.get(\"runtime\", 0),\n",
        "            \"status\": tmdb_movie.get(\"status\", \"\"),\n",
        "            \n",
        "            # Rating information\n",
        "            \"vote_average\": tmdb_movie.get(\"vote_average\", 0),\n",
        "            \"vote_count\": tmdb_movie.get(\"vote_count\", 0),\n",
        "            \"popularity\": tmdb_movie.get(\"popularity\", 0),\n",
        "            \n",
        "            # Classification information\n",
        "            \"genres\": \"|\".join([g[\"name\"] for g in tmdb_movie.get(\"genres\", [])]),\n",
        "            \"original_language\": tmdb_movie.get(\"original_language\", \"\"),\n",
        "            \"production_countries\": \"|\".join([c[\"name\"] for c in tmdb_movie.get(\"production_countries\", [])]),\n",
        "            \"production_companies\": \"|\".join([c[\"name\"] for c in tmdb_movie.get(\"production_companies\", [])]),\n",
        "            \n",
        "            # Financial information\n",
        "            \"budget\": tmdb_movie.get(\"budget\", 0),\n",
        "            \"revenue\": tmdb_movie.get(\"revenue\", 0),\n",
        "        }\n",
        "        \n",
        "        # Cast and crew information\n",
        "        if \"credits\" in tmdb_movie:\n",
        "            credits = tmdb_movie[\"credits\"]\n",
        "            \n",
        "            # Directors\n",
        "            directors = [crew[\"name\"] for crew in credits.get(\"crew\", []) if crew.get(\"job\") == \"Director\"]\n",
        "            features[\"directors\"] = \"|\".join(directors)\n",
        "            \n",
        "            # Cast\n",
        "            cast = [actor[\"name\"] for actor in credits.get(\"cast\", [])[:10]]\n",
        "            features[\"cast\"] = \"|\".join(cast)\n",
        "        \n",
        "        # Keywords\n",
        "        if \"keywords\" in tmdb_movie and \"keywords\" in tmdb_movie[\"keywords\"]:\n",
        "            keywords = [kw[\"name\"] for kw in tmdb_movie[\"keywords\"][\"keywords\"][:15]]\n",
        "            features[\"keywords\"] = \"|\".join(keywords)\n",
        "        \n",
        "        return features\n",
        "\n",
        "# Check progress status\n",
        "processor = EnhancedTMDBProcessor(TMDB_API_KEY)\n",
        "current_processed = len(processor.processed_movies)\n",
        "\n",
        "#print(f\"Current processing progress: {current_processed}/{TARGET_MOVIE_COUNT}\")\n",
        "\n",
        "# Intelligent progress management\n",
        "if current_processed >= TARGET_MOVIE_COUNT:\n",
        "    print(f\"Target achieved ({current_processed} >= {TARGET_MOVIE_COUNT})\")\n",
        "    print(\"Skipping download phase, using existing data\")\n",
        "    SKIP_DOWNLOAD = True\n",
        "else:\n",
        "    need_to_process = TARGET_MOVIE_COUNT - current_processed\n",
        "    print(f\"Remaining to process: {need_to_process} movies\")\n",
        "    SKIP_DOWNLOAD = False\n",
        "    \n",
        "print(\"\\nTMDB processor ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting TMDB data processing and image download\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:   0%|          | 0/52 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[1/52] 1. Toy Story -> tt0114709\n",
            "   Already processed, skipping\n",
            "\n",
            "[2/52] 2. GoldenEye -> tt0113189\n",
            "   Already processed, skipping\n",
            "\n",
            "[3/52] 3. Four Rooms -> tt0113101\n",
            "   Already processed, skipping\n",
            "\n",
            "[4/52] 4. Get Shorty -> tt0113161\n",
            "   Already processed, skipping\n",
            "\n",
            "[5/52] 5. Copycat -> tt0112722\n",
            "   Already processed, skipping\n",
            "\n",
            "[6/52] 6. Shanghai Triad (Yao a yao yao dao waipo qiao) -> tt0115012\n",
            "   Already processed, skipping\n",
            "\n",
            "[7/52] 7. Twelve Monkeys -> tt0114746\n",
            "   Already processed, skipping\n",
            "\n",
            "[8/52] 8. Babe -> tt0112431\n",
            "   Already processed, skipping\n",
            "\n",
            "[9/52] 9. Dead Man Walking -> tt0112818\n",
            "   Already processed, skipping\n",
            "\n",
            "[10/52] 10. Richard III -> tt0114279\n",
            "   Already processed, skipping\n",
            "\n",
            "[11/52] 11. Seven (Se7en) -> tt0114369\n",
            "   Already processed, skipping\n",
            "\n",
            "[12/52] 12. Usual Suspects, The -> tt0114814\n",
            "   Already processed, skipping\n",
            "\n",
            "[13/52] 13. Mighty Aphrodite -> tt0113819\n",
            "   Already processed, skipping\n",
            "\n",
            "[14/52] 14. Postino, Il -> tt0110877\n",
            "   Already processed, skipping\n",
            "\n",
            "[15/52] 15. Mr. Holland's Opus -> tt0113862\n",
            "   Already processed, skipping\n",
            "\n",
            "[16/52] 16. French Twist (Gazon maudit) -> tt0113149\n",
            "   Already processed, skipping\n",
            "\n",
            "[17/52] 17. From Dusk Till Dawn -> tt0116367\n",
            "   Already processed, skipping\n",
            "\n",
            "[18/52] 18. White Balloon, The -> tt0112445\n",
            "   Already processed, skipping\n",
            "\n",
            "[19/52] 19. Antonia's Line -> tt0112379\n",
            "   Already processed, skipping\n",
            "\n",
            "[20/52] 20. Angels and Insects -> tt0112365\n",
            "   Already processed, skipping\n",
            "\n",
            "[21/52] 21. Muppet Treasure Island -> tt0117110\n",
            "   Already processed, skipping\n",
            "\n",
            "[22/52] 22. Braveheart -> tt0112573\n",
            "   Already processed, skipping\n",
            "\n",
            "[23/52] 23. Taxi Driver -> tt0075314\n",
            "   Already processed, skipping\n",
            "\n",
            "[24/52] 24. Rumble in the Bronx -> tt0113326\n",
            "   Already processed, skipping\n",
            "\n",
            "[25/52] 25. Birdcage, The -> tt0115685\n",
            "   Already processed, skipping\n",
            "\n",
            "[26/52] 26. Brothers McMullen, The -> tt0112585\n",
            "   Already processed, skipping\n",
            "\n",
            "[27/52] 27. Bad Boys -> tt0112442\n",
            "   Already processed, skipping\n",
            "\n",
            "[28/52] 28. Apollo 13 -> tt0112384\n",
            "   Already processed, skipping\n",
            "\n",
            "[29/52] 29. Batman Forever -> tt0112462\n",
            "   Already processed, skipping\n",
            "\n",
            "[30/52] 30. Belle de jour -> tt0061395\n",
            "   Already processed, skipping\n",
            "\n",
            "[31/52] 31. Crimson Tide -> tt0112740\n",
            "   Already processed, skipping\n",
            "\n",
            "[32/52] 32. Crumb -> tt0109508\n",
            "   Already processed, skipping\n",
            "\n",
            "[33/52] 33. Desperado -> tt0112851\n",
            "   Already processed, skipping\n",
            "\n",
            "[34/52] 34. Doom Generation, The -> tt0112887\n",
            "   Already processed, skipping\n",
            "\n",
            "[35/52] 35. Free Willy 2_ The Adventure Home -> tt0113114\n",
            "   Already processed, skipping\n",
            "\n",
            "[36/52] 36. Mad Love -> tt0113729\n",
            "   Already processed, skipping\n",
            "\n",
            "[37/52] 37. Nadja -> tt0110620\n",
            "   Already processed, skipping\n",
            "\n",
            "[38/52] 38. Net, The -> tt0113957\n",
            "   Already processed, skipping\n",
            "\n",
            "[39/52] 39. Strange Days -> tt0114558\n",
            "   Already processed, skipping\n",
            "\n",
            "[40/52] 40. To Wong Foo, Thanks for Everything! Julie Newmar -> tt0114682\n",
            "   Already processed, skipping\n",
            "\n",
            "[41/52] 41. Billy Madison -> tt0112508\n",
            "   Already processed, skipping\n",
            "\n",
            "[42/52] 42. Clerks -> tt0109445\n",
            "   Already processed, skipping\n",
            "\n",
            "[43/52] 43. Disclosure -> tt0109635\n",
            "   SUCCESS: 10 images, rating 6.3/10\n",
            "   Genres: Thriller|Drama|Crime\n",
            "   Directors: Barry Levinson\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:  83%|████████▎ | 43/52 [00:03<00:00, 11.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[44/52] 44. Dolores Claiborne -> tt0109642\n",
            "   SUCCESS: 10 images, rating 7.278/10\n",
            "   Genres: Crime|Drama|Mystery\n",
            "   Directors: Taylor Hackford\n",
            "\n",
            "[45/52] 45. Eat Drink Man Woman -> tt0111797\n",
            "   SUCCESS: 10 images, rating 7.621/10\n",
            "   Genres: Comedy|Drama|Romance\n",
            "   Directors: Ang Lee\n",
            "   Progress saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:  87%|████████▋ | 45/52 [00:07<00:01,  4.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[46/52] 46. Exotica -> tt0109759\n",
            "   SUCCESS: 10 images, rating 6.61/10\n",
            "   Genres: Drama\n",
            "   Directors: Atom Egoyan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:  88%|████████▊ | 46/52 [00:11<00:02,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[47/52] 47. Ed Wood -> tt0109707\n",
            "   SUCCESS: 10 images, rating 7.5/10\n",
            "   Genres: Comedy|Drama|History\n",
            "   Directors: Tim Burton\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:  90%|█████████ | 47/52 [00:12<00:02,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[48/52] 48. Hoop Dreams -> tt0110057\n",
            "   SUCCESS: 8 images, rating 7.596/10\n",
            "   Genres: Documentary\n",
            "   Directors: Steve James\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:  92%|█████████▏| 48/52 [00:15<00:02,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[49/52] 49. I.Q. -> tt0110099\n",
            "   SUCCESS: 9 images, rating 6.0/10\n",
            "   Genres: Comedy|Drama|Romance\n",
            "   Directors: Fred Schepisi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:  94%|█████████▍| 49/52 [00:19<00:02,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[50/52] 50. Star Wars -> tt0076759\n",
            "   SUCCESS: 10 images, rating 8.205/10\n",
            "   Genres: Adventure|Action|Science Fiction\n",
            "   Directors: George Lucas\n",
            "   Progress saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:  96%|█████████▌| 50/52 [00:20<00:01,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[51/52] 51. Legends of the Fall -> tt0110322\n",
            "   SUCCESS: 10 images, rating 7.393/10\n",
            "   Genres: Drama|Western|Romance|War|Action\n",
            "   Directors: Edward Zwick\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies:  98%|█████████▊| 51/52 [00:22<00:01,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[52/52] 52. Madness of King George, The -> tt0110428\n",
            "   SUCCESS: 6 images, rating 6.786/10\n",
            "   Genres: Comedy|Drama|History\n",
            "   Directors: Nicholas Hytner\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing movies: 100%|██████████| 52/52 [00:25<00:00,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Movie feature data saved:\n",
            "   JSON format: multimodal_data\\tmdb_movie_features.json\n",
            "   CSV format: multimodal_data\\tmdb_movie_features.csv\n",
            "\n",
            "TMDB processing statistics:\n",
            "   Successful: 52 movies\n",
            "   Failed: 0 movies\n",
            "   Images downloaded: 93\n",
            "   Success rate: 100.0%\n",
            "   Target achieved: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Execute TMDB data acquisition and image download\n",
        "if not SKIP_DOWNLOAD and 'target_movies' in locals():\n",
        "    print(\"Starting TMDB data processing and image download\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    all_movie_features = []\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    total_images = 0\n",
        "    \n",
        "    # Process each movie\n",
        "    for idx, (_, movie_info) in enumerate(tqdm(target_movies.iterrows(), total=len(target_movies), desc=\"Processing movies\")):\n",
        "        movie_id = movie_info[\"movie_id\"]\n",
        "        title = movie_info[\"title\"].replace(':', '_')\n",
        "        imdb_id = movie_info[\"imdb_id\"]\n",
        "        \n",
        "        print(f\"\\n[{idx+1}/{len(target_movies)}] {movie_id}. {title} -> tt{imdb_id}\")\n",
        "        \n",
        "        # Check if already processed\n",
        "        if str(movie_id) in processor.processed_movies:\n",
        "            print(f\"   Already processed, skipping\")\n",
        "            if str(movie_id) in processor.movie_features:\n",
        "                all_movie_features.append(processor.movie_features[str(movie_id)])\n",
        "            success_count += 1\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            # 1. Find TMDB movie\n",
        "            tmdb_basic = processor.find_movie_by_imdb_id(imdb_id)\n",
        "            if not tmdb_basic:\n",
        "                print(f\"   ERROR: Not found in TMDB\")\n",
        "                processor.failed_movies.add(str(movie_id))\n",
        "                error_count += 1\n",
        "                continue\n",
        "            \n",
        "            # 2. Get detailed information\n",
        "            tmdb_movie = processor.get_movie_details(tmdb_basic[\"id\"])\n",
        "            if not tmdb_movie:\n",
        "                print(f\"   ERROR: Failed to get details\")\n",
        "                processor.failed_movies.add(str(movie_id))\n",
        "                error_count += 1\n",
        "                continue\n",
        "            \n",
        "            # 3. Extract features\n",
        "            features = processor.extract_movie_features(tmdb_movie, movie_info)\n",
        "            \n",
        "            # 4. Download images\n",
        "            downloaded_images = processor.download_movie_images(movie_id, title, tmdb_movie)\n",
        "            features[\"downloaded_images_count\"] = len(downloaded_images)\n",
        "            features[\"image_paths\"] = [path for _, path in downloaded_images]\n",
        "            total_images += len(downloaded_images)\n",
        "            \n",
        "            # 5. Record success\n",
        "            all_movie_features.append(features)\n",
        "            processor.processed_movies.add(str(movie_id))\n",
        "            processor.movie_features[str(movie_id)] = features\n",
        "            success_count += 1\n",
        "            \n",
        "            print(f\"   SUCCESS: {len(downloaded_images)} images, rating {features['vote_average']}/10\")\n",
        "            print(f\"   Genres: {features['genres']}\")\n",
        "            print(f\"   Directors: {features.get('directors', 'N/A')}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ERROR: Processing failed: {str(e)}\")\n",
        "            processor.failed_movies.add(str(movie_id))\n",
        "            error_count += 1\n",
        "        \n",
        "        # Save progress periodically\n",
        "        if (idx + 1) % 5 == 0:\n",
        "            processor.save_progress()\n",
        "            print(f\"   Progress saved\")\n",
        "        \n",
        "        # API request interval\n",
        "        time.sleep(DELAY_BETWEEN_REQUESTS)\n",
        "    \n",
        "    # Final progress save\n",
        "    processor.save_progress()\n",
        "    \n",
        "    # Save movie feature data\n",
        "    if all_movie_features:\n",
        "        features_file = os.path.join(DATA_DIR, 'tmdb_movie_features.json')\n",
        "        with open(features_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(all_movie_features, f, ensure_ascii=False, indent=2)\n",
        "        \n",
        "        csv_file = os.path.join(DATA_DIR, 'tmdb_movie_features.csv')\n",
        "        pd.DataFrame(all_movie_features).to_csv(csv_file, index=False, encoding='utf-8')\n",
        "        \n",
        "        print(f\"\\nMovie feature data saved:\")\n",
        "        print(f\"   JSON format: {features_file}\")\n",
        "        print(f\"   CSV format: {csv_file}\")\n",
        "    \n",
        "    # Output statistics\n",
        "    print(f\"\\nTMDB processing statistics:\")\n",
        "    print(f\"   Successful: {success_count} movies\")\n",
        "    print(f\"   Failed: {error_count} movies\")\n",
        "    print(f\"   Images downloaded: {total_images}\")\n",
        "    print(f\"   Success rate: {success_count/(success_count+error_count)*100:.1f}%\")\n",
        "    print(f\"   Target achieved: {success_count >= TARGET_MOVIE_COUNT}\")\n",
        "\n",
        "else:\n",
        "    # Load existing data\n",
        "    features_file = os.path.join(DATA_DIR, 'tmdb_movie_features.json')\n",
        "    if os.path.exists(features_file):\n",
        "        with open(features_file, 'r', encoding='utf-8') as f:\n",
        "            all_movie_features = json.load(f)\n",
        "        print(f\"Existing movie feature data loaded: {len(all_movie_features)} movies\")\n",
        "    else:\n",
        "        print(\"ERROR: No existing movie feature data found\")\n",
        "        all_movie_features = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Similarity Calculation and Selection\n",
            "==================================================\n",
            "Current similarity calculation method: clip_features\n",
            "Available methods:\n",
            "Traditional Computer Vision Methods:\n",
            "  - 'histogram': HSV color histogram correlation\n",
            "  - 'ssim': Structural Similarity Index\n",
            "  - 'perceptual_hash': Perceptual hashing based on image structure\n",
            "  - 'combined': Weighted combination of traditional methods\n",
            "Deep Learning Methods:\n",
            "  - 'cnn_features': Pre-trained ResNet-50 CNN features\n",
            "  - 'clip_features': CLIP multimodal model features\n",
            "\n",
            "Method Characteristics:\n",
            "  Traditional methods: Fast, lightweight, good for basic similarity\n",
            "  CNN features: Captures high-level visual features, better semantic understanding\n",
            "  CLIP features: Best semantic similarity, trained on image-text pairs\n",
            "\n",
            "Starting image selection for 52 movies\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:   0%|          | 0/52 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Using similarity method: clip_features\n",
            "       Loading CLIP model (first time only)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Selecting images:   2%|▏         | 1/52 [00:04<03:26,  4.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 1. Toy Story: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:   4%|▍         | 2/52 [00:07<02:54,  3.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 2. GoldenEye: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:   6%|▌         | 3/52 [00:10<02:42,  3.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 3. Four Rooms: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:   8%|▊         | 4/52 [00:13<02:35,  3.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 4. Get Shorty: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  10%|▉         | 5/52 [00:16<02:29,  3.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 5. Copycat: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  12%|█▏        | 6/52 [00:17<02:00,  2.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 6. Shanghai Triad (Yao a yao yao dao waipo qiao): 7 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  13%|█▎        | 7/52 [00:21<02:04,  2.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 7. Twelve Monkeys: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  15%|█▌        | 8/52 [00:24<02:16,  3.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 8. Babe: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  17%|█▋        | 9/52 [00:28<02:23,  3.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 9. Dead Man Walking: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  19%|█▉        | 10/52 [00:30<02:00,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 10. Richard III: 7 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  21%|██        | 11/52 [00:34<02:09,  3.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 11. Seven (Se7en): 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  23%|██▎       | 12/52 [00:38<02:15,  3.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 12. Usual Suspects, The: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  25%|██▌       | 13/52 [00:42<02:18,  3.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 13. Mighty Aphrodite: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  27%|██▋       | 14/52 [00:46<02:20,  3.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 14. Postino, Il: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  29%|██▉       | 15/52 [00:50<02:18,  3.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 15. Mr. Holland's Opus: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  31%|███       | 16/52 [00:53<02:15,  3.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 16. French Twist (Gazon maudit): 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  33%|███▎      | 17/52 [00:57<02:11,  3.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 17. From Dusk Till Dawn: 10 -> 5 images\n",
            "   SUCCESS: 18. White Balloon, The: 4 -> 4 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  37%|███▋      | 19/52 [00:59<01:20,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 19. Antonia's Line: 7 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  38%|███▊      | 20/52 [01:01<01:16,  2.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 20. Angels and Insects: 8 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  40%|████      | 21/52 [01:05<01:24,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 21. Muppet Treasure Island: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  42%|████▏     | 22/52 [01:09<01:29,  2.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 22. Braveheart: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  44%|████▍     | 23/52 [01:12<01:32,  3.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 23. Taxi Driver: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  46%|████▌     | 24/52 [01:16<01:33,  3.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 24. Rumble in the Bronx: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  48%|████▊     | 25/52 [01:20<01:32,  3.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 25. Birdcage, The: 10 -> 5 images\n",
            "   SUCCESS: 26. Brothers McMullen, The: 4 -> 4 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  52%|█████▏    | 27/52 [01:23<01:07,  2.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 27. Bad Boys: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  54%|█████▍    | 28/52 [01:27<01:11,  2.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 28. Apollo 13: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  56%|█████▌    | 29/52 [01:31<01:12,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 29. Batman Forever: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  58%|█████▊    | 30/52 [01:34<01:12,  3.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 30. Belle de jour: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  60%|█████▉    | 31/52 [01:38<01:11,  3.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 31. Crimson Tide: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  62%|██████▏   | 32/52 [01:42<01:09,  3.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 32. Crumb: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  63%|██████▎   | 33/52 [01:46<01:07,  3.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 33. Desperado: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  65%|██████▌   | 34/52 [01:49<01:04,  3.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 34. Doom Generation, The: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  67%|██████▋   | 35/52 [01:53<01:01,  3.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 35. Free Willy 2: The Adventure Home: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  69%|██████▉   | 36/52 [01:56<00:54,  3.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 36. Mad Love: 9 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  71%|███████   | 37/52 [01:57<00:41,  2.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 37. Nadja: 6 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  73%|███████▎  | 38/52 [02:01<00:42,  3.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 38. Net, The: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  75%|███████▌  | 39/52 [02:04<00:42,  3.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 39. Strange Days: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  77%|███████▋  | 40/52 [02:08<00:40,  3.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 40. To Wong Foo, Thanks for Everything! Julie Newmar: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  79%|███████▉  | 41/52 [02:11<00:35,  3.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 41. Billy Madison: 9 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  81%|████████  | 42/52 [02:15<00:34,  3.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 42. Clerks: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  83%|████████▎ | 43/52 [02:19<00:31,  3.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 43. Disclosure: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  85%|████████▍ | 44/52 [02:22<00:28,  3.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 44. Dolores Claiborne: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  87%|████████▋ | 45/52 [02:26<00:25,  3.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 45. Eat Drink Man Woman: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  88%|████████▊ | 46/52 [02:31<00:23,  3.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 46. Exotica: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  90%|█████████ | 47/52 [02:36<00:21,  4.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 47. Ed Wood: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  92%|█████████▏| 48/52 [02:39<00:16,  4.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 48. Hoop Dreams: 8 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  94%|█████████▍| 49/52 [02:43<00:12,  4.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 49. I.Q.: 9 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  96%|█████████▌| 50/52 [02:49<00:08,  4.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 50. Star Wars: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images:  98%|█████████▊| 51/52 [02:54<00:04,  4.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 51. Legends of the Fall: 10 -> 5 images\n",
            "       Using similarity method: clip_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting images: 100%|██████████| 52/52 [02:55<00:00,  3.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 52. Madness of King George, The: 6 -> 5 images\n",
            "\n",
            "Image selection statistics:\n",
            "   Similarity method used: clip_features\n",
            "   Movies processed: 52\n",
            "   Total selected images: 258\n",
            "   Average per movie: 5.0 images\n",
            "   Updated data saved: multimodal_data\\movie_features_with_selected_images.json\n",
            "\n",
            "Selection details:\n",
            "   Original images total: 484\n",
            "   Selected images total: 258\n",
            "   Selection rate: 53.3%\n",
            "\n",
            "==================================================\n",
            "To change similarity calculation method, modify the SIMILARITY_METHOD variable:\n",
            "# Traditional methods:\n",
            "SIMILARITY_METHOD = 'histogram'       # Color-based similarity (fastest)\n",
            "SIMILARITY_METHOD = 'ssim'            # Structural similarity\n",
            "SIMILARITY_METHOD = 'perceptual_hash' # Content-based similarity\n",
            "SIMILARITY_METHOD = 'combined'        # Combination of traditional methods\n",
            "\n",
            "# Deep learning methods (require additional libraries):\n",
            "SIMILARITY_METHOD = 'cnn_features'    # CNN features (good semantic understanding)\n",
            "SIMILARITY_METHOD = 'clip_features'   # CLIP features (best semantic similarity)\n",
            "\n",
            "Installation requirements for deep learning methods:\n",
            "pip install torch torchvision        # For CNN features\n",
            "pip install transformers torch       # For CLIP features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Image similarity calculation and selection - select 5 most diverse from 10\n",
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from PIL import Image\n",
        "import hashlib\n",
        "\n",
        "# Deep learning imports (optional - install if using deep learning methods)\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision.transforms as transforms\n",
        "    import torchvision.models as models\n",
        "    from transformers import CLIPProcessor, CLIPModel\n",
        "    DEEP_LEARNING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    DEEP_LEARNING_AVAILABLE = False\n",
        "    print(\"Deep learning libraries not available. Install torch, torchvision, and transformers for CNN and CLIP methods.\")\n",
        "\n",
        "print(\"Image Similarity Calculation and Selection\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# SIMILARITY CALCULATION METHOD SELECTION\n",
        "SIMILARITY_METHOD = \"clip_features\"  # Options: \"histogram\", \"ssim\", \"perceptual_hash\", \"combined\", \"cnn_features\", \"clip_features\"\n",
        "\n",
        "def sanitize_filename(filename):\n",
        "    \"\"\"Remove or replace invalid characters for Windows file/folder names\"\"\"\n",
        "    # Replace invalid characters with underscore\n",
        "    invalid_chars = r'[<>:\"/\\\\|?*]'\n",
        "    sanitized = re.sub(invalid_chars, '_', filename)\n",
        "    \n",
        "    # Remove any trailing dots or spaces (also invalid in Windows)\n",
        "    sanitized = sanitized.rstrip('. ')\n",
        "    \n",
        "    # Ensure the name isn't empty after sanitization\n",
        "    if not sanitized.strip():\n",
        "        sanitized = \"unnamed\"\n",
        "    \n",
        "    return sanitized\n",
        "\n",
        "def calculate_histogram_similarity(img1_path, img2_path):\n",
        "    \"\"\"Calculate similarity between two images using HSV histogram comparison\"\"\"\n",
        "    try:\n",
        "        # Read images\n",
        "        img1 = cv2.imread(img1_path)\n",
        "        img2 = cv2.imread(img2_path)\n",
        "        \n",
        "        if img1 is None or img2 is None:\n",
        "            return 0.0\n",
        "        \n",
        "        # Convert to HSV color space\n",
        "        hsv1 = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
        "        hsv2 = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
        "        \n",
        "        # Calculate histograms\n",
        "        hist1 = cv2.calcHist([hsv1], [0, 1, 2], None, [50, 60, 60], [0, 180, 0, 256, 0, 256])\n",
        "        hist2 = cv2.calcHist([hsv2], [0, 1, 2], None, [50, 60, 60], [0, 180, 0, 256, 0, 256])\n",
        "        \n",
        "        # Calculate correlation\n",
        "        correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
        "        return max(0.0, correlation)  # Ensure non-negative\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"       Histogram similarity calculation failed: {str(e)}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_ssim_similarity(img1_path, img2_path):\n",
        "    \"\"\"Calculate similarity between two images using Structural Similarity Index (SSIM)\"\"\"\n",
        "    try:\n",
        "        # Read images\n",
        "        img1 = cv2.imread(img1_path)\n",
        "        img2 = cv2.imread(img2_path)\n",
        "        \n",
        "        if img1 is None or img2 is None:\n",
        "            return 0.0\n",
        "        \n",
        "        # Convert to grayscale\n",
        "        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Resize to same dimensions for comparison\n",
        "        height = min(gray1.shape[0], gray2.shape[0])\n",
        "        width = min(gray1.shape[1], gray2.shape[1])\n",
        "        \n",
        "        gray1_resized = cv2.resize(gray1, (width, height))\n",
        "        gray2_resized = cv2.resize(gray2, (width, height))\n",
        "        \n",
        "        # Calculate SSIM\n",
        "        similarity_score = ssim(gray1_resized, gray2_resized)\n",
        "        return max(0.0, similarity_score)  # Ensure non-negative\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"       SSIM similarity calculation failed: {str(e)}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_perceptual_hash_similarity(img1_path, img2_path):\n",
        "    \"\"\"Calculate similarity between two images using perceptual hashing\"\"\"\n",
        "    try:\n",
        "        def perceptual_hash(image_path, hash_size=8):\n",
        "            \"\"\"Calculate perceptual hash of an image\"\"\"\n",
        "            # Open and convert to grayscale\n",
        "            img = Image.open(image_path).convert('L')\n",
        "            \n",
        "            # Resize to hash_size x hash_size\n",
        "            img = img.resize((hash_size, hash_size), Image.Resampling.LANCZOS)\n",
        "            \n",
        "            # Convert to numpy array\n",
        "            pixels = np.array(img)\n",
        "            \n",
        "            # Calculate average pixel value\n",
        "            avg = pixels.mean()\n",
        "            \n",
        "            # Create binary hash\n",
        "            binary_hash = pixels > avg\n",
        "            \n",
        "            return binary_hash.flatten()\n",
        "        \n",
        "        # Calculate hashes\n",
        "        hash1 = perceptual_hash(img1_path)\n",
        "        hash2 = perceptual_hash(img2_path)\n",
        "        \n",
        "        # Calculate Hamming distance (number of different bits)\n",
        "        hamming_distance = np.sum(hash1 != hash2)\n",
        "        \n",
        "        # Convert to similarity (0 = identical, 1 = completely different)\n",
        "        max_distance = len(hash1)\n",
        "        similarity = 1.0 - (hamming_distance / max_distance)\n",
        "        \n",
        "        return max(0.0, similarity)\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"       Perceptual hash similarity calculation failed: {str(e)}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_combined_similarity(img1_path, img2_path):\n",
        "    \"\"\"Calculate similarity using a combination of multiple methods\"\"\"\n",
        "    try:\n",
        "        # Weight for each method\n",
        "        weights = {\n",
        "            'histogram': 0.4,\n",
        "            'ssim': 0.4,\n",
        "            'perceptual': 0.2\n",
        "        }\n",
        "        \n",
        "        # Calculate individual similarities\n",
        "        hist_sim = calculate_histogram_similarity(img1_path, img2_path)\n",
        "        ssim_sim = calculate_ssim_similarity(img1_path, img2_path)\n",
        "        hash_sim = calculate_perceptual_hash_similarity(img1_path, img2_path)\n",
        "        \n",
        "        # Weighted combination\n",
        "        combined_sim = (weights['histogram'] * hist_sim + \n",
        "                       weights['ssim'] * ssim_sim + \n",
        "                       weights['perceptual'] * hash_sim)\n",
        "        \n",
        "        return max(0.0, combined_sim)\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"       Combined similarity calculation failed: {str(e)}\")\n",
        "        return 0.0\n",
        "\n",
        "# Global variables for CNN model (to avoid reloading)\n",
        "_cnn_model = None\n",
        "_cnn_transform = None\n",
        "\n",
        "def calculate_cnn_features_similarity(img1_path, img2_path):\n",
        "    \"\"\"Calculate similarity using pre-trained CNN features (ResNet-50)\"\"\"\n",
        "    if not DEEP_LEARNING_AVAILABLE:\n",
        "        print(\"       CNN features method requires torch and torchvision\")\n",
        "        return 0.0\n",
        "    \n",
        "    global _cnn_model, _cnn_transform\n",
        "    \n",
        "    try:\n",
        "        # Load model and transform once\n",
        "        if _cnn_model is None:\n",
        "            print(\"       Loading ResNet-50 model (first time only)...\")\n",
        "            _cnn_model = models.resnet50(pretrained=True)\n",
        "            _cnn_model.eval()\n",
        "            # Remove the final classification layer to get features\n",
        "            _cnn_model = torch.nn.Sequential(*list(_cnn_model.children())[:-1])\n",
        "            \n",
        "            _cnn_transform = transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                   std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        \n",
        "        def extract_cnn_features(image_path):\n",
        "            \"\"\"Extract CNN features from an image\"\"\"\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            image_tensor = _cnn_transform(image).unsqueeze(0)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                features = _cnn_model(image_tensor)\n",
        "                features = features.squeeze().numpy()\n",
        "            \n",
        "            return features\n",
        "        \n",
        "        # Extract features\n",
        "        features1 = extract_cnn_features(img1_path)\n",
        "        features2 = extract_cnn_features(img2_path)\n",
        "        \n",
        "        # Calculate cosine similarity\n",
        "        dot_product = np.dot(features1, features2)\n",
        "        norm1 = np.linalg.norm(features1)\n",
        "        norm2 = np.linalg.norm(features2)\n",
        "        \n",
        "        if norm1 == 0 or norm2 == 0:\n",
        "            return 0.0\n",
        "        \n",
        "        cosine_sim = dot_product / (norm1 * norm2)\n",
        "        # Convert from [-1, 1] to [0, 1]\n",
        "        similarity = (cosine_sim + 1) / 2\n",
        "        \n",
        "        return max(0.0, min(1.0, similarity))\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"       CNN features similarity calculation failed: {str(e)}\")\n",
        "        return 0.0\n",
        "\n",
        "# Global variables for CLIP model\n",
        "_clip_model = None\n",
        "_clip_processor = None\n",
        "\n",
        "def calculate_clip_features_similarity(img1_path, img2_path):\n",
        "    \"\"\"Calculate similarity using CLIP model features\"\"\"\n",
        "    if not DEEP_LEARNING_AVAILABLE:\n",
        "        print(\"       CLIP features method requires transformers library\")\n",
        "        return 0.0\n",
        "    \n",
        "    global _clip_model, _clip_processor\n",
        "    \n",
        "    try:\n",
        "        # Load CLIP model and processor once\n",
        "        if _clip_model is None:\n",
        "            print(\"       Loading CLIP model (first time only)...\")\n",
        "            _clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "            _clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        \n",
        "        def extract_clip_features(image_path):\n",
        "            \"\"\"Extract CLIP features from an image\"\"\"\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            inputs = _clip_processor(images=image, return_tensors=\"pt\")\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                image_features = _clip_model.get_image_features(**inputs)\n",
        "                # Normalize features\n",
        "                image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)\n",
        "            \n",
        "            return image_features.squeeze().numpy()\n",
        "        \n",
        "        # Extract features\n",
        "        features1 = extract_clip_features(img1_path)\n",
        "        features2 = extract_clip_features(img2_path)\n",
        "        \n",
        "        # Calculate cosine similarity\n",
        "        cosine_sim = np.dot(features1, features2)\n",
        "        # CLIP features are already normalized, so dot product gives cosine similarity\n",
        "        # Convert from [-1, 1] to [0, 1]\n",
        "        similarity = (cosine_sim + 1) / 2\n",
        "        \n",
        "        return max(0.0, min(1.0, similarity))\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"       CLIP features similarity calculation failed: {str(e)}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_image_similarity(img1_path, img2_path, method=SIMILARITY_METHOD):\n",
        "    \"\"\"Calculate similarity between two images using specified method\"\"\"\n",
        "    method_functions = {\n",
        "        'histogram': calculate_histogram_similarity,\n",
        "        'ssim': calculate_ssim_similarity,\n",
        "        'perceptual_hash': calculate_perceptual_hash_similarity,\n",
        "        'combined': calculate_combined_similarity,\n",
        "        'cnn_features': calculate_cnn_features_similarity,\n",
        "        'clip_features': calculate_clip_features_similarity\n",
        "    }\n",
        "    \n",
        "    if method not in method_functions:\n",
        "        print(f\"   WARNING: Unknown similarity method '{method}', using 'histogram'\")\n",
        "        method = 'histogram'\n",
        "    \n",
        "    # Check if deep learning methods are available\n",
        "    if method in ['cnn_features', 'clip_features'] and not DEEP_LEARNING_AVAILABLE:\n",
        "        print(f\"   WARNING: Deep learning method '{method}' not available, using 'histogram'\")\n",
        "        method = 'histogram'\n",
        "    \n",
        "    return method_functions[method](img1_path, img2_path)\n",
        "\n",
        "def select_diverse_images(image_paths, target_count=5, similarity_method=SIMILARITY_METHOD):\n",
        "    \"\"\"Select the most diverse target_count images from the image list\"\"\"\n",
        "    if len(image_paths) <= target_count:\n",
        "        return image_paths\n",
        "    \n",
        "    print(f\"       Using similarity method: {similarity_method}\")\n",
        "    \n",
        "    # Calculate similarity matrix for all image pairs\n",
        "    n = len(image_paths)\n",
        "    similarity_matrix = np.zeros((n, n))\n",
        "    \n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            sim = calculate_image_similarity(image_paths[i], image_paths[j], similarity_method)\n",
        "            similarity_matrix[i][j] = sim\n",
        "            similarity_matrix[j][i] = sim\n",
        "    \n",
        "    # Greedy algorithm to select most dissimilar images\n",
        "    selected_indices = [0]  # Start with first image\n",
        "    \n",
        "    for _ in range(target_count - 1):\n",
        "        max_min_sim = -1\n",
        "        best_candidate = -1\n",
        "        \n",
        "        for candidate in range(n):\n",
        "            if candidate in selected_indices:\n",
        "                continue\n",
        "            \n",
        "            # Calculate minimum similarity with already selected images\n",
        "            min_sim = min(similarity_matrix[candidate][selected] for selected in selected_indices)\n",
        "            \n",
        "            if min_sim > max_min_sim:\n",
        "                max_min_sim = min_sim\n",
        "                best_candidate = candidate\n",
        "        \n",
        "        if best_candidate != -1:\n",
        "            selected_indices.append(best_candidate)\n",
        "    \n",
        "    return [image_paths[i] for i in selected_indices]\n",
        "\n",
        "# Print current configuration\n",
        "print(f\"Current similarity calculation method: {SIMILARITY_METHOD}\")\n",
        "print(\"Available methods:\")\n",
        "print(\"Traditional Computer Vision Methods:\")\n",
        "print(\"  - 'histogram': HSV color histogram correlation\")\n",
        "print(\"  - 'ssim': Structural Similarity Index\")\n",
        "print(\"  - 'perceptual_hash': Perceptual hashing based on image structure\")\n",
        "print(\"  - 'combined': Weighted combination of traditional methods\")\n",
        "\n",
        "if DEEP_LEARNING_AVAILABLE:\n",
        "    print(\"Deep Learning Methods:\")\n",
        "    print(\"  - 'cnn_features': Pre-trained ResNet-50 CNN features\")\n",
        "    print(\"  - 'clip_features': CLIP multimodal model features\")\n",
        "else:\n",
        "    print(\"Deep Learning Methods (Not Available - install requirements):\")\n",
        "    print(\"  - 'cnn_features': Pre-trained ResNet-50 CNN features [REQUIRES: torch, torchvision]\")\n",
        "    print(\"  - 'clip_features': CLIP multimodal model features [REQUIRES: transformers]\")\n",
        "\n",
        "print()\n",
        "print(\"Method Characteristics:\")\n",
        "print(\"  Traditional methods: Fast, lightweight, good for basic similarity\")\n",
        "print(\"  CNN features: Captures high-level visual features, better semantic understanding\")\n",
        "print(\"  CLIP features: Best semantic similarity, trained on image-text pairs\")\n",
        "print()\n",
        "\n",
        "# Filter images for each movie\n",
        "if 'all_movie_features' in locals() and all_movie_features:\n",
        "    print(f\"Starting image selection for {len(all_movie_features)} movies\")\n",
        "    \n",
        "    selected_image_stats = []\n",
        "    total_selected = 0\n",
        "    \n",
        "    for movie_features in tqdm(all_movie_features, desc=\"Selecting images\"):\n",
        "        movie_id = movie_features['movielens_id']\n",
        "        title = movie_features['movielens_title']\n",
        "        \n",
        "        # Get image paths\n",
        "        image_paths = movie_features.get('image_paths', [])\n",
        "        \n",
        "        if not image_paths:\n",
        "            print(f\"   WARNING: {movie_id}. {title}: No images found\")\n",
        "            continue\n",
        "        \n",
        "        # Verify image files exist\n",
        "        valid_paths = [path for path in image_paths if os.path.exists(path)]\n",
        "        \n",
        "        if len(valid_paths) == 0:\n",
        "            print(f\"   ERROR: {movie_id}. {title}: Image files do not exist\")\n",
        "            continue\n",
        "        \n",
        "        # Select most diverse images\n",
        "        selected_paths = select_diverse_images(valid_paths, SELECTED_IMAGES, SIMILARITY_METHOD)\n",
        "        \n",
        "        # Create selected image directory and copy images\n",
        "        # FIXED: Sanitize the title to remove invalid characters\n",
        "        sanitized_title = sanitize_filename(title[:50])\n",
        "        selected_folder = os.path.join(SELECTED_IMAGE_DIR, f\"{movie_id:04d}_{sanitized_title}\")\n",
        "        \n",
        "        try:\n",
        "            os.makedirs(selected_folder, exist_ok=True)\n",
        "        except Exception as e:\n",
        "            print(f\"   ERROR: Failed to create directory for {movie_id}. {title}: {str(e)}\")\n",
        "            # Fallback: use only movie ID as folder name\n",
        "            selected_folder = os.path.join(SELECTED_IMAGE_DIR, f\"{movie_id:04d}\")\n",
        "            os.makedirs(selected_folder, exist_ok=True)\n",
        "        \n",
        "        copied_paths = []\n",
        "        for i, src_path in enumerate(selected_paths):\n",
        "            filename = f\"selected_{i+1}.jpg\"\n",
        "            dst_path = os.path.join(selected_folder, filename)\n",
        "            \n",
        "            try:\n",
        "                # Copy image\n",
        "                img = Image.open(src_path)\n",
        "                img.save(dst_path, \"JPEG\", quality=90)\n",
        "                copied_paths.append(dst_path)\n",
        "            except Exception as e:\n",
        "                print(f\"     ERROR: Failed to copy image: {str(e)}\")\n",
        "        \n",
        "        # Update feature data\n",
        "        movie_features['selected_image_paths'] = copied_paths\n",
        "        movie_features['selected_images_count'] = len(copied_paths)\n",
        "        movie_features['similarity_method_used'] = SIMILARITY_METHOD\n",
        "        \n",
        "        selected_image_stats.append({\n",
        "            'movie_id': movie_id,\n",
        "            'title': title,\n",
        "            'original_count': len(valid_paths),\n",
        "            'selected_count': len(copied_paths)\n",
        "        })\n",
        "        \n",
        "        total_selected += len(copied_paths)\n",
        "        \n",
        "        print(f\"   SUCCESS: {movie_id}. {title}: {len(valid_paths)} -> {len(copied_paths)} images\")\n",
        "    \n",
        "    # Save updated feature data\n",
        "    updated_features_file = os.path.join(DATA_DIR, 'movie_features_with_selected_images.json')\n",
        "    with open(updated_features_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_movie_features, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"\\nImage selection statistics:\")\n",
        "    print(f\"   Similarity method used: {SIMILARITY_METHOD}\")\n",
        "    print(f\"   Movies processed: {len(selected_image_stats)}\")\n",
        "    print(f\"   Total selected images: {total_selected}\")\n",
        "    print(f\"   Average per movie: {total_selected/len(selected_image_stats):.1f} images\")\n",
        "    print(f\"   Updated data saved: {updated_features_file}\")\n",
        "    \n",
        "    # Display selection details\n",
        "    stats_df = pd.DataFrame(selected_image_stats)\n",
        "    print(f\"\\nSelection details:\")\n",
        "    print(f\"   Original images total: {stats_df['original_count'].sum()}\")\n",
        "    print(f\"   Selected images total: {stats_df['selected_count'].sum()}\")\n",
        "    print(f\"   Selection rate: {stats_df['selected_count'].sum()/stats_df['original_count'].sum()*100:.1f}%\")\n",
        "    \n",
        "else:\n",
        "    print(\"ERROR: No movie feature data available for image selection\")\n",
        "\n",
        "# Example of how to change similarity method:\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"To change similarity calculation method, modify the SIMILARITY_METHOD variable:\")\n",
        "print(\"# Traditional methods:\")\n",
        "print(\"SIMILARITY_METHOD = 'histogram'       # Color-based similarity (fastest)\")\n",
        "print(\"SIMILARITY_METHOD = 'ssim'            # Structural similarity\") \n",
        "print(\"SIMILARITY_METHOD = 'perceptual_hash' # Content-based similarity\")\n",
        "print(\"SIMILARITY_METHOD = 'combined'        # Combination of traditional methods\")\n",
        "print()\n",
        "print(\"# Deep learning methods (require additional libraries):\")\n",
        "print(\"SIMILARITY_METHOD = 'cnn_features'    # CNN features (good semantic understanding)\")\n",
        "print(\"SIMILARITY_METHOD = 'clip_features'   # CLIP features (best semantic similarity)\")\n",
        "print()\n",
        "print(\"Installation requirements for deep learning methods:\")\n",
        "print(\"pip install torch torchvision        # For CNN features\")\n",
        "print(\"pip install transformers torch       # For CLIP features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "SIMILARITY METHODS COMPARISON\n",
            "======================================================================\n",
            "✓ All required functions are available\n",
            "📋 Comparison Configuration:\n",
            "   Sample Size: 10 images\n",
            "   Max Movies: 5\n",
            "   Total Comparisons per Method: 45\n",
            "   Estimated Time per Method:\n",
            "     - Traditional methods: 10-60 seconds\n",
            "     - Deep learning methods: 2-10 minutes\n",
            "\n",
            "Collecting sample images for comparison...\n",
            "Found 52 movies with sufficient images\n",
            "Selected 2 images from movie: Mr. Holland's Opus\n",
            "Selected 2 images from movie: Bad Boys\n",
            "Selected 2 images from movie: From Dusk Till Dawn\n",
            "Selected 2 images from movie: Four Rooms\n",
            "Selected 2 images from movie: Crimson Tide\n",
            "Selected 10 images from 5 movies for comparison\n",
            "Total similarity calculations per method: 45\n",
            "\n",
            "Testing method: histogram...\n",
            "  ✓ Completed - Avg: 0.171, Time: 0.11s, Speed: 426.5 comp/s\n",
            "Testing method: ssim...\n",
            "  ✓ Completed - Avg: 0.142, Time: 1.09s, Speed: 41.4 comp/s\n",
            "Testing method: perceptual_hash...\n",
            "  ✓ Completed - Avg: 0.497, Time: 0.13s, Speed: 343.4 comp/s\n",
            "Testing method: combined...\n",
            "  ✓ Completed - Avg: 0.225, Time: 1.32s, Speed: 34.2 comp/s\n",
            "Testing method: cnn_features...\n",
            "       Loading ResNet-50 model (first time only)...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Admin/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:02<00:00, 39.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✓ Completed - Avg: 0.839, Time: 6.18s, Speed: 7.3 comp/s\n",
            "Testing method: clip_features...\n",
            "  ✓ Completed - Avg: 0.771, Time: 3.15s, Speed: 14.3 comp/s\n",
            "\n",
            "================================================================================\n",
            "SIMILARITY METHODS COMPARISON RESULTS\n",
            "================================================================================\n",
            "\n",
            "📊 SIMILARITY STATISTICS:\n",
            "--------------------------------------------------------------------------------\n",
            "         Method  Average Similarity  Std Deviation  Min Similarity  Max Similarity\n",
            "      histogram              0.1710         0.2896          0.0000          0.9956\n",
            "           ssim              0.1424         0.1016          0.0052          0.5065\n",
            "perceptual_hash              0.4972         0.1085          0.2031          0.8125\n",
            "       combined              0.2248         0.1230          0.0966          0.6473\n",
            "   cnn_features              0.8389         0.0435          0.7597          0.9419\n",
            "  clip_features              0.7715         0.0616          0.6728          0.9282\n",
            "\n",
            "⏱️  DETAILED TIME PERFORMANCE:\n",
            "--------------------------------------------------------------------------------\n",
            "         Method Total Time (s) Avg Time per Comparison (ms) Min Time per Comparison (ms) Max Time per Comparison (ms) Comparisons per Second\n",
            "      histogram           0.11                         2.34                         2.00                         3.00                  426.5\n",
            "           ssim           1.09                        24.13                        21.82                        28.01                   41.4\n",
            "perceptual_hash           0.13                         2.91                         2.00                         4.00                  343.4\n",
            "       combined           1.32                        29.27                        26.99                        35.48                   34.2\n",
            "   cnn_features           6.18                       137.41                        65.52                      3125.38                    7.3\n",
            "  clip_features           3.15                        69.89                        65.02                        81.11                   14.3\n",
            "\n",
            "📈 TIME VARIABILITY:\n",
            "--------------------------------------------------------------------------------\n",
            "         Method Std Time per Comparison (ms)  Total Comparisons  Status\n",
            "      histogram                         0.46                 45 Success\n",
            "           ssim                         1.41                 45 Success\n",
            "perceptual_hash                         0.46                 45 Success\n",
            "       combined                         1.50                 45 Success\n",
            "   cnn_features                       450.47                 45 Success\n",
            "  clip_features                         3.51                 45 Success\n",
            "\n",
            "🏆 METHOD RANKINGS:\n",
            "--------------------------------------------------------------------------------\n",
            "         Method  Speed Rank  Diversity Rank  Consistency Rank  Combined Rank\n",
            "      histogram         1.0             2.0               2.0            1.7\n",
            "           ssim         3.0             1.0               3.0            2.3\n",
            "perceptual_hash         2.0             4.0               1.0            2.3\n",
            "       combined         4.0             3.0               4.0            3.7\n",
            "  clip_features         5.0             5.0               5.0            5.0\n",
            "   cnn_features         6.0             6.0               6.0            6.0\n",
            "\n",
            "🥇 BEST PERFORMERS:\n",
            "   Overall Best: histogram\n",
            "   Fastest: histogram\n",
            "   Most Diverse Selection: ssim\n",
            "   Most Consistent: perceptual_hash\n",
            "\n",
            "⚡ TIME EFFICIENCY ANALYSIS:\n",
            "   Fastest method: histogram (426.5 comp/s)\n",
            "   Slowest method: cnn_features (7.3 comp/s)\n",
            "   Speed difference: 58.6x faster\n",
            "\n",
            "📈 TIME SCALING ESTIMATES (for 1000 comparisons):\n",
            "   histogram      :      2.3 seconds\n",
            "   ssim           :     24.1 seconds\n",
            "   perceptual_hash:      2.9 seconds\n",
            "   combined       :     29.3 seconds\n",
            "   cnn_features   :    137.4 seconds\n",
            "   clip_features  :     69.9 seconds\n",
            "\n",
            "📝 INTERPRETATION GUIDE:\n",
            "--------------------------------------------------------------------------------\n",
            "• Lower Average Similarity = Better for diverse image selection\n",
            "• Higher Comparisons per Second = Faster processing\n",
            "• Lower Time Std = More consistent performance\n",
            "• Combined Rank considers speed, diversity, and consistency\n",
            "• For large datasets, prioritize methods with high 'Comparisons per Second'\n",
            "• For quality, consider methods with low 'Average Similarity'\n",
            "\n",
            "💾 Results saved to:\n",
            "   - Detailed data: multimodal_data\\similarity_methods_comparison.csv\n",
            "   - Summary report: multimodal_data\\similarity_comparison_summary.txt\n",
            "   - Sample info: multimodal_data\\similarity_comparison_sample_info.json\n"
          ]
        }
      ],
      "source": [
        "# Optional: Compare different similarity calculation methods\n",
        "# Set this to True to run the comparison\n",
        "RUN_COMPARISON = True # Change to True to enable comparison\n",
        "\n",
        "if RUN_COMPARISON:\n",
        "    import time\n",
        "    import pandas as pd\n",
        "    import random\n",
        "    from statistics import mean, stdev\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    print(\"SIMILARITY METHODS COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Check if required functions are available\n",
        "    required_functions = ['calculate_image_similarity']\n",
        "    missing_functions = []\n",
        "    \n",
        "    for func_name in required_functions:\n",
        "        if func_name not in globals():\n",
        "            missing_functions.append(func_name)\n",
        "    \n",
        "    if missing_functions:\n",
        "        print(f\"ERROR: Required functions not found: {missing_functions}\")\n",
        "        print(\"Please run the main image selection cell first to define all required functions\")\n",
        "        print(\"Set RUN_COMPARISON = False to disable this check\")\n",
        "    else:\n",
        "        print(\"✓ All required functions are available\")\n",
        "    \n",
        "    # Sample selection for comparison\n",
        "    COMPARISON_SAMPLE_SIZE = 10  # Number of images to use for comparison\n",
        "    MAX_MOVIES_TO_TEST = 5       # Number of movies to test (to limit computation time)\n",
        "    \n",
        "    print(f\"📋 Comparison Configuration:\")\n",
        "    print(f\"   Sample Size: {COMPARISON_SAMPLE_SIZE} images\")\n",
        "    print(f\"   Max Movies: {MAX_MOVIES_TO_TEST}\")\n",
        "    print(f\"   Total Comparisons per Method: {COMPARISON_SAMPLE_SIZE * (COMPARISON_SAMPLE_SIZE - 1) // 2}\")\n",
        "    print(f\"   Estimated Time per Method:\")\n",
        "    print(f\"     - Traditional methods: 10-60 seconds\")\n",
        "    print(f\"     - Deep learning methods: 2-10 minutes\")\n",
        "    print()\n",
        "    \n",
        "    def collect_sample_images():\n",
        "        \"\"\"Collect sample images from processed movies for comparison\"\"\"\n",
        "        sample_images = []\n",
        "        \n",
        "        # Check if movie feature data is available\n",
        "        try:\n",
        "            # Try to access the global variable\n",
        "            movie_data = globals().get('all_movie_features', None)\n",
        "            if movie_data is None:\n",
        "                print(\"ERROR: all_movie_features variable not found in global scope\")\n",
        "                print(\"Please run the main image selection cell first to load movie data\")\n",
        "                return None\n",
        "            \n",
        "            if not movie_data:\n",
        "                print(\"ERROR: all_movie_features is empty\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Cannot access movie feature data: {str(e)}\")\n",
        "            return None\n",
        "        \n",
        "        # Collect images from multiple movies\n",
        "        movies_with_images = [movie for movie in movie_data \n",
        "                            if movie.get('image_paths') and len(movie.get('image_paths', [])) >= 3]\n",
        "        \n",
        "        if len(movies_with_images) == 0:\n",
        "            print(\"ERROR: No movies with sufficient images found\")\n",
        "            print(\"Make sure the main image selection process has been completed\")\n",
        "            return None\n",
        "        \n",
        "        print(f\"Found {len(movies_with_images)} movies with sufficient images\")\n",
        "        \n",
        "        # Randomly select movies for testing\n",
        "        test_movies = random.sample(movies_with_images, \n",
        "                                  min(MAX_MOVIES_TO_TEST, len(movies_with_images)))\n",
        "        \n",
        "        for movie in test_movies:\n",
        "            valid_paths = [path for path in movie.get('image_paths', []) \n",
        "                         if os.path.exists(path)]\n",
        "            \n",
        "            if len(valid_paths) == 0:\n",
        "                print(f\"Warning: No valid image paths found for movie {movie.get('movielens_title', 'Unknown')}\")\n",
        "                continue\n",
        "            \n",
        "            # Take up to COMPARISON_SAMPLE_SIZE//MAX_MOVIES_TO_TEST images per movie\n",
        "            images_per_movie = max(1, COMPARISON_SAMPLE_SIZE // MAX_MOVIES_TO_TEST)\n",
        "            selected = random.sample(valid_paths, \n",
        "                                   min(images_per_movie, len(valid_paths)))\n",
        "            sample_images.extend(selected)\n",
        "            \n",
        "            print(f\"Selected {len(selected)} images from movie: {movie.get('movielens_title', 'Unknown')}\")\n",
        "        \n",
        "        # Ensure we don't exceed the sample size\n",
        "        if len(sample_images) > COMPARISON_SAMPLE_SIZE:\n",
        "            sample_images = random.sample(sample_images, COMPARISON_SAMPLE_SIZE)\n",
        "        \n",
        "        return sample_images\n",
        "    \n",
        "    def calculate_similarity_matrix(image_paths, method_name):\n",
        "        \"\"\"Calculate similarity matrix for given images using specified method\"\"\"\n",
        "        n = len(image_paths)\n",
        "        similarities = []\n",
        "        time_records = []\n",
        "        \n",
        "        total_start_time = time.time()\n",
        "        \n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):  # Only calculate upper triangle to avoid duplicates\n",
        "                comparison_start = time.time()\n",
        "                sim = calculate_image_similarity(image_paths[i], image_paths[j], method_name)\n",
        "                comparison_end = time.time()\n",
        "                \n",
        "                similarities.append(sim)\n",
        "                time_records.append(comparison_end - comparison_start)\n",
        "        \n",
        "        total_end_time = time.time()\n",
        "        total_computation_time = total_end_time - total_start_time\n",
        "        \n",
        "        # Calculate time statistics\n",
        "        time_stats = {\n",
        "            'total_time': total_computation_time,\n",
        "            'avg_time_per_comparison': np.mean(time_records) if time_records else 0.0,\n",
        "            'min_time_per_comparison': min(time_records) if time_records else 0.0,\n",
        "            'max_time_per_comparison': max(time_records) if time_records else 0.0,\n",
        "            'std_time_per_comparison': np.std(time_records) if time_records else 0.0,\n",
        "            'total_comparisons': len(similarities)\n",
        "        }\n",
        "        \n",
        "        return similarities, time_stats\n",
        "    \n",
        "    def run_methods_comparison():\n",
        "        \"\"\"Run comparison of all available similarity methods\"\"\"\n",
        "        \n",
        "        # Collect sample images\n",
        "        print(\"Collecting sample images for comparison...\")\n",
        "        sample_images = collect_sample_images()\n",
        "        \n",
        "        if sample_images is None:\n",
        "            print(\"SOLUTION: Please run the main image selection cell first to generate all_movie_features\")\n",
        "            return None, None\n",
        "        \n",
        "        if len(sample_images) < 3:\n",
        "            print(f\"ERROR: Need at least 3 images for comparison, found {len(sample_images)}\")\n",
        "            print(\"Try increasing MAX_MOVIES_TO_TEST or check if image files exist\")\n",
        "            return None, None\n",
        "        \n",
        "        print(f\"Selected {len(sample_images)} images from {MAX_MOVIES_TO_TEST} movies for comparison\")\n",
        "        print(f\"Total similarity calculations per method: {len(sample_images) * (len(sample_images) - 1) // 2}\")\n",
        "        print()\n",
        "        \n",
        "        # Define methods to test\n",
        "        methods_to_test = ['histogram', 'ssim', 'perceptual_hash', 'combined']\n",
        "        \n",
        "        # Add deep learning methods if available\n",
        "        if DEEP_LEARNING_AVAILABLE:\n",
        "            methods_to_test.extend(['cnn_features', 'clip_features'])\n",
        "        \n",
        "        # Store results\n",
        "        results = []\n",
        "        \n",
        "        # Test each method\n",
        "        for method in methods_to_test:\n",
        "            print(f\"Testing method: {method}...\")\n",
        "            \n",
        "            try:\n",
        "                similarities, time_stats = calculate_similarity_matrix(sample_images, method)\n",
        "                \n",
        "                if similarities:\n",
        "                    avg_similarity = mean(similarities)\n",
        "                    std_similarity = stdev(similarities) if len(similarities) > 1 else 0.0\n",
        "                    min_similarity = min(similarities)\n",
        "                    max_similarity = max(similarities)\n",
        "                    \n",
        "                    results.append({\n",
        "                        'Method': method,\n",
        "                        'Average Similarity': avg_similarity,\n",
        "                        'Std Deviation': std_similarity,\n",
        "                        'Min Similarity': min_similarity,\n",
        "                        'Max Similarity': max_similarity,\n",
        "                        'Total Time (s)': time_stats['total_time'],\n",
        "                        'Avg Time per Comparison (ms)': time_stats['avg_time_per_comparison'] * 1000,\n",
        "                        'Min Time per Comparison (ms)': time_stats['min_time_per_comparison'] * 1000,\n",
        "                        'Max Time per Comparison (ms)': time_stats['max_time_per_comparison'] * 1000,\n",
        "                        'Std Time per Comparison (ms)': time_stats['std_time_per_comparison'] * 1000,\n",
        "                        'Total Comparisons': time_stats['total_comparisons'],\n",
        "                        'Comparisons per Second': time_stats['total_comparisons'] / time_stats['total_time'] if time_stats['total_time'] > 0 else 0,\n",
        "                        'Status': 'Success'\n",
        "                    })\n",
        "                    \n",
        "                    print(f\"  ✓ Completed - Avg: {avg_similarity:.3f}, Time: {time_stats['total_time']:.2f}s, Speed: {time_stats['total_comparisons']/time_stats['total_time']:.1f} comp/s\")\n",
        "                else:\n",
        "                    results.append({\n",
        "                        'Method': method,\n",
        "                        'Average Similarity': 0.0,\n",
        "                        'Std Deviation': 0.0,\n",
        "                        'Min Similarity': 0.0,\n",
        "                        'Max Similarity': 0.0,\n",
        "                        'Total Time (s)': time_stats.get('total_time', 0.0),\n",
        "                        'Avg Time per Comparison (ms)': 0.0,\n",
        "                        'Min Time per Comparison (ms)': 0.0,\n",
        "                        'Max Time per Comparison (ms)': 0.0,\n",
        "                        'Std Time per Comparison (ms)': 0.0,\n",
        "                        'Total Comparisons': 0,\n",
        "                        'Comparisons per Second': 0.0,\n",
        "                        'Status': 'Failed - No similarities calculated'\n",
        "                    })\n",
        "                    print(f\"  ✗ Failed - No similarities calculated\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                results.append({\n",
        "                    'Method': method,\n",
        "                    'Average Similarity': 0.0,\n",
        "                    'Std Deviation': 0.0,\n",
        "                    'Min Similarity': 0.0,\n",
        "                    'Max Similarity': 0.0,\n",
        "                    'Total Time (s)': 0.0,\n",
        "                    'Avg Time per Comparison (ms)': 0.0,\n",
        "                    'Min Time per Comparison (ms)': 0.0,\n",
        "                    'Max Time per Comparison (ms)': 0.0,\n",
        "                    'Std Time per Comparison (ms)': 0.0,\n",
        "                    'Total Comparisons': 0,\n",
        "                    'Comparisons per Second': 0.0,\n",
        "                    'Status': f'Error: {str(e)[:50]}...'\n",
        "                })\n",
        "                print(f\"  ✗ Error: {str(e)}\")\n",
        "        \n",
        "        return results, sample_images\n",
        "    \n",
        "    def display_comparison_results(results):\n",
        "        \"\"\"Display comparison results in a formatted table\"\"\"\n",
        "        df = pd.DataFrame(results)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SIMILARITY METHODS COMPARISON RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        # Create a more readable display\n",
        "        print(\"\\n📊 SIMILARITY STATISTICS:\")\n",
        "        print(\"-\" * 80)\n",
        "        similarity_cols = ['Method', 'Average Similarity', 'Std Deviation', 'Min Similarity', 'Max Similarity']\n",
        "        print(df[similarity_cols].to_string(index=False, float_format='%.4f'))\n",
        "        \n",
        "        print(\"\\n⏱️  DETAILED TIME PERFORMANCE:\")\n",
        "        print(\"-\" * 80)\n",
        "        time_cols = ['Method', 'Total Time (s)', 'Avg Time per Comparison (ms)', \n",
        "                    'Min Time per Comparison (ms)', 'Max Time per Comparison (ms)', \n",
        "                    'Comparisons per Second']\n",
        "        time_df = df[time_cols].copy()\n",
        "        \n",
        "        # Format time columns for better readability\n",
        "        time_df['Total Time (s)'] = time_df['Total Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "        time_df['Avg Time per Comparison (ms)'] = time_df['Avg Time per Comparison (ms)'].apply(lambda x: f\"{x:.2f}\")\n",
        "        time_df['Min Time per Comparison (ms)'] = time_df['Min Time per Comparison (ms)'].apply(lambda x: f\"{x:.2f}\")\n",
        "        time_df['Max Time per Comparison (ms)'] = time_df['Max Time per Comparison (ms)'].apply(lambda x: f\"{x:.2f}\")\n",
        "        time_df['Comparisons per Second'] = time_df['Comparisons per Second'].apply(lambda x: f\"{x:.1f}\")\n",
        "        \n",
        "        print(time_df.to_string(index=False))\n",
        "        \n",
        "        print(\"\\n📈 TIME VARIABILITY:\")\n",
        "        print(\"-\" * 80)\n",
        "        variability_cols = ['Method', 'Std Time per Comparison (ms)', 'Total Comparisons', 'Status']\n",
        "        var_df = df[variability_cols].copy()\n",
        "        var_df['Std Time per Comparison (ms)'] = var_df['Std Time per Comparison (ms)'].apply(lambda x: f\"{x:.2f}\")\n",
        "        print(var_df.to_string(index=False))\n",
        "        \n",
        "        print(\"\\n🏆 METHOD RANKINGS:\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        # Rank by average similarity (diversity perspective - lower is better for diverse selection)\n",
        "        successful_results = df[df['Status'] == 'Success'].copy()\n",
        "        \n",
        "        if len(successful_results) > 0:\n",
        "            # Rank by speed (higher comparisons per second is better)\n",
        "            successful_results['Speed Rank'] = successful_results['Comparisons per Second'].rank(ascending=False)\n",
        "            \n",
        "            # Rank by diversity (lower average similarity is better for diverse selection)\n",
        "            successful_results['Diversity Rank'] = successful_results['Average Similarity'].rank()\n",
        "            \n",
        "            # Rank by consistency (lower time std is better)\n",
        "            successful_results['Consistency Rank'] = successful_results['Std Time per Comparison (ms)'].rank()\n",
        "            \n",
        "            # Combined rank (lower is better)\n",
        "            successful_results['Combined Rank'] = (successful_results['Speed Rank'] + \n",
        "                                                 successful_results['Diversity Rank'] + \n",
        "                                                 successful_results['Consistency Rank']) / 3\n",
        "            \n",
        "            ranking_cols = ['Method', 'Speed Rank', 'Diversity Rank', 'Consistency Rank', 'Combined Rank']\n",
        "            ranking_df = successful_results[ranking_cols].sort_values('Combined Rank')\n",
        "            print(ranking_df.to_string(index=False, float_format='%.1f'))\n",
        "            \n",
        "            print(f\"\\n🥇 BEST PERFORMERS:\")\n",
        "            print(f\"   Overall Best: {ranking_df.iloc[0]['Method']}\")\n",
        "            print(f\"   Fastest: {successful_results.loc[successful_results['Speed Rank'].idxmin(), 'Method']}\")\n",
        "            print(f\"   Most Diverse Selection: {successful_results.loc[successful_results['Diversity Rank'].idxmin(), 'Method']}\")\n",
        "            print(f\"   Most Consistent: {successful_results.loc[successful_results['Consistency Rank'].idxmin(), 'Method']}\")\n",
        "            \n",
        "            # Time efficiency analysis\n",
        "            print(f\"\\n⚡ TIME EFFICIENCY ANALYSIS:\")\n",
        "            fastest = successful_results.loc[successful_results['Comparisons per Second'].idxmax()]\n",
        "            slowest = successful_results.loc[successful_results['Comparisons per Second'].idxmin()]\n",
        "            speedup = fastest['Comparisons per Second'] / slowest['Comparisons per Second']\n",
        "            \n",
        "            print(f\"   Fastest method: {fastest['Method']} ({fastest['Comparisons per Second']:.1f} comp/s)\")\n",
        "            print(f\"   Slowest method: {slowest['Method']} ({slowest['Comparisons per Second']:.1f} comp/s)\")\n",
        "            print(f\"   Speed difference: {speedup:.1f}x faster\")\n",
        "            \n",
        "            # Time scaling estimates\n",
        "            print(f\"\\n📈 TIME SCALING ESTIMATES (for 1000 comparisons):\")\n",
        "            for _, row in successful_results.iterrows():\n",
        "                time_for_1000 = 1000 / row['Comparisons per Second']\n",
        "                print(f\"   {row['Method']:15}: {time_for_1000:8.1f} seconds\")\n",
        "        \n",
        "        print(\"\\n📝 INTERPRETATION GUIDE:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(\"• Lower Average Similarity = Better for diverse image selection\")\n",
        "        print(\"• Higher Comparisons per Second = Faster processing\")\n",
        "        print(\"• Lower Time Std = More consistent performance\")\n",
        "        print(\"• Combined Rank considers speed, diversity, and consistency\")\n",
        "        print(\"• For large datasets, prioritize methods with high 'Comparisons per Second'\")\n",
        "        print(\"• For quality, consider methods with low 'Average Similarity'\")\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def save_comparison_results(results, sample_images):\n",
        "        \"\"\"Save comparison results to file\"\"\"\n",
        "        try:\n",
        "            # Save detailed results\n",
        "            results_df = pd.DataFrame(results)\n",
        "            results_file = os.path.join(DATA_DIR, 'similarity_methods_comparison.csv')\n",
        "            results_df.to_csv(results_file, index=False)\n",
        "            \n",
        "            # Create a summary report\n",
        "            summary_file = os.path.join(DATA_DIR, 'similarity_comparison_summary.txt')\n",
        "            with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(\"SIMILARITY METHODS COMPARISON SUMMARY\\n\")\n",
        "                f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "                f.write(f\"Comparison Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "                f.write(f\"Sample Size: {len(sample_images)} images\\n\")\n",
        "                f.write(f\"Total Methods Tested: {len(results)}\\n\\n\")\n",
        "                \n",
        "                # Write performance summary\n",
        "                successful_results = [r for r in results if r['Status'] == 'Success']\n",
        "                if successful_results:\n",
        "                    f.write(\"PERFORMANCE SUMMARY:\\n\")\n",
        "                    f.write(\"-\" * 30 + \"\\n\")\n",
        "                    for result in successful_results:\n",
        "                        f.write(f\"{result['Method']:15}: {result['Comparisons per Second']:6.1f} comp/s, \")\n",
        "                        f.write(f\"Avg Sim: {result['Average Similarity']:.3f}\\n\")\n",
        "                    \n",
        "                    fastest = max(successful_results, key=lambda x: x['Comparisons per Second'])\n",
        "                    most_diverse = min(successful_results, key=lambda x: x['Average Similarity'])\n",
        "                    \n",
        "                    f.write(f\"\\nFastest Method: {fastest['Method']}\\n\")\n",
        "                    f.write(f\"Most Diverse: {most_diverse['Method']}\\n\")\n",
        "            \n",
        "            # Save sample images list\n",
        "            sample_info = {\n",
        "                'sample_images': sample_images,\n",
        "                'sample_size': len(sample_images),\n",
        "                'comparison_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                'methods_tested': [r['Method'] for r in results],\n",
        "                'total_time_spent': sum(r.get('Total Time (s)', 0) for r in results),\n",
        "                'total_comparisons': sum(r.get('Total Comparisons', 0) for r in results)\n",
        "            }\n",
        "            \n",
        "            sample_file = os.path.join(DATA_DIR, 'similarity_comparison_sample_info.json')\n",
        "            with open(sample_file, 'w') as f:\n",
        "                json.dump(sample_info, f, indent=2)\n",
        "            \n",
        "            print(f\"\\n💾 Results saved to:\")\n",
        "            print(f\"   - Detailed data: {results_file}\")\n",
        "            print(f\"   - Summary report: {summary_file}\")\n",
        "            print(f\"   - Sample info: {sample_file}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results: {str(e)}\")\n",
        "    \n",
        "    # Run the comparison only if all required functions are available\n",
        "    if not missing_functions:\n",
        "        try:\n",
        "            comparison_result = run_methods_comparison()\n",
        "            \n",
        "            if comparison_result[0] is None:\n",
        "                print(\"\\nComparison aborted due to data availability issues.\")\n",
        "            else:\n",
        "                results, sample_images = comparison_result\n",
        "                comparison_df = display_comparison_results(results)\n",
        "                save_comparison_results(results, sample_images)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Comparison failed: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"Similarity methods comparison is disabled.\")\n",
        "    print(\"To enable comparison, set RUN_COMPARISON = True\")\n",
        "    print(\"\\nPrerequisites:\")\n",
        "    print(\"1. Run the main image selection cell first\")\n",
        "    print(\"2. Ensure all_movie_features variable is populated\")\n",
        "    print(\"3. Ensure similarity calculation functions are defined\")\n",
        "    print(\"\\nNote: Comparison will test multiple similarity methods on a sample of images\")\n",
        "    print(\"and may take several minutes depending on the methods and sample size.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FAIR SELECTION METHODS COMPARISON\n",
            "================================================================================\n",
            "🎯 COMPARISON LOGIC:\n",
            "   1️⃣ Each method selects images using its OWN criteria\n",
            "   2️⃣ All selections evaluated using UNIFIED method (fair comparison)\n",
            "   3️⃣ Results show which selection strategy works best\n",
            "\n",
            "💡 Why this matters:\n",
            "   • Different methods have different similarity scales\n",
            "   • Using unified evaluation ensures fair comparison\n",
            "   • Shows which selection method truly picks most diverse images\n",
            "================================================================================\n",
            "✓ All required functions are available\n",
            "📋 Comparison Configuration:\n",
            "   Total Images per Test: 10\n",
            "   Images to Select: 3\n",
            "   Movies to Test: 5\n",
            "   🎯 Unified Evaluation Method: cnn_features\n",
            "\n",
            "📊 Process: Each method selects 3 images → All evaluated by cnn_features\n",
            "✅ This ensures fair comparison regardless of selection method's internal similarity scale!\n",
            "\n",
            "💡 Evaluation Method Suggestions:\n",
            "   • 'cnn_features' or 'clip_features': Best for semantic diversity assessment\n",
            "   • 'combined': Good balance of traditional methods\n",
            "   • 'histogram': Fast evaluation, focuses on color diversity\n",
            "   • Choose method that represents your diversity goals!\n",
            "\n",
            "Collecting sample images for comparison...\n",
            "Found 40 movies with sufficient images\n",
            "Selected 10 images from: French Twist (Gazon maudit)\n",
            "Selected 10 images from: Eat Drink Man Woman\n",
            "Selected 10 images from: Bad Boys\n",
            "Selected 10 images from: Dead Man Walking\n",
            "Selected 10 images from: Mighty Aphrodite\n",
            "\n",
            "🔬 Testing 6 selection methods\n",
            "📏 All results evaluated using: cnn_features\n",
            "📊 Testing on 5 image sets...\n",
            "\n",
            "🎯 Logic: Each method selects images → All evaluated by cnn_features → Fair comparison!\n",
            "\n",
            "📷 Testing on Movie 1: French Twist (Gazon maudit)\n",
            "   Selecting 3 most diverse images from 10 images\n",
            "   🔍 histogram (selection) → cnn_features (evaluation)...        Using similarity method: histogram\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.133\n",
            "   🔍 ssim (selection) → cnn_features (evaluation)...        Using similarity method: ssim\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.173\n",
            "   🔍 perceptual_hash (selection) → cnn_features (evaluation)...        Using similarity method: perceptual_hash\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.124\n",
            "   🔍 combined (selection) → cnn_features (evaluation)...        Using similarity method: combined\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.133\n",
            "   🔍 cnn_features (selection) → cnn_features (evaluation)...        Using similarity method: cnn_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.098\n",
            "   🔍 clip_features (selection) → cnn_features (evaluation)...        Using similarity method: clip_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.100\n",
            "\n",
            "📷 Testing on Movie 2: Eat Drink Man Woman\n",
            "   Selecting 3 most diverse images from 10 images\n",
            "   🔍 histogram (selection) → cnn_features (evaluation)...        Using similarity method: histogram\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.152\n",
            "   🔍 ssim (selection) → cnn_features (evaluation)...        Using similarity method: ssim\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.142\n",
            "   🔍 perceptual_hash (selection) → cnn_features (evaluation)...        Using similarity method: perceptual_hash\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.181\n",
            "   🔍 combined (selection) → cnn_features (evaluation)...        Using similarity method: combined\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.134\n",
            "   🔍 cnn_features (selection) → cnn_features (evaluation)...        Using similarity method: cnn_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.153\n",
            "   🔍 clip_features (selection) → cnn_features (evaluation)...        Using similarity method: clip_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.156\n",
            "\n",
            "📷 Testing on Movie 3: Bad Boys\n",
            "   Selecting 3 most diverse images from 10 images\n",
            "   🔍 histogram (selection) → cnn_features (evaluation)...        Using similarity method: histogram\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.066\n",
            "   🔍 ssim (selection) → cnn_features (evaluation)...        Using similarity method: ssim\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.090\n",
            "   🔍 perceptual_hash (selection) → cnn_features (evaluation)...        Using similarity method: perceptual_hash\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.090\n",
            "   🔍 combined (selection) → cnn_features (evaluation)...        Using similarity method: combined\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.066\n",
            "   🔍 cnn_features (selection) → cnn_features (evaluation)...        Using similarity method: cnn_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.078\n",
            "   🔍 clip_features (selection) → cnn_features (evaluation)...        Using similarity method: clip_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.065\n",
            "\n",
            "📷 Testing on Movie 4: Dead Man Walking\n",
            "   Selecting 3 most diverse images from 10 images\n",
            "   🔍 histogram (selection) → cnn_features (evaluation)...        Using similarity method: histogram\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.035\n",
            "   🔍 ssim (selection) → cnn_features (evaluation)...        Using similarity method: ssim\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.035\n",
            "   🔍 perceptual_hash (selection) → cnn_features (evaluation)...        Using similarity method: perceptual_hash\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.034\n",
            "   🔍 combined (selection) → cnn_features (evaluation)...        Using similarity method: combined\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.035\n",
            "   🔍 cnn_features (selection) → cnn_features (evaluation)...        Using similarity method: cnn_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.032\n",
            "   🔍 clip_features (selection) → cnn_features (evaluation)...        Using similarity method: clip_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.032\n",
            "\n",
            "📷 Testing on Movie 5: Mighty Aphrodite\n",
            "   Selecting 3 most diverse images from 10 images\n",
            "   🔍 histogram (selection) → cnn_features (evaluation)...        Using similarity method: histogram\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.152\n",
            "   🔍 ssim (selection) → cnn_features (evaluation)...        Using similarity method: ssim\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.169\n",
            "   🔍 perceptual_hash (selection) → cnn_features (evaluation)...        Using similarity method: perceptual_hash\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.042\n",
            "   🔍 combined (selection) → cnn_features (evaluation)...        Using similarity method: combined\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.169\n",
            "   🔍 cnn_features (selection) → cnn_features (evaluation)...        Using similarity method: cnn_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.042\n",
            "   🔍 clip_features (selection) → cnn_features (evaluation)...        Using similarity method: clip_features\n",
            "         Evaluating diversity using cnn_features...✓ Diversity: 0.042\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FAIR SELECTION EFFECTIVENESS COMPARISON\n",
            "================================================================================\n",
            "🎯 All results evaluated using unified method: cnn_features\n",
            "📊 This ensures fair comparison of selection effectiveness!\n",
            "\n",
            "🏆 SELECTION METHOD PERFORMANCE SUMMARY:\n",
            "--------------------------------------------------------------------------------\n",
            "selection_method  diversity_score_mean  diversity_score_std  avg_similarity_mean  avg_similarity_std  selection_time_mean  selection_time_std  movie_set_count\n",
            "   clip_features                0.0790               0.0501               0.9210              0.0501               3.1307              0.0650                5\n",
            "    cnn_features                0.0805               0.0483               0.9195              0.0483               3.0765              0.0270                5\n",
            "        combined                0.1076               0.0551               0.8924              0.0551               1.3985              0.0777                5\n",
            "       histogram                0.1077               0.0538               0.8923              0.0538               0.1033              0.0040                5\n",
            " perceptual_hash                0.0941               0.0610               0.9059              0.0610               0.1241              0.0049                5\n",
            "            ssim                0.1219               0.0587               0.8781              0.0587               1.1711              0.0941                5\n",
            "\n",
            "📊 DETAILED RESULTS BY MOVIE SET:\n",
            "(All diversity scores calculated using cnn_features)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Movie Set 1: French Twist (Gazon maudit)\n",
            "         method  diversity_score  avg_similarity selection_time\n",
            "      histogram           0.1332          0.8668          0.10s\n",
            "           ssim           0.1725          0.8275          1.11s\n",
            "perceptual_hash           0.1242          0.8758          0.12s\n",
            "       combined           0.1332          0.8668          1.32s\n",
            "   cnn_features           0.0984          0.9016          3.08s\n",
            "  clip_features           0.0998          0.9002          3.07s\n",
            "\n",
            "Movie Set 2: Eat Drink Man Woman\n",
            "         method  diversity_score  avg_similarity selection_time\n",
            "      histogram           0.1522          0.8478          0.11s\n",
            "           ssim           0.1424          0.8576          1.10s\n",
            "perceptual_hash           0.1809          0.8191          0.13s\n",
            "       combined           0.1339          0.8661          1.36s\n",
            "   cnn_features           0.1526          0.8474          3.11s\n",
            "  clip_features           0.1556          0.8444          3.11s\n",
            "\n",
            "Movie Set 3: Bad Boys\n",
            "         method  diversity_score  avg_similarity selection_time\n",
            "      histogram           0.0662          0.9338          0.10s\n",
            "           ssim           0.0901          0.9099          1.09s\n",
            "perceptual_hash           0.0901          0.9099          0.12s\n",
            "       combined           0.0662          0.9338          1.34s\n",
            "   cnn_features           0.0776          0.9224          3.06s\n",
            "  clip_features           0.0655          0.9345          3.24s\n",
            "\n",
            "Movie Set 4: Dead Man Walking\n",
            "         method  diversity_score  avg_similarity selection_time\n",
            "      histogram           0.0351          0.9649          0.10s\n",
            "           ssim           0.0351          0.9649          1.30s\n",
            "perceptual_hash           0.0335          0.9665          0.12s\n",
            "       combined           0.0351          0.9649          1.48s\n",
            "   cnn_features           0.0324          0.9676          3.09s\n",
            "  clip_features           0.0324          0.9676          3.11s\n",
            "\n",
            "Movie Set 5: Mighty Aphrodite\n",
            "         method  diversity_score  avg_similarity selection_time\n",
            "      histogram           0.1519          0.8481          0.10s\n",
            "           ssim           0.1694          0.8306          1.25s\n",
            "perceptual_hash           0.0418          0.9582          0.12s\n",
            "       combined           0.1694          0.8306          1.49s\n",
            "   cnn_features           0.0418          0.9582          3.04s\n",
            "  clip_features           0.0418          0.9582          3.12s\n",
            "\n",
            "🏆 SELECTION METHOD RANKINGS:\n",
            "(Based on cnn_features evaluation)\n",
            "--------------------------------------------------------------------------------\n",
            "         method  diversity_score  avg_similarity selection_time  rank_score\n",
            "      histogram           0.1077          0.8923          0.10s      1.6667\n",
            "           ssim           0.1219          0.8781          1.17s      1.6667\n",
            "perceptual_hash           0.0941          0.9059          0.12s      3.3333\n",
            "       combined           0.1076          0.8924          1.40s      3.3333\n",
            "   cnn_features           0.0805          0.9195          3.08s      5.0000\n",
            "  clip_features           0.0790          0.9210          3.13s      6.0000\n",
            "\n",
            "🥇 BEST SELECTION METHODS:\n",
            "(According to cnn_features evaluation)\n",
            "   🎯 Best Diversity: ssim (score: 0.1219)\n",
            "   ⚡ Fastest: histogram (0.10s)\n",
            "   🏆 Best Overall: histogram (rank score: 1.67)\n",
            "\n",
            "📈 CONSISTENCY ANALYSIS:\n",
            "--------------------------------------------------------------------------------\n",
            "Selection method consistency (lower std = more consistent):\n",
            "   cnn_features   : 0.0483\n",
            "   clip_features  : 0.0501\n",
            "   histogram      : 0.0538\n",
            "   combined       : 0.0551\n",
            "   ssim           : 0.0587\n",
            "   perceptual_hash: 0.0610\n",
            "\n",
            "💡 KEY INSIGHTS:\n",
            "--------------------------------------------------------------------------------\n",
            "• Best selection method (histogram) achieves 1.36x better diversity than worst (clip_features)\n",
            "• All diversity measurements use cnn_features for fair comparison\n",
            "• Results show which selection strategy works best according to cnn_features criteria\n",
            "\n",
            "📝 INTERPRETATION:\n",
            "--------------------------------------------------------------------------------\n",
            "• Diversity Score: Higher = better (1.0 = perfect diversity, 0.0 = all identical)\n",
            "• Avg Similarity: Lower = better (according to cnn_features standards)\n",
            "• Selection Time: How long each method takes to choose images\n",
            "• Rank Score: Lower = better overall performance\n",
            "• ALL diversity evaluations use cnn_features for fair comparison!\n",
            "\n",
            "💾 Results saved to: multimodal_data\\selection_methods_comparison\n",
            "   📊 Main results: selection_methods_comparison.csv\n",
            "   ✅ Successful only: successful_comparisons.csv\n",
            "   📋 Summary: comparison_summary.json\n",
            "   🎬 Sample info: sample_sets_info.json\n"
          ]
        }
      ],
      "source": [
        "# Optional: Compare different similarity methods' selection effectiveness\n",
        "# Set this to True to run the comparison\n",
        "RUN_COMPARISON = True  # Change to True to enable comparison\n",
        "\n",
        "if RUN_COMPARISON:\n",
        "    import time\n",
        "    import pandas as pd\n",
        "    import random\n",
        "    from statistics import mean, stdev\n",
        "    import itertools\n",
        "    import numpy as np\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(\"FAIR SELECTION METHODS COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"🎯 COMPARISON LOGIC:\")\n",
        "    print(\"   1️⃣ Each method selects images using its OWN criteria\")\n",
        "    print(\"   2️⃣ All selections evaluated using UNIFIED method (fair comparison)\")\n",
        "    print(\"   3️⃣ Results show which selection strategy works best\")\n",
        "    print()\n",
        "    print(\"💡 Why this matters:\")\n",
        "    print(\"   • Different methods have different similarity scales\")\n",
        "    print(\"   • Using unified evaluation ensures fair comparison\")\n",
        "    print(\"   • Shows which selection method truly picks most diverse images\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Check if required functions are available\n",
        "    required_functions = ['calculate_image_similarity', 'select_diverse_images']\n",
        "    missing_functions = []\n",
        "    \n",
        "    for func_name in required_functions:\n",
        "        if func_name not in globals():\n",
        "            missing_functions.append(func_name)\n",
        "    \n",
        "    if missing_functions:\n",
        "        print(f\"ERROR: Required functions not found: {missing_functions}\")\n",
        "        print(\"Please run the main image selection cell first to define all required functions\")\n",
        "        print(\"Set RUN_COMPARISON = False to disable this check\")\n",
        "    else:\n",
        "        print(\"✓ All required functions are available\")\n",
        "    \n",
        "    # Comparison configuration\n",
        "    COMPARISON_SAMPLE_SIZE = 10   # Total images to select from (need >5 for meaningful comparison)\n",
        "    SELECTION_TARGET = 3          # Number of images to select (same as SELECTED_IMAGES)\n",
        "    MAX_MOVIES_TO_TEST = 5        # Number of movies to test\n",
        "    \n",
        "    # 🎯 KEY SETTING: Unified evaluation method for fair comparison\n",
        "    EVALUATION_METHOD = \"cnn_features\"  # Options: \"histogram\", \"ssim\", \"perceptual_hash\", \"combined\", \"cnn_features\", \"clip_features\"\n",
        "    # This method will be used to evaluate ALL selection results for fair comparison\n",
        "    \n",
        "    print(f\"📋 Comparison Configuration:\")\n",
        "    print(f\"   Total Images per Test: {COMPARISON_SAMPLE_SIZE}\")\n",
        "    print(f\"   Images to Select: {SELECTION_TARGET}\")\n",
        "    print(f\"   Movies to Test: {MAX_MOVIES_TO_TEST}\")\n",
        "    print(f\"   🎯 Unified Evaluation Method: {EVALUATION_METHOD}\")\n",
        "    print()\n",
        "    print(f\"📊 Process: Each method selects {SELECTION_TARGET} images → All evaluated by {EVALUATION_METHOD}\")\n",
        "    print(f\"✅ This ensures fair comparison regardless of selection method's internal similarity scale!\")\n",
        "    print()\n",
        "    \n",
        "    # Configuration suggestions\n",
        "    print(\"💡 Evaluation Method Suggestions:\")\n",
        "    print(\"   • 'cnn_features' or 'clip_features': Best for semantic diversity assessment\")\n",
        "    print(\"   • 'combined': Good balance of traditional methods\")\n",
        "    print(\"   • 'histogram': Fast evaluation, focuses on color diversity\")\n",
        "    print(\"   • Choose method that represents your diversity goals!\")\n",
        "    print()\n",
        "\n",
        "    def collect_sample_images():\n",
        "        \"\"\"Collect sample images from processed movies for comparison\"\"\"\n",
        "        sample_image_sets = []\n",
        "        \n",
        "        # Check if movie feature data is available\n",
        "        try:\n",
        "            movie_data = globals().get('all_movie_features', None)\n",
        "            if movie_data is None:\n",
        "                print(\"ERROR: all_movie_features variable not found in global scope\")\n",
        "                print(\"Please run the main image selection cell first to load movie data\")\n",
        "                return None\n",
        "            \n",
        "            if not movie_data:\n",
        "                print(\"ERROR: all_movie_features is empty\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Cannot access movie feature data: {str(e)}\")\n",
        "            return None\n",
        "        \n",
        "        # Collect images from multiple movies\n",
        "        movies_with_images = [movie for movie in movie_data \n",
        "                            if movie.get('image_paths') and len(movie.get('image_paths', [])) >= COMPARISON_SAMPLE_SIZE]\n",
        "        \n",
        "        if len(movies_with_images) == 0:\n",
        "            print(\"ERROR: No movies with sufficient images found\")\n",
        "            print(f\"Need at least {COMPARISON_SAMPLE_SIZE} images per movie\")\n",
        "            return None\n",
        "        \n",
        "        print(f\"Found {len(movies_with_images)} movies with sufficient images\")\n",
        "        \n",
        "        # Select movies for testing\n",
        "        test_movies = random.sample(movies_with_images, \n",
        "                                  min(MAX_MOVIES_TO_TEST, len(movies_with_images)))\n",
        "        \n",
        "        for movie in test_movies:\n",
        "            valid_paths = [path for path in movie.get('image_paths', []) \n",
        "                         if os.path.exists(path)]\n",
        "            \n",
        "            if len(valid_paths) < COMPARISON_SAMPLE_SIZE:\n",
        "                print(f\"Warning: Movie {movie.get('movielens_title', 'Unknown')} has only {len(valid_paths)} valid images\")\n",
        "                continue\n",
        "            \n",
        "            # Select exactly COMPARISON_SAMPLE_SIZE images for this movie\n",
        "            selected_images = random.sample(valid_paths, COMPARISON_SAMPLE_SIZE)\n",
        "            sample_image_sets.append({\n",
        "                'movie_id': movie.get('movielens_id'),\n",
        "                'movie_title': movie.get('movielens_title', 'Unknown'),\n",
        "                'images': selected_images\n",
        "            })\n",
        "            \n",
        "            print(f\"Selected {len(selected_images)} images from: {movie.get('movielens_title', 'Unknown')}\")\n",
        "        \n",
        "        return sample_image_sets\n",
        "\n",
        "    def calculate_selection_diversity(selected_images, evaluation_method):\n",
        "        \"\"\"Calculate diversity metrics for selected images using unified evaluation method\"\"\"\n",
        "        if len(selected_images) < 2:\n",
        "            return {\n",
        "                'avg_similarity': 0.0,\n",
        "                'min_similarity': 0.0,\n",
        "                'max_similarity': 0.0,\n",
        "                'similarity_std': 0.0,\n",
        "                'total_comparisons': 0,\n",
        "                'diversity_score': 1.0\n",
        "            }\n",
        "        \n",
        "        similarities = []\n",
        "        \n",
        "        # Calculate pairwise similarities using UNIFIED evaluation method\n",
        "        print(f\"         Evaluating diversity using {evaluation_method}...\", end=\"\")\n",
        "        try:\n",
        "            for i in range(len(selected_images)):\n",
        "                for j in range(i + 1, len(selected_images)):\n",
        "                    sim = calculate_image_similarity(selected_images[i], selected_images[j], evaluation_method)\n",
        "                    # 🔧 FIX: Ensure consistent data type\n",
        "                    if hasattr(sim, 'item'):  # If it's a numpy scalar\n",
        "                        sim = float(sim.item())\n",
        "                    else:\n",
        "                        sim = float(sim)\n",
        "                    similarities.append(sim)\n",
        "            \n",
        "            if not similarities:\n",
        "                return {\n",
        "                    'avg_similarity': 0.0,\n",
        "                    'min_similarity': 0.0,\n",
        "                    'max_similarity': 0.0,\n",
        "                    'similarity_std': 0.0,\n",
        "                    'total_comparisons': 0,\n",
        "                    'diversity_score': 1.0\n",
        "                }\n",
        "            \n",
        "            # 🔧 FIX: Convert all values to regular Python floats\n",
        "            similarities = [float(s) for s in similarities]\n",
        "            \n",
        "            avg_sim = mean(similarities)\n",
        "            min_sim = min(similarities)\n",
        "            max_sim = max(similarities)\n",
        "            std_sim = stdev(similarities) if len(similarities) > 1 else 0.0\n",
        "            \n",
        "            # Diversity score: lower average similarity = higher diversity\n",
        "            # Normalize to 0-1 where 1 = most diverse (all similarities = 0)\n",
        "            diversity_score = 1.0 - avg_sim\n",
        "            \n",
        "            return {\n",
        "                'avg_similarity': float(avg_sim),\n",
        "                'min_similarity': float(min_sim),\n",
        "                'max_similarity': float(max_sim),\n",
        "                'similarity_std': float(std_sim),\n",
        "                'total_comparisons': len(similarities),\n",
        "                'diversity_score': float(diversity_score)\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\" Error: {str(e)}\")\n",
        "            return {\n",
        "                'avg_similarity': 1.0,\n",
        "                'min_similarity': 1.0,\n",
        "                'max_similarity': 1.0,\n",
        "                'similarity_std': 0.0,\n",
        "                'total_comparisons': 0,\n",
        "                'diversity_score': 0.0\n",
        "            }\n",
        "\n",
        "    def test_selection_methods():\n",
        "        \"\"\"Test different selection methods and compare their effectiveness\"\"\"\n",
        "        # 🔧 FIX: Declare as global to avoid UnboundLocalError\n",
        "        global EVALUATION_METHOD\n",
        "        \n",
        "        # Collect sample image sets\n",
        "        print(\"Collecting sample images for comparison...\")\n",
        "        sample_sets = collect_sample_images()\n",
        "        \n",
        "        if sample_sets is None:\n",
        "            print(\"SOLUTION: Please run the main image selection cell first to generate all_movie_features\")\n",
        "            return None, None\n",
        "        \n",
        "        if len(sample_sets) == 0:\n",
        "            print(\"ERROR: No valid image sets collected\")\n",
        "            return None, None\n",
        "        \n",
        "        # Define methods to test\n",
        "        methods_to_test = ['histogram', 'ssim', 'perceptual_hash', 'combined']\n",
        "        \n",
        "        # Add deep learning methods if available\n",
        "        if DEEP_LEARNING_AVAILABLE:\n",
        "            methods_to_test.extend(['cnn_features', 'clip_features'])\n",
        "        \n",
        "        # Check if evaluation method is available\n",
        "        if EVALUATION_METHOD not in methods_to_test and EVALUATION_METHOD in ['cnn_features', 'clip_features'] and not DEEP_LEARNING_AVAILABLE:\n",
        "            print(f\"WARNING: Evaluation method '{EVALUATION_METHOD}' not available\")\n",
        "            print(\"Falling back to 'combined' for evaluation\")\n",
        "            EVALUATION_METHOD = 'combined'\n",
        "        \n",
        "        print(f\"\\n🔬 Testing {len(methods_to_test)} selection methods\")\n",
        "        print(f\"📏 All results evaluated using: {EVALUATION_METHOD}\")\n",
        "        print(f\"📊 Testing on {len(sample_sets)} image sets...\")\n",
        "        print(f\"\\n🎯 Logic: Each method selects images → All evaluated by {EVALUATION_METHOD} → Fair comparison!\")\n",
        "        print()\n",
        "        \n",
        "        # Store results\n",
        "        all_results = []\n",
        "        \n",
        "        # Test each method on each image set\n",
        "        for set_idx, image_set in enumerate(sample_sets):\n",
        "            movie_title = image_set['movie_title']\n",
        "            images = image_set['images']\n",
        "            \n",
        "            print(f\"📷 Testing on Movie {set_idx + 1}: {movie_title}\")\n",
        "            print(f\"   Selecting {SELECTION_TARGET} most diverse images from {len(images)} images\")\n",
        "            \n",
        "            set_results = []\n",
        "            \n",
        "            for method in methods_to_test:\n",
        "                print(f\"   🔍 {method} (selection) → {EVALUATION_METHOD} (evaluation)...\", end=\" \")\n",
        "                \n",
        "                try:\n",
        "                    start_time = time.time()\n",
        "                    \n",
        "                    # STEP 1: Use the method to select diverse images (method's own criteria)\n",
        "                    selected_images = select_diverse_images(images, SELECTION_TARGET, method)\n",
        "                    \n",
        "                    selection_time = time.time() - start_time\n",
        "                    \n",
        "                    # STEP 2: Evaluate diversity using UNIFIED method (fair comparison)\n",
        "                    diversity_metrics = calculate_selection_diversity(selected_images, EVALUATION_METHOD)\n",
        "                    \n",
        "                    result = {\n",
        "                        'movie_set': set_idx + 1,\n",
        "                        'movie_title': movie_title,\n",
        "                        'selection_method': method,\n",
        "                        'evaluation_method': EVALUATION_METHOD,\n",
        "                        'selection_time': float(selection_time),\n",
        "                        'selected_count': len(selected_images),\n",
        "                        **diversity_metrics,\n",
        "                        'status': 'Success'\n",
        "                    }\n",
        "                    \n",
        "                    set_results.append(result)\n",
        "                    all_results.append(result)\n",
        "                    \n",
        "                    print(f\"✓ Diversity: {diversity_metrics['diversity_score']:.3f}\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    error_result = {\n",
        "                        'movie_set': set_idx + 1,\n",
        "                        'movie_title': movie_title,\n",
        "                        'selection_method': method,\n",
        "                        'evaluation_method': EVALUATION_METHOD,\n",
        "                        'selection_time': 0.0,\n",
        "                        'selected_count': 0,\n",
        "                        'avg_similarity': 1.0,\n",
        "                        'diversity_score': 0.0,\n",
        "                        'min_similarity': 1.0,\n",
        "                        'max_similarity': 1.0,\n",
        "                        'similarity_std': 0.0,\n",
        "                        'total_comparisons': 0,\n",
        "                        'status': f'Error: {str(e)[:50]}...'\n",
        "                    }\n",
        "                    set_results.append(error_result)\n",
        "                    all_results.append(error_result)\n",
        "                    print(f\"✗ Error: {str(e)}\")\n",
        "            \n",
        "            print()\n",
        "        \n",
        "        return all_results, sample_sets\n",
        "\n",
        "    def display_selection_comparison(results):\n",
        "        \"\"\"Display selection comparison results\"\"\"\n",
        "        if not results:\n",
        "            return None\n",
        "            \n",
        "        df = pd.DataFrame(results)\n",
        "        successful_results = df[df['status'] == 'Success'].copy()\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FAIR SELECTION EFFECTIVENESS COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"🎯 All results evaluated using unified method: {EVALUATION_METHOD}\")\n",
        "        print(f\"📊 This ensures fair comparison of selection effectiveness!\")\n",
        "        \n",
        "        if len(successful_results) == 0:\n",
        "            print(\"No successful results to display\")\n",
        "            return df\n",
        "        \n",
        "        # 1. Method Performance Summary\n",
        "        print(\"\\n🏆 SELECTION METHOD PERFORMANCE SUMMARY:\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        method_summary = successful_results.groupby('selection_method').agg({\n",
        "            'diversity_score': ['mean', 'std'],\n",
        "            'avg_similarity': ['mean', 'std'],\n",
        "            'selection_time': ['mean', 'std'],\n",
        "            'movie_set': 'count'\n",
        "        }).round(4)\n",
        "        \n",
        "        # Flatten column names\n",
        "        method_summary.columns = ['_'.join(col).strip() for col in method_summary.columns]\n",
        "        method_summary = method_summary.reset_index()\n",
        "        \n",
        "        print(method_summary.to_string(index=False))\n",
        "        \n",
        "        # 2. Detailed Results by Movie Set\n",
        "        print(f\"\\n📊 DETAILED RESULTS BY MOVIE SET:\")\n",
        "        print(f\"(All diversity scores calculated using {EVALUATION_METHOD})\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        for movie_set in sorted(successful_results['movie_set'].unique()):\n",
        "            movie_data = successful_results[successful_results['movie_set'] == movie_set]\n",
        "            movie_title = movie_data.iloc[0]['movie_title']\n",
        "            \n",
        "            print(f\"\\nMovie Set {movie_set}: {movie_title}\")\n",
        "            display_cols = ['selection_method', 'diversity_score', 'avg_similarity', 'selection_time']\n",
        "            movie_display = movie_data[display_cols].copy()\n",
        "            movie_display['selection_time'] = movie_display['selection_time'].apply(lambda x: f\"{x:.2f}s\")\n",
        "            movie_display = movie_display.rename(columns={'selection_method': 'method'})\n",
        "            print(movie_display.to_string(index=False, float_format='%.4f'))\n",
        "        \n",
        "        # 3. Method Rankings\n",
        "        print(f\"\\n🏆 SELECTION METHOD RANKINGS:\")\n",
        "        print(f\"(Based on {EVALUATION_METHOD} evaluation)\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        # Calculate average performance across all sets\n",
        "        method_avg = successful_results.groupby('selection_method').agg({\n",
        "            'diversity_score': 'mean',\n",
        "            'selection_time': 'mean',\n",
        "            'avg_similarity': 'mean'\n",
        "        }).reset_index()\n",
        "        \n",
        "        # Rank methods\n",
        "        method_avg['diversity_rank'] = method_avg['diversity_score'].rank(ascending=False)  # Higher diversity = better\n",
        "        method_avg['speed_rank'] = method_avg['selection_time'].rank(ascending=True)       # Faster = better\n",
        "        method_avg['similarity_rank'] = method_avg['avg_similarity'].rank(ascending=True)  # Lower similarity = better\n",
        "        \n",
        "        # Combined ranking\n",
        "        method_avg['combined_score'] = (method_avg['diversity_rank'] + method_avg['speed_rank'] + method_avg['similarity_rank']) / 3\n",
        "        method_avg = method_avg.sort_values('combined_score')\n",
        "        \n",
        "        ranking_display = method_avg[['selection_method', 'diversity_score', 'avg_similarity', 'selection_time', 'combined_score']].copy()\n",
        "        ranking_display['selection_time'] = ranking_display['selection_time'].apply(lambda x: f\"{x:.2f}s\")\n",
        "        ranking_display = ranking_display.rename(columns={'combined_score': 'rank_score', 'selection_method': 'method'})\n",
        "        \n",
        "        print(ranking_display.to_string(index=False, float_format='%.4f'))\n",
        "        \n",
        "        # 4. Best Performers\n",
        "        print(f\"\\n🥇 BEST SELECTION METHODS:\")\n",
        "        print(f\"(According to {EVALUATION_METHOD} evaluation)\")\n",
        "        best_diversity = method_avg.loc[method_avg['diversity_score'].idxmax()]\n",
        "        fastest = method_avg.loc[method_avg['selection_time'].idxmin()]\n",
        "        best_overall = method_avg.iloc[0]  # Already sorted by combined_score\n",
        "        \n",
        "        print(f\"   🎯 Best Diversity: {best_diversity['selection_method']} (score: {best_diversity['diversity_score']:.4f})\")\n",
        "        print(f\"   ⚡ Fastest: {fastest['selection_method']} ({fastest['selection_time']:.2f}s)\")\n",
        "        print(f\"   🏆 Best Overall: {best_overall['selection_method']} (rank score: {best_overall['combined_score']:.2f})\")\n",
        "        \n",
        "        # 5. Consistency Analysis\n",
        "        print(f\"\\n📈 CONSISTENCY ANALYSIS:\")\n",
        "        print(\"-\" * 80)\n",
        "        method_consistency = successful_results.groupby('selection_method')['diversity_score'].std().sort_values()\n",
        "        print(\"Selection method consistency (lower std = more consistent):\")\n",
        "        for method, std_val in method_consistency.items():\n",
        "            print(f\"   {method:15}: {std_val:.4f}\")\n",
        "        \n",
        "        # 6. Key insights\n",
        "        print(f\"\\n💡 KEY INSIGHTS:\")\n",
        "        print(\"-\" * 80)\n",
        "        best_method = best_overall['selection_method']\n",
        "        worst_method = method_avg.iloc[-1]['selection_method']\n",
        "        improvement = best_overall['diversity_score'] / method_avg.iloc[-1]['diversity_score']\n",
        "        \n",
        "        print(f\"• Best selection method ({best_method}) achieves {improvement:.2f}x better diversity than worst ({worst_method})\")\n",
        "        print(f\"• All diversity measurements use {EVALUATION_METHOD} for fair comparison\")\n",
        "        print(f\"• Results show which selection strategy works best according to {EVALUATION_METHOD} criteria\")\n",
        "        \n",
        "        print(f\"\\n📝 INTERPRETATION:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(\"• Diversity Score: Higher = better (1.0 = perfect diversity, 0.0 = all identical)\")\n",
        "        print(f\"• Avg Similarity: Lower = better (according to {EVALUATION_METHOD} standards)\")\n",
        "        print(\"• Selection Time: How long each method takes to choose images\")\n",
        "        print(\"• Rank Score: Lower = better overall performance\")\n",
        "        print(f\"• ALL diversity evaluations use {EVALUATION_METHOD} for fair comparison!\")\n",
        "        \n",
        "        return df\n",
        "\n",
        "    def save_selection_comparison(results, sample_sets):\n",
        "        \"\"\"Save selection comparison results to organized subfolder\"\"\"\n",
        "        try:\n",
        "            if not results:\n",
        "                return\n",
        "            \n",
        "            # 🔧 FIX: Create organized subfolder structure\n",
        "            comparison_dir = os.path.join(DATA_DIR, 'selection_methods_comparison')\n",
        "            os.makedirs(comparison_dir, exist_ok=True)\n",
        "            \n",
        "            results_df = pd.DataFrame(results)\n",
        "            \n",
        "            # Save main results\n",
        "            results_file = os.path.join(comparison_dir, 'selection_methods_comparison.csv')\n",
        "            results_df.to_csv(results_file, index=False)\n",
        "            \n",
        "            # Save successful results only\n",
        "            successful_df = results_df[results_df['status'] == 'Success']\n",
        "            if len(successful_df) > 0:\n",
        "                successful_file = os.path.join(comparison_dir, 'successful_comparisons.csv')\n",
        "                successful_df.to_csv(successful_file, index=False)\n",
        "            \n",
        "            # Create detailed summary\n",
        "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            summary_info = {\n",
        "                'comparison_timestamp': timestamp,\n",
        "                'comparison_type': 'Fair Selection Effectiveness',\n",
        "                'evaluation_method_used': EVALUATION_METHOD,\n",
        "                'configuration': {\n",
        "                    'total_image_sets': len(sample_sets),\n",
        "                    'images_per_set': COMPARISON_SAMPLE_SIZE,\n",
        "                    'selection_target': SELECTION_TARGET,\n",
        "                    'max_movies_tested': MAX_MOVIES_TO_TEST\n",
        "                },\n",
        "                'results_summary': {\n",
        "                    'selection_methods_tested': list(results_df['selection_method'].unique()),\n",
        "                    'total_tests': len(results),\n",
        "                    'successful_tests': len(successful_df),\n",
        "                    'failed_tests': len(results) - len(successful_df)\n",
        "                },\n",
        "                'methodology': 'Each method selects images using own criteria, all evaluated using unified method for fair comparison',\n",
        "                'files_created': [\n",
        "                    'selection_methods_comparison.csv',\n",
        "                    'successful_comparisons.csv' if len(successful_df) > 0 else None,\n",
        "                    'comparison_summary.json'\n",
        "                ]\n",
        "            }\n",
        "            \n",
        "            # Add performance summary if we have successful results\n",
        "            if len(successful_df) > 0:\n",
        "                method_performance = successful_df.groupby('selection_method').agg({\n",
        "                    'diversity_score': 'mean',\n",
        "                    'selection_time': 'mean',\n",
        "                    'avg_similarity': 'mean'\n",
        "                }).to_dict()\n",
        "                summary_info['performance_summary'] = method_performance\n",
        "            \n",
        "            summary_file = os.path.join(comparison_dir, 'comparison_summary.json')\n",
        "            with open(summary_file, 'w') as f:\n",
        "                json.dump(summary_info, f, indent=2, default=str)\n",
        "            \n",
        "            # Save sample info\n",
        "            sample_info = {\n",
        "                'sample_sets': [\n",
        "                    {\n",
        "                        'movie_id': s.get('movie_id'),\n",
        "                        'movie_title': s.get('movie_title'),\n",
        "                        'image_count': len(s.get('images', []))\n",
        "                    }\n",
        "                    for s in sample_sets\n",
        "                ]\n",
        "            }\n",
        "            sample_file = os.path.join(comparison_dir, 'sample_sets_info.json')\n",
        "            with open(sample_file, 'w') as f:\n",
        "                json.dump(sample_info, f, indent=2)\n",
        "            \n",
        "            print(f\"\\n💾 Results saved to: {comparison_dir}\")\n",
        "            print(f\"   📊 Main results: selection_methods_comparison.csv\")\n",
        "            if len(successful_df) > 0:\n",
        "                print(f\"   ✅ Successful only: successful_comparisons.csv\")\n",
        "            print(f\"   📋 Summary: comparison_summary.json\")\n",
        "            print(f\"   🎬 Sample info: sample_sets_info.json\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Run the comparison only if all required functions are available\n",
        "    if not missing_functions:\n",
        "        try:\n",
        "            comparison_result = test_selection_methods()\n",
        "            \n",
        "            if comparison_result[0] is None:\n",
        "                print(\"\\nComparison aborted due to data availability issues.\")\n",
        "            else:\n",
        "                results, sample_sets = comparison_result\n",
        "                comparison_df = display_selection_comparison(results)\n",
        "                save_selection_comparison(results, sample_sets)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Comparison failed: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"Fair selection methods comparison is disabled.\")\n",
        "    print(\"To enable comparison, set RUN_COMPARISON = True\")\n",
        "    print(\"\\nPrerequisites:\")\n",
        "    print(\"1. Run the main image selection cell first\")\n",
        "    print(\"2. Ensure all_movie_features variable is populated\")\n",
        "    print(\"3. Ensure similarity calculation functions are defined\")\n",
        "    print(\"\\n🎯 This comparison will:\")\n",
        "    print(\"• Test each method's ability to select diverse images\")\n",
        "    print(\"• Use UNIFIED evaluation method for fair comparison\")\n",
        "    print(\"• Show which selection strategy works best\")\n",
        "    print(\"• Provide rankings based on actual selection effectiveness\")\n",
        "    print(\"\\n💡 Key advantage:\")\n",
        "    print(\"• Eliminates bias from different similarity scales\")\n",
        "    print(\"• Fair comparison of selection effectiveness\")\n",
        "    print(\"• Results you can trust for choosing best method!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ViT Image Feature Extraction\n",
            "==================================================\n",
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ViT model loaded successfully: google/vit-base-patch16-224\n",
            "\n",
            "Starting ViT feature extraction for 25 movies\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:   4%|▍         | 1/25 [00:00<00:10,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 1. Toy Story: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:   8%|▊         | 2/25 [00:00<00:08,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 2. GoldenEye: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  12%|█▏        | 3/25 [00:01<00:08,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 3. Four Rooms: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  16%|█▌        | 4/25 [00:01<00:07,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 4. Get Shorty: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  20%|██        | 5/25 [00:01<00:07,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 5. Copycat: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  24%|██▍       | 6/25 [00:02<00:06,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 6. Shanghai Triad (Yao a yao yao dao waipo qiao): feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  28%|██▊       | 7/25 [00:02<00:06,  2.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 7. Twelve Monkeys: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  32%|███▏      | 8/25 [00:02<00:06,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 8. Babe: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  36%|███▌      | 9/25 [00:03<00:05,  2.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 9. Dead Man Walking: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  40%|████      | 10/25 [00:03<00:05,  2.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 10. Richard III: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  44%|████▍     | 11/25 [00:04<00:05,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 11. Seven (Se7en): feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  48%|████▊     | 12/25 [00:04<00:04,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 12. Usual Suspects, The: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  52%|█████▏    | 13/25 [00:04<00:04,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 13. Mighty Aphrodite: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  56%|█████▌    | 14/25 [00:05<00:03,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 14. Postino, Il: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  60%|██████    | 15/25 [00:05<00:03,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 15. Mr. Holland's Opus: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  64%|██████▍   | 16/25 [00:05<00:03,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 16. French Twist (Gazon maudit): feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  68%|██████▊   | 17/25 [00:06<00:02,  2.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 17. From Dusk Till Dawn: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  72%|███████▏  | 18/25 [00:06<00:02,  3.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 18. White Balloon, The: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  76%|███████▌  | 19/25 [00:06<00:02,  2.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 19. Antonia's Line: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  80%|████████  | 20/25 [00:07<00:01,  2.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 20. Angels and Insects: feature dimension 768\n",
            "   SUCCESS: 21. Muppet Treasure Island: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  88%|████████▊ | 22/25 [00:07<00:00,  3.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 22. Braveheart: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  92%|█████████▏| 23/25 [00:07<00:00,  3.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 23. Taxi Driver: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features:  96%|█████████▌| 24/25 [00:08<00:00,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 24. Rumble in the Bronx: feature dimension 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ViT features: 100%|██████████| 25/25 [00:08<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUCCESS: 25. Birdcage, The: feature dimension 768\n",
            "\n",
            "ViT feature extraction statistics:\n",
            "   Successfully processed movies: 25\n",
            "   Feature dimension: 768\n",
            "   Feature matrix shape: (25, 768)\n",
            "   Feature matrix saved: multimodal_data\\vit_features_matrix.npy\n",
            "   Mapping file saved: multimodal_data\\vit_movie_mapping.json\n",
            "   Updated feature data saved: multimodal_data\\movie_features_with_vit.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ViT image feature extraction\n",
        "print(\"ViT Image Feature Extraction\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "class ViTFeatureExtractor:\n",
        "    def __init__(self, model_name='google/vit-base-patch16-224'):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        \n",
        "        try:\n",
        "            # Load ViT model and processor\n",
        "            self.processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "            self.model = ViTModel.from_pretrained(model_name)\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "            print(f\"ViT model loaded successfully: {model_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: ViT model loading failed: {str(e)}\")\n",
        "            self.model = None\n",
        "    \n",
        "    def extract_image_features(self, image_path):\n",
        "        \"\"\"Extract ViT features from a single image\"\"\"\n",
        "        if self.model is None:\n",
        "            return None\n",
        "        \n",
        "        try:\n",
        "            # Load and preprocess image\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            inputs = self.processor(images=image, return_tensors=\"pt\")\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "            \n",
        "            # Extract features\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                # Use [CLS] token features as image representation\n",
        "                image_features = outputs.last_hidden_state[:, 0, :].cpu().numpy().flatten()\n",
        "            \n",
        "            return image_features\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"   ERROR: Feature extraction failed ({image_path}): {str(e)}\")\n",
        "            return None\n",
        "    \n",
        "    def extract_movie_features(self, image_paths):\n",
        "        \"\"\"Extract and fuse features from all movie images\"\"\"\n",
        "        if not image_paths:\n",
        "            return None\n",
        "        \n",
        "        features_list = []\n",
        "        \n",
        "        for image_path in image_paths:\n",
        "            if os.path.exists(image_path):\n",
        "                features = self.extract_image_features(image_path)\n",
        "                if features is not None:\n",
        "                    features_list.append(features)\n",
        "        \n",
        "        if not features_list:\n",
        "            return None\n",
        "        \n",
        "        # Fuse multiple image features (average pooling)\n",
        "        combined_features = np.mean(features_list, axis=0)\n",
        "        return combined_features\n",
        "\n",
        "# Initialize ViT feature extractor\n",
        "vit_extractor = ViTFeatureExtractor()\n",
        "\n",
        "# Extract ViT features for all movies\n",
        "if 'all_movie_features' in locals() and all_movie_features and vit_extractor.model is not None:\n",
        "    print(f\"\\nStarting ViT feature extraction for {len(all_movie_features)} movies\")\n",
        "    \n",
        "    vit_features_matrix = []\n",
        "    vit_movie_ids = []\n",
        "    success_count = 0\n",
        "    \n",
        "    for movie_features in tqdm(all_movie_features, desc=\"Extracting ViT features\"):\n",
        "        movie_id = movie_features['movielens_id']\n",
        "        title = movie_features['movielens_title']\n",
        "        \n",
        "        # Use selected images\n",
        "        selected_paths = movie_features.get('selected_image_paths', [])\n",
        "        \n",
        "        if not selected_paths:\n",
        "            print(f\"   WARNING: {movie_id}. {title}: No selected images\")\n",
        "            continue\n",
        "        \n",
        "        # Extract features\n",
        "        vit_features = vit_extractor.extract_movie_features(selected_paths)\n",
        "        \n",
        "        if vit_features is not None:\n",
        "            vit_features_matrix.append(vit_features)\n",
        "            vit_movie_ids.append(movie_id)\n",
        "            \n",
        "            # Update movie feature data\n",
        "            movie_features['vit_features'] = vit_features.tolist()\n",
        "            movie_features['vit_feature_dim'] = len(vit_features)\n",
        "            \n",
        "            success_count += 1\n",
        "            print(f\"   SUCCESS: {movie_id}. {title}: feature dimension {len(vit_features)}\")\n",
        "        else:\n",
        "            print(f\"   ERROR: {movie_id}. {title}: ViT feature extraction failed\")\n",
        "    \n",
        "    # Convert to numpy array and save\n",
        "    if vit_features_matrix:\n",
        "        vit_features_array = np.array(vit_features_matrix)\n",
        "        \n",
        "        # Save ViT feature matrix\n",
        "        vit_features_file = os.path.join(DATA_DIR, 'vit_features_matrix.npy')\n",
        "        np.save(vit_features_file, vit_features_array)\n",
        "        \n",
        "        # Save movie ID mapping\n",
        "        vit_mapping_file = os.path.join(DATA_DIR, 'vit_movie_mapping.json')\n",
        "        with open(vit_mapping_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({'movie_ids': vit_movie_ids, 'feature_dim': len(vit_features_matrix[0])}, f)\n",
        "        \n",
        "        print(f\"\\nViT feature extraction statistics:\")\n",
        "        print(f\"   Successfully processed movies: {success_count}\")\n",
        "        print(f\"   Feature dimension: {vit_features_array.shape[1]}\")\n",
        "        print(f\"   Feature matrix shape: {vit_features_array.shape}\")\n",
        "        print(f\"   Feature matrix saved: {vit_features_file}\")\n",
        "        print(f\"   Mapping file saved: {vit_mapping_file}\")\n",
        "        \n",
        "        # Save updated movie features\n",
        "        updated_features_file = os.path.join(DATA_DIR, 'movie_features_with_vit.json')\n",
        "        with open(updated_features_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(all_movie_features, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"   Updated feature data saved: {updated_features_file}\")\n",
        "    else:\n",
        "        print(\"ERROR: No ViT features extracted successfully\")\n",
        "else:\n",
        "    print(\"ERROR: ViT model not loaded or no movie data available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT Text Feature Extraction\n",
            "==================================================\n",
            "Using device: cpu\n",
            "BERT model loaded successfully: bert-base-uncased\n",
            "\n",
            "Starting BERT text feature extraction for 25 movies\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing 1. Toy Story\n",
            "     Overview length: 303 characters\n",
            "     Tagline length: 47 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:   4%|▍         | 1/25 [00:00<00:07,  3.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 2. GoldenEye\n",
            "     Overview length: 371 characters\n",
            "     Tagline length: 36 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:   8%|▊         | 2/25 [00:00<00:06,  3.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 3. Four Rooms\n",
            "     Overview length: 237 characters\n",
            "     Tagline length: 155 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  12%|█▏        | 3/25 [00:00<00:05,  3.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 4. Get Shorty\n",
            "     Overview length: 367 characters\n",
            "     Tagline length: 22 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  16%|█▌        | 4/25 [00:01<00:05,  4.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 5. Copycat\n",
            "     Overview length: 139 characters\n",
            "     Tagline length: 142 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  20%|██        | 5/25 [00:01<00:04,  4.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 6. Shanghai Triad (Yao a yao yao dao waipo qiao)\n",
            "     Overview length: 271 characters\n",
            "     Tagline length: 68 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  24%|██▍       | 6/25 [00:01<00:04,  4.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 7. Twelve Monkeys\n",
            "     Overview length: 536 characters\n",
            "     Tagline length: 22 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  28%|██▊       | 7/25 [00:01<00:04,  4.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 8. Babe\n",
            "     Overview length: 383 characters\n",
            "     Tagline length: 29 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  36%|███▌      | 9/25 [00:02<00:03,  5.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 9. Dead Man Walking\n",
            "     Overview length: 147 characters\n",
            "     Tagline length: 0 characters\n",
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 10. Richard III\n",
            "     Overview length: 442 characters\n",
            "     Tagline length: 37 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  40%|████      | 10/25 [00:02<00:03,  4.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 11. Seven (Se7en)\n",
            "     Overview length: 389 characters\n",
            "     Tagline length: 37 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  44%|████▍     | 11/25 [00:02<00:02,  4.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 12. Usual Suspects, The\n",
            "     Overview length: 409 characters\n",
            "     Tagline length: 44 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  48%|████▊     | 12/25 [00:02<00:02,  4.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 13. Mighty Aphrodite\n",
            "     Overview length: 419 characters\n",
            "     Tagline length: 75 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  52%|█████▏    | 13/25 [00:02<00:02,  4.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 14. Postino, Il\n",
            "     Overview length: 127 characters\n",
            "     Tagline length: 20 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  56%|█████▌    | 14/25 [00:03<00:02,  4.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 15. Mr. Holland's Opus\n",
            "     Overview length: 340 characters\n",
            "     Tagline length: 71 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  60%|██████    | 15/25 [00:03<00:02,  4.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 16. French Twist (Gazon maudit)\n",
            "     Overview length: 157 characters\n",
            "     Tagline length: 58 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  64%|██████▍   | 16/25 [00:03<00:02,  4.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 17. From Dusk Till Dawn\n",
            "     Overview length: 163 characters\n",
            "     Tagline length: 94 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  72%|███████▏  | 18/25 [00:04<00:01,  5.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 18. White Balloon, The\n",
            "     Overview length: 125 characters\n",
            "     Tagline length: 0 characters\n",
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 19. Antonia's Line\n",
            "     Overview length: 424 characters\n",
            "     Tagline length: 64 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  76%|███████▌  | 19/25 [00:04<00:01,  4.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 20. Angels and Insects\n",
            "     Overview length: 438 characters\n",
            "     Tagline length: 65 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  80%|████████  | 20/25 [00:04<00:01,  4.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 21. Muppet Treasure Island\n",
            "     Overview length: 397 characters\n",
            "     Tagline length: 27 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  84%|████████▍ | 21/25 [00:04<00:00,  4.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 22. Braveheart\n",
            "     Overview length: 258 characters\n",
            "     Tagline length: 43 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  88%|████████▊ | 22/25 [00:04<00:00,  4.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 23. Taxi Driver\n",
            "     Overview length: 165 characters\n",
            "     Tagline length: 143 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  92%|█████████▏| 23/25 [00:05<00:00,  4.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 24. Rumble in the Bronx\n",
            "     Overview length: 397 characters\n",
            "     Tagline length: 31 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features:  96%|█████████▌| 24/25 [00:05<00:00,  4.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "   Processing 25. Birdcage, The\n",
            "     Overview length: 567 characters\n",
            "     Tagline length: 16 characters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting BERT features: 100%|██████████| 25/25 [00:05<00:00,  4.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     SUCCESS: BERT feature dimension: 768\n",
            "\n",
            "BERT feature extraction statistics:\n",
            "   Successfully processed movies: 25\n",
            "   Feature dimension: 768\n",
            "   Feature matrix shape: (25, 768)\n",
            "   Feature matrix saved: multimodal_data\\bert_features_matrix.npy\n",
            "   Mapping file saved: multimodal_data\\bert_movie_mapping.json\n",
            "   Updated feature data saved: multimodal_data\\movie_features_with_bert.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# BERT text feature extraction\n",
        "print(\"BERT Text Feature Extraction\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "class BERTFeatureExtractor:\n",
        "    def __init__(self, model_name='bert-base-uncased'):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        \n",
        "        try:\n",
        "            # Load BERT model and tokenizer\n",
        "            self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "            self.model = BertModel.from_pretrained(model_name)\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "            print(f\"BERT model loaded successfully: {model_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: BERT model loading failed: {str(e)}\")\n",
        "            self.model = None\n",
        "    \n",
        "    def extract_text_features(self, text, max_length=512):\n",
        "        \"\"\"Extract BERT features from text\"\"\"\n",
        "        if self.model is None or not text or text.strip() == \"\":\n",
        "            return None\n",
        "        \n",
        "        try:\n",
        "            # Text preprocessing and tokenization\n",
        "            inputs = self.tokenizer(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=max_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            \n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "            \n",
        "            # Extract features\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                # Use [CLS] token features as sentence representation\n",
        "                text_features = outputs.last_hidden_state[:, 0, :].cpu().numpy().flatten()\n",
        "            \n",
        "            return text_features\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"   ERROR: Text feature extraction failed: {str(e)}\")\n",
        "            return None\n",
        "    \n",
        "    def extract_movie_text_features(self, overview, tagline):\n",
        "        \"\"\"Extract movie text features (overview + tagline)\"\"\"\n",
        "        features_list = []\n",
        "        \n",
        "        # Extract overview features\n",
        "        if overview and overview.strip():\n",
        "            overview_features = self.extract_text_features(overview)\n",
        "            if overview_features is not None:\n",
        "                features_list.append(overview_features)\n",
        "        \n",
        "        # Extract tagline features\n",
        "        if tagline and tagline.strip():\n",
        "            tagline_features = self.extract_text_features(tagline)\n",
        "            if tagline_features is not None:\n",
        "                features_list.append(tagline_features)\n",
        "        \n",
        "        if not features_list:\n",
        "            return None\n",
        "        \n",
        "        # Average pooling to fuse features\n",
        "        combined_features = np.mean(features_list, axis=0)\n",
        "        return combined_features\n",
        "\n",
        "# Initialize BERT feature extractor\n",
        "bert_extractor = BERTFeatureExtractor()\n",
        "\n",
        "# Extract BERT text features for all movies\n",
        "if 'all_movie_features' in locals() and all_movie_features and bert_extractor.model is not None:\n",
        "    print(f\"\\nStarting BERT text feature extraction for {len(all_movie_features)} movies\")\n",
        "    \n",
        "    bert_features_matrix = []\n",
        "    bert_movie_ids = []\n",
        "    success_count = 0\n",
        "    \n",
        "    for movie_features in tqdm(all_movie_features, desc=\"Extracting BERT features\"):\n",
        "        movie_id = movie_features['movielens_id']\n",
        "        title = movie_features['movielens_title']\n",
        "        overview = movie_features.get('overview', '')\n",
        "        tagline = movie_features.get('tagline', '')\n",
        "        \n",
        "        print(f\"   Processing {movie_id}. {title}\")\n",
        "        print(f\"     Overview length: {len(overview) if overview else 0} characters\")\n",
        "        print(f\"     Tagline length: {len(tagline) if tagline else 0} characters\")\n",
        "        \n",
        "        # Extract text features\n",
        "        bert_features = bert_extractor.extract_movie_text_features(overview, tagline)\n",
        "        \n",
        "        if bert_features is not None:\n",
        "            bert_features_matrix.append(bert_features)\n",
        "            bert_movie_ids.append(movie_id)\n",
        "            \n",
        "            # Update movie feature data\n",
        "            movie_features['bert_features'] = bert_features.tolist()\n",
        "            movie_features['bert_feature_dim'] = len(bert_features)\n",
        "            movie_features['text_length'] = len(overview) + len(tagline)\n",
        "            \n",
        "            success_count += 1\n",
        "            print(f\"     SUCCESS: BERT feature dimension: {len(bert_features)}\")\n",
        "        else:\n",
        "            print(f\"     ERROR: BERT feature extraction failed\")\n",
        "    \n",
        "    # Convert to numpy array and save\n",
        "    if bert_features_matrix:\n",
        "        bert_features_array = np.array(bert_features_matrix)\n",
        "        \n",
        "        # Save BERT feature matrix\n",
        "        bert_features_file = os.path.join(DATA_DIR, 'bert_features_matrix.npy')\n",
        "        np.save(bert_features_file, bert_features_array)\n",
        "        \n",
        "        # Save movie ID mapping\n",
        "        bert_mapping_file = os.path.join(DATA_DIR, 'bert_movie_mapping.json')\n",
        "        with open(bert_mapping_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({'movie_ids': bert_movie_ids, 'feature_dim': len(bert_features_matrix[0])}, f)\n",
        "        \n",
        "        print(f\"\\nBERT feature extraction statistics:\")\n",
        "        print(f\"   Successfully processed movies: {success_count}\")\n",
        "        print(f\"   Feature dimension: {bert_features_array.shape[1]}\")\n",
        "        print(f\"   Feature matrix shape: {bert_features_array.shape}\")\n",
        "        print(f\"   Feature matrix saved: {bert_features_file}\")\n",
        "        print(f\"   Mapping file saved: {bert_mapping_file}\")\n",
        "        \n",
        "        # Save updated movie features\n",
        "        updated_features_file = os.path.join(DATA_DIR, 'movie_features_with_bert.json')\n",
        "        with open(updated_features_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(all_movie_features, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"   Updated feature data saved: {updated_features_file}\")\n",
        "    else:\n",
        "        print(\"ERROR: No BERT features extracted successfully\")\n",
        "else:\n",
        "    print(\"ERROR: BERT model not loaded or no movie data available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cast & Crew Statistical Feature Engineering\n",
            "==================================================\n",
            "Starting cast & crew feature extraction for 25 movies\n",
            "Cast & crew statistics:\n",
            "   Total directors: 24 people\n",
            "   Total cast: 232 people\n",
            "   Selected high-frequency directors: 24 people\n",
            "   Selected high-frequency cast: 50 people\n",
            "\n",
            "TOP 10 high-frequency directors:\n",
            "    1. Martin Campbell: 2 movies\n",
            "    2. John Lasseter: 1 movies\n",
            "    3. Barry Sonnenfeld: 1 movies\n",
            "    4. Jon Amiel: 1 movies\n",
            "    5. Zhang Yimou: 1 movies\n",
            "    6. Terry Gilliam: 1 movies\n",
            "    7. Chris Noonan: 1 movies\n",
            "    8. Tim Robbins: 1 movies\n",
            "    9. Richard Loncraine: 1 movies\n",
            "   10. David Fincher: 1 movies\n",
            "\n",
            "TOP 10 high-frequency cast:\n",
            "    1. Pierce Brosnan: 2 movies\n",
            "    2. Sean Bean: 2 movies\n",
            "    3. Izabella Scorupco: 2 movies\n",
            "    4. Famke Janssen: 2 movies\n",
            "    5. Joe Don Baker: 2 movies\n",
            "    6. Judi Dench: 2 movies\n",
            "    7. Robbie Coltrane: 2 movies\n",
            "    8. Tchéky Karyo: 2 movies\n",
            "    9. Gottfried John: 2 movies\n",
            "   10. Alan Cumming: 2 movies\n",
            "\n",
            "Cast & crew feature statistics:\n",
            "   Movies processed: 25\n",
            "   Director feature dimension: 24\n",
            "   Cast feature dimension: 50\n",
            "   Total feature dimension: 74\n",
            "   Feature matrix shape: (25, 74)\n",
            "   Feature matrix saved: multimodal_data\\cast_crew_features.npy\n",
            "   Mapping file saved: multimodal_data\\cast_crew_mapping.json\n",
            "   Feature sparsity: 95.08%\n",
            "   Average high-frequency cast & crew per movie: 3.6\n",
            "   Complete feature data saved: multimodal_data\\movie_features_complete.json\n"
          ]
        }
      ],
      "source": [
        "# Cast & crew statistical feature engineering\n",
        "print(\"Cast & Crew Statistical Feature Engineering\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def extract_cast_crew_features(all_movie_features, top_n=50):\n",
        "    \"\"\"Extract cast & crew statistical features\"\"\"\n",
        "    if not all_movie_features:\n",
        "        return None, None, None\n",
        "    \n",
        "    # Count frequency of all directors and cast\n",
        "    all_directors = []\n",
        "    all_cast = []\n",
        "    \n",
        "    for movie in all_movie_features:\n",
        "        # Directors\n",
        "        directors = movie.get('directors', '')\n",
        "        if directors:\n",
        "            all_directors.extend([d.strip() for d in directors.split('|') if d.strip()])\n",
        "        \n",
        "        # Cast\n",
        "        cast = movie.get('cast', '')\n",
        "        if cast:\n",
        "            all_cast.extend([c.strip() for c in cast.split('|') if c.strip()])\n",
        "    \n",
        "    # Count frequencies\n",
        "    director_counts = Counter(all_directors)\n",
        "    cast_counts = Counter(all_cast)\n",
        "    \n",
        "    # Get high-frequency cast & crew\n",
        "    top_directors = [director for director, count in director_counts.most_common(top_n)]\n",
        "    top_cast = [actor for actor, count in cast_counts.most_common(top_n)]\n",
        "    \n",
        "    print(f\"Cast & crew statistics:\")\n",
        "    print(f\"   Total directors: {len(director_counts)} people\")\n",
        "    print(f\"   Total cast: {len(cast_counts)} people\")\n",
        "    print(f\"   Selected high-frequency directors: {len(top_directors)} people\")\n",
        "    print(f\"   Selected high-frequency cast: {len(top_cast)} people\")\n",
        "    \n",
        "    # Display TOP 10 directors and cast\n",
        "    print(f\"\\nTOP 10 high-frequency directors:\")\n",
        "    for i, (director, count) in enumerate(director_counts.most_common(10), 1):\n",
        "        print(f\"   {i:2d}. {director}: {count} movies\")\n",
        "    \n",
        "    print(f\"\\nTOP 10 high-frequency cast:\")\n",
        "    for i, (actor, count) in enumerate(cast_counts.most_common(10), 1):\n",
        "        print(f\"   {i:2d}. {actor}: {count} movies\")\n",
        "    \n",
        "    return top_directors, top_cast, (director_counts, cast_counts)\n",
        "\n",
        "def create_cast_crew_features(all_movie_features, top_directors, top_cast):\n",
        "    \"\"\"Create cast & crew feature vectors for each movie\"\"\"\n",
        "    if not all_movie_features or not top_directors or not top_cast:\n",
        "        return None, None\n",
        "    \n",
        "    cast_crew_matrix = []\n",
        "    movie_ids = []\n",
        "    \n",
        "    for movie in all_movie_features:\n",
        "        movie_id = movie['movielens_id']\n",
        "        \n",
        "        # Director features (one-hot encoding)\n",
        "        director_features = np.zeros(len(top_directors))\n",
        "        directors = movie.get('directors', '')\n",
        "        if directors:\n",
        "            movie_directors = [d.strip() for d in directors.split('|') if d.strip()]\n",
        "            for i, top_director in enumerate(top_directors):\n",
        "                if top_director in movie_directors:\n",
        "                    director_features[i] = 1\n",
        "        \n",
        "        # Cast features (one-hot encoding)\n",
        "        cast_features = np.zeros(len(top_cast))\n",
        "        cast = movie.get('cast', '')\n",
        "        if cast:\n",
        "            movie_cast = [c.strip() for c in cast.split('|') if c.strip()]\n",
        "            for i, top_actor in enumerate(top_cast):\n",
        "                if top_actor in movie_cast:\n",
        "                    cast_features[i] = 1\n",
        "        \n",
        "        # Combine features\n",
        "        combined_features = np.concatenate([director_features, cast_features])\n",
        "        cast_crew_matrix.append(combined_features)\n",
        "        movie_ids.append(movie_id)\n",
        "    \n",
        "    return np.array(cast_crew_matrix), movie_ids\n",
        "\n",
        "# Execute cast & crew feature engineering\n",
        "if 'all_movie_features' in locals() and all_movie_features:\n",
        "    print(f\"Starting cast & crew feature extraction for {len(all_movie_features)} movies\")\n",
        "    \n",
        "    # Extract high-frequency cast & crew\n",
        "    top_directors, top_cast, (director_counts, cast_counts) = extract_cast_crew_features(all_movie_features)\n",
        "    \n",
        "    if top_directors and top_cast:\n",
        "        # Create cast & crew feature matrix\n",
        "        cast_crew_matrix, cc_movie_ids = create_cast_crew_features(\n",
        "            all_movie_features, top_directors, top_cast\n",
        "        )\n",
        "        \n",
        "        if cast_crew_matrix is not None:\n",
        "            # Save cast & crew features\n",
        "            cast_crew_file = os.path.join(DATA_DIR, 'cast_crew_features.npy')\n",
        "            np.save(cast_crew_file, cast_crew_matrix)\n",
        "            \n",
        "            # Save cast & crew mapping information\n",
        "            cast_crew_mapping = {\n",
        "                'movie_ids': cc_movie_ids,\n",
        "                'top_directors': top_directors,\n",
        "                'top_cast': top_cast,\n",
        "                'director_feature_dim': len(top_directors),\n",
        "                'cast_feature_dim': len(top_cast),\n",
        "                'total_feature_dim': len(top_directors) + len(top_cast)\n",
        "            }\n",
        "            \n",
        "            mapping_file = os.path.join(DATA_DIR, 'cast_crew_mapping.json')\n",
        "            with open(mapping_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(cast_crew_mapping, f, ensure_ascii=False, indent=2)\n",
        "            \n",
        "            # Update movie feature data\n",
        "            for i, movie in enumerate(all_movie_features):\n",
        "                if movie['movielens_id'] in cc_movie_ids:\n",
        "                    idx = cc_movie_ids.index(movie['movielens_id'])\n",
        "                    movie['cast_crew_features'] = cast_crew_matrix[idx].tolist()\n",
        "                    movie['cast_crew_feature_dim'] = len(cast_crew_matrix[idx])\n",
        "            \n",
        "            print(f\"\\nCast & crew feature statistics:\")\n",
        "            print(f\"   Movies processed: {len(cc_movie_ids)}\")\n",
        "            print(f\"   Director feature dimension: {len(top_directors)}\")\n",
        "            print(f\"   Cast feature dimension: {len(top_cast)}\")\n",
        "            print(f\"   Total feature dimension: {cast_crew_matrix.shape[1]}\")\n",
        "            print(f\"   Feature matrix shape: {cast_crew_matrix.shape}\")\n",
        "            print(f\"   Feature matrix saved: {cast_crew_file}\")\n",
        "            print(f\"   Mapping file saved: {mapping_file}\")\n",
        "            \n",
        "            # Analyze feature sparsity\n",
        "            sparsity = 1 - np.count_nonzero(cast_crew_matrix) / cast_crew_matrix.size\n",
        "            print(f\"   Feature sparsity: {sparsity*100:.2f}%\")\n",
        "            print(f\"   Average high-frequency cast & crew per movie: {np.mean(np.sum(cast_crew_matrix, axis=1)):.1f}\")\n",
        "            \n",
        "            # Save final movie feature data\n",
        "            final_features_file = os.path.join(DATA_DIR, 'movie_features_complete.json')\n",
        "            with open(final_features_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(all_movie_features, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"   Complete feature data saved: {final_features_file}\")\n",
        "        else:\n",
        "            print(\"ERROR: Cast & crew feature matrix creation failed\")\n",
        "    else:\n",
        "        print(\"ERROR: High-frequency cast & crew extraction failed\")\n",
        "else:\n",
        "    print(\"ERROR: No movie feature data available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multimodal Feature Fusion\n",
            "==================================================\n",
            "Starting multimodal feature fusion\n",
            "ViT features loaded: (25, 768) (standardized)\n",
            "BERT features loaded: (25, 768) (standardized)\n",
            "Cast & crew features loaded: (25, 74) (one-hot encoded)\n",
            "\n",
            "Using concatenate method for feature fusion\n",
            "Feature intersection statistics:\n",
            "   vit: 25 movies\n",
            "   bert: 25 movies\n",
            "   cast_crew: 25 movies\n",
            "   Intersection: 25 movies\n",
            "   vit: (25, 768)\n",
            "   bert: (25, 768)\n",
            "   cast_crew: (25, 74)\n",
            "\n",
            "Concatenation fusion result: (25, 1610)\n",
            "   concatenate fused features saved: multimodal_data\\multimodal_features_concatenate.npy\n",
            "   Mapping file saved: multimodal_data\\multimodal_mapping_concatenate.json\n",
            "\n",
            "Using weighted_average method for feature fusion\n",
            "Feature intersection statistics:\n",
            "   vit: 25 movies\n",
            "   bert: 25 movies\n",
            "   cast_crew: 25 movies\n",
            "   Intersection: 25 movies\n",
            "   vit: (25, 768)\n",
            "   bert: (25, 768)\n",
            "   cast_crew: (25, 74)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "n_components=74 must be between 0 and min(n_samples, n_features)=25 with svd_solver='full'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 160\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m fusion_methods:\n\u001b[32m    159\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m method for feature fusion\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     multimodal_features, movie_ids = \u001b[43mcreate_multimodal_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m multimodal_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    163\u001b[39m         multimodal_results[method] = {\n\u001b[32m    164\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m'\u001b[39m: multimodal_features,\n\u001b[32m    165\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mmovie_ids\u001b[39m\u001b[33m'\u001b[39m: movie_ids\n\u001b[32m    166\u001b[39m         }\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 131\u001b[39m, in \u001b[36mcreate_multimodal_features\u001b[39m\u001b[34m(features_data, fusion_method)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature.shape[\u001b[32m1\u001b[39m] > target_dim:\n\u001b[32m    130\u001b[39m     pca = PCA(n_components=target_dim)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     reduced_feature = \u001b[43mpca\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     reduced_features.append(reduced_feature)\n\u001b[32m    133\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreduced_feature.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (PCA)\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mz:\\Document\\MyProject\\3033-061\\.conda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mz:\\Document\\MyProject\\3033-061\\.conda\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mz:\\Document\\MyProject\\3033-061\\.conda\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:466\u001b[39m, in \u001b[36mPCA.fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    445\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[32m    446\u001b[39m \n\u001b[32m    447\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m \u001b[33;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     U, S, _, X, x_is_centered, xp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         U = U[:, : \u001b[38;5;28mself\u001b[39m.n_components_]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mz:\\Document\\MyProject\\3033-061\\.conda\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:540\u001b[39m, in \u001b[36mPCA._fit\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mfull\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcovariance_eigh\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_array_api_compliant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33marpack\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrandomized\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_truncated(X, n_components, xp)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mz:\\Document\\MyProject\\3033-061\\.conda\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:554\u001b[39m, in \u001b[36mPCA._fit_full\u001b[39m\u001b[34m(self, X, n_components, xp, is_array_api_compliant)\u001b[39m\n\u001b[32m    550\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    551\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn_components=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmle\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is only supported if n_samples >= n_features\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    552\u001b[39m         )\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m0\u001b[39m <= n_components <= \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    555\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mn_components=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be between 0 and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    556\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(n_samples,\u001b[38;5;250m \u001b[39mn_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    557\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msvd_solver=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._fit_svd_solver\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m     )\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.mean_ = xp.mean(X, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# When X is a scipy sparse matrix, self.mean_ is a numpy matrix, so we need\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# to transform it to a 1D array. Note that this is not the case when X\u001b[39;00m\n\u001b[32m    563\u001b[39m \u001b[38;5;66;03m# is a scipy sparse array.\u001b[39;00m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# TODO: remove the following two lines when scikit-learn only depends\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# on scipy versions that no longer support scipy.sparse matrices.\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: n_components=74 must be between 0 and min(n_samples, n_features)=25 with svd_solver='full'"
          ]
        }
      ],
      "source": [
        "# Multimodal feature fusion\n",
        "print(\"Multimodal Feature Fusion\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def load_and_normalize_features():\n",
        "    \"\"\"Load and normalize all features\"\"\"\n",
        "    features_data = {}\n",
        "    \n",
        "    # 1. Load ViT image features\n",
        "    vit_file = os.path.join(DATA_DIR, 'vit_features_matrix.npy')\n",
        "    vit_mapping_file = os.path.join(DATA_DIR, 'vit_movie_mapping.json')\n",
        "    \n",
        "    if os.path.exists(vit_file) and os.path.exists(vit_mapping_file):\n",
        "        vit_features = np.load(vit_file)\n",
        "        with open(vit_mapping_file, 'r') as f:\n",
        "            vit_mapping = json.load(f)\n",
        "        \n",
        "        # Standardize ViT features\n",
        "        scaler_vit = StandardScaler()\n",
        "        vit_features_normalized = scaler_vit.fit_transform(vit_features)\n",
        "        \n",
        "        features_data['vit'] = {\n",
        "            'features': vit_features_normalized,\n",
        "            'movie_ids': vit_mapping['movie_ids'],\n",
        "            'dim': vit_features_normalized.shape[1],\n",
        "            'scaler': scaler_vit\n",
        "        }\n",
        "        print(f\"ViT features loaded: {vit_features_normalized.shape} (standardized)\")\n",
        "    else:\n",
        "        print(\"WARNING: ViT feature files not found\")\n",
        "    \n",
        "    # 2. Load BERT text features\n",
        "    bert_file = os.path.join(DATA_DIR, 'bert_features_matrix.npy')\n",
        "    bert_mapping_file = os.path.join(DATA_DIR, 'bert_movie_mapping.json')\n",
        "    \n",
        "    if os.path.exists(bert_file) and os.path.exists(bert_mapping_file):\n",
        "        bert_features = np.load(bert_file)\n",
        "        with open(bert_mapping_file, 'r') as f:\n",
        "            bert_mapping = json.load(f)\n",
        "        \n",
        "        # Standardize BERT features\n",
        "        scaler_bert = StandardScaler()\n",
        "        bert_features_normalized = scaler_bert.fit_transform(bert_features)\n",
        "        \n",
        "        features_data['bert'] = {\n",
        "            'features': bert_features_normalized,\n",
        "            'movie_ids': bert_mapping['movie_ids'],\n",
        "            'dim': bert_features_normalized.shape[1],\n",
        "            'scaler': scaler_bert\n",
        "        }\n",
        "        print(f\"BERT features loaded: {bert_features_normalized.shape} (standardized)\")\n",
        "    else:\n",
        "        print(\"WARNING: BERT feature files not found\")\n",
        "    \n",
        "    # 3. Load cast & crew features\n",
        "    cast_crew_file = os.path.join(DATA_DIR, 'cast_crew_features.npy')\n",
        "    cast_crew_mapping_file = os.path.join(DATA_DIR, 'cast_crew_mapping.json')\n",
        "    \n",
        "    if os.path.exists(cast_crew_file) and os.path.exists(cast_crew_mapping_file):\n",
        "        cast_crew_features = np.load(cast_crew_file)\n",
        "        with open(cast_crew_mapping_file, 'r') as f:\n",
        "            cast_crew_mapping = json.load(f)\n",
        "        \n",
        "        # Cast & crew features are already 0-1 encoded, no standardization needed\n",
        "        features_data['cast_crew'] = {\n",
        "            'features': cast_crew_features,\n",
        "            'movie_ids': cast_crew_mapping['movie_ids'],\n",
        "            'dim': cast_crew_features.shape[1],\n",
        "            'directors_dim': cast_crew_mapping['director_feature_dim'],\n",
        "            'cast_dim': cast_crew_mapping['cast_feature_dim']\n",
        "        }\n",
        "        print(f\"Cast & crew features loaded: {cast_crew_features.shape} (one-hot encoded)\")\n",
        "    else:\n",
        "        print(\"WARNING: Cast & crew feature files not found\")\n",
        "    \n",
        "    return features_data\n",
        "\n",
        "def create_multimodal_features(features_data, fusion_method='concatenate'):\n",
        "    \"\"\"Create multimodal fused features\"\"\"\n",
        "    if not features_data:\n",
        "        return None, None\n",
        "    \n",
        "    # Find intersection of movie IDs from all features\n",
        "    movie_id_sets = [set(data['movie_ids']) for data in features_data.values()]\n",
        "    common_movie_ids = set.intersection(*movie_id_sets)\n",
        "    common_movie_ids = sorted(list(common_movie_ids))\n",
        "    \n",
        "    print(f\"Feature intersection statistics:\")\n",
        "    for feature_name, data in features_data.items():\n",
        "        print(f\"   {feature_name}: {len(data['movie_ids'])} movies\")\n",
        "    print(f\"   Intersection: {len(common_movie_ids)} movies\")\n",
        "    \n",
        "    if not common_movie_ids:\n",
        "        print(\"ERROR: No common movie IDs found\")\n",
        "        return None, None\n",
        "    \n",
        "    # Align feature matrices\n",
        "    aligned_features = []\n",
        "    feature_dims = []\n",
        "    feature_names = []\n",
        "    \n",
        "    for feature_name, data in features_data.items():\n",
        "        movie_ids = data['movie_ids']\n",
        "        features = data['features']\n",
        "        \n",
        "        # Create index mapping\n",
        "        id_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n",
        "        \n",
        "        # Reorder features according to intersection IDs\n",
        "        aligned_feature = np.array([features[id_to_idx[movie_id]] for movie_id in common_movie_ids])\n",
        "        aligned_features.append(aligned_feature)\n",
        "        feature_dims.append(aligned_feature.shape[1])\n",
        "        feature_names.append(feature_name)\n",
        "        \n",
        "        print(f\"   {feature_name}: {aligned_feature.shape}\")\n",
        "    \n",
        "    # Feature fusion\n",
        "    if fusion_method == 'concatenate':\n",
        "        # Simple concatenation\n",
        "        multimodal_features = np.concatenate(aligned_features, axis=1)\n",
        "        print(f\"\\nConcatenation fusion result: {multimodal_features.shape}\")\n",
        "    \n",
        "    elif fusion_method == 'weighted_average':\n",
        "        # Weighted average (requires consistent feature dimensions, using PCA for dimensionality reduction)\n",
        "        target_dim = min(feature_dims)\n",
        "        reduced_features = []\n",
        "        \n",
        "        for i, feature in enumerate(aligned_features):\n",
        "            if feature.shape[1] > target_dim:\n",
        "                pca = PCA(n_components=target_dim)\n",
        "                reduced_feature = pca.fit_transform(feature)\n",
        "                reduced_features.append(reduced_feature)\n",
        "                print(f\"   {feature_names[i]}: {feature.shape} -> {reduced_feature.shape} (PCA)\")\n",
        "            else:\n",
        "                reduced_features.append(feature)\n",
        "        \n",
        "        # Equal weight average\n",
        "        multimodal_features = np.mean(reduced_features, axis=0)\n",
        "        print(f\"\\nWeighted average fusion result: {multimodal_features.shape}\")\n",
        "    \n",
        "    else:\n",
        "        # Default concatenation\n",
        "        multimodal_features = np.concatenate(aligned_features, axis=1)\n",
        "    \n",
        "    return multimodal_features, common_movie_ids\n",
        "\n",
        "# Execute multimodal feature fusion\n",
        "print(\"Starting multimodal feature fusion\")\n",
        "\n",
        "# Load and normalize features\n",
        "features_data = load_and_normalize_features()\n",
        "\n",
        "if features_data:\n",
        "    # Create multiple fusion versions\n",
        "    fusion_methods = ['concatenate', 'weighted_average']\n",
        "    multimodal_results = {}\n",
        "    \n",
        "    for method in fusion_methods:\n",
        "        print(f\"\\nUsing {method} method for feature fusion\")\n",
        "        multimodal_features, movie_ids = create_multimodal_features(features_data, method)\n",
        "        \n",
        "        if multimodal_features is not None:\n",
        "            multimodal_results[method] = {\n",
        "                'features': multimodal_features,\n",
        "                'movie_ids': movie_ids\n",
        "            }\n",
        "            \n",
        "            # Save fused features\n",
        "            fusion_file = os.path.join(DATA_DIR, f'multimodal_features_{method}.npy')\n",
        "            np.save(fusion_file, multimodal_features)\n",
        "            \n",
        "            # Save movie ID mapping\n",
        "            mapping_file = os.path.join(DATA_DIR, f'multimodal_mapping_{method}.json')\n",
        "            with open(mapping_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\n",
        "                    'movie_ids': movie_ids,\n",
        "                    'feature_dim': multimodal_features.shape[1],\n",
        "                    'fusion_method': method,\n",
        "                    'component_dims': {name: data['dim'] for name, data in features_data.items()}\n",
        "                }, f, indent=2)\n",
        "            \n",
        "            print(f\"   {method} fused features saved: {fusion_file}\")\n",
        "            print(f\"   Mapping file saved: {mapping_file}\")\n",
        "    \n",
        "    if multimodal_results:\n",
        "        print(f\"\\nMultimodal feature fusion completed\")\n",
        "        print(f\"Fusion results summary:\")\n",
        "        for method, result in multimodal_results.items():\n",
        "            features = result['features']\n",
        "            print(f\"   {method}: {features.shape} (movies x feature_dim)\")\n",
        "        \n",
        "        # Save feature statistics\n",
        "        stats = {\n",
        "            'total_movies': len(movie_ids),\n",
        "            'fusion_methods': list(multimodal_results.keys()),\n",
        "            'feature_sources': list(features_data.keys()),\n",
        "            'individual_dims': {name: data['dim'] for name, data in features_data.items()}\n",
        "        }\n",
        "        \n",
        "        stats_file = os.path.join(DATA_DIR, 'multimodal_stats.json')\n",
        "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(stats, f, indent=2)\n",
        "        print(f\"   Statistics saved: {stats_file}\")\n",
        "    else:\n",
        "        print(\"ERROR: Multimodal feature fusion failed\")\n",
        "else:\n",
        "    print(\"ERROR: No available feature data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendation System Implementation and Performance Comparison\n",
            "============================================================\n",
            "Recommendation system classes defined successfully\n"
          ]
        }
      ],
      "source": [
        "# Recommendation system implementation and performance comparison\n",
        "print(\"Recommendation System Implementation and Performance Comparison\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Import traditional recommendation algorithms (reuse previous implementation)\n",
        "class UserBasedCF:\n",
        "    def __init__(self, rating_matrix, user_features=None, use_features=False):\n",
        "        self.rating_matrix = rating_matrix\n",
        "        self.user_features = user_features\n",
        "        self.use_features = use_features\n",
        "        self.user_similarity = None\n",
        "        \n",
        "    def compute_similarity(self):\n",
        "        if self.use_features and self.user_features is not None:\n",
        "            # Feature-based similarity\n",
        "            self.user_similarity = cosine_similarity(self.user_features)\n",
        "        else:\n",
        "            # Rating-based similarity\n",
        "            self.user_similarity = cosine_similarity(self.rating_matrix)\n",
        "    \n",
        "    def predict(self, user_idx, item_idx, k=50):\n",
        "        if self.user_similarity is None:\n",
        "            self.compute_similarity()\n",
        "        \n",
        "        user_ratings = self.rating_matrix[user_idx]\n",
        "        if user_ratings[item_idx] != 0:\n",
        "            return user_ratings[item_idx]\n",
        "        \n",
        "        # Find k most similar users\n",
        "        similarities = self.user_similarity[user_idx]\n",
        "        similar_users = np.argsort(similarities)[::-1][1:k+1]\n",
        "        \n",
        "        # Predict rating\n",
        "        numerator = 0\n",
        "        denominator = 0\n",
        "        \n",
        "        for similar_user in similar_users:\n",
        "            if self.rating_matrix[similar_user, item_idx] != 0:\n",
        "                sim = similarities[similar_user]\n",
        "                numerator += sim * self.rating_matrix[similar_user, item_idx]\n",
        "                denominator += abs(sim)\n",
        "        \n",
        "        if denominator == 0:\n",
        "            return np.mean(user_ratings[user_ratings != 0]) if np.any(user_ratings != 0) else 3.0\n",
        "        \n",
        "        return numerator / denominator\n",
        "\n",
        "class ItemBasedCF:\n",
        "    def __init__(self, rating_matrix, item_features=None, use_features=False):\n",
        "        self.rating_matrix = rating_matrix\n",
        "        self.item_features = item_features\n",
        "        self.use_features = use_features\n",
        "        self.item_similarity = None\n",
        "        \n",
        "    def compute_similarity(self):\n",
        "        if self.use_features and self.item_features is not None:\n",
        "            # Feature-based similarity\n",
        "            self.item_similarity = cosine_similarity(self.item_features.T)\n",
        "        else:\n",
        "            # Rating-based similarity\n",
        "            self.item_similarity = cosine_similarity(self.rating_matrix.T)\n",
        "    \n",
        "    def predict(self, user_idx, item_idx, k=50):\n",
        "        if self.item_similarity is None:\n",
        "            self.compute_similarity()\n",
        "        \n",
        "        user_ratings = self.rating_matrix[user_idx]\n",
        "        if user_ratings[item_idx] != 0:\n",
        "            return user_ratings[item_idx]\n",
        "        \n",
        "        # Find k most similar items\n",
        "        similarities = self.item_similarity[item_idx]\n",
        "        similar_items = np.argsort(similarities)[::-1][1:k+1]\n",
        "        \n",
        "        # Predict rating\n",
        "        numerator = 0\n",
        "        denominator = 0\n",
        "        \n",
        "        for similar_item in similar_items:\n",
        "            if user_ratings[similar_item] != 0:\n",
        "                sim = similarities[similar_item]\n",
        "                numerator += sim * user_ratings[similar_item]\n",
        "                denominator += abs(sim)\n",
        "        \n",
        "        if denominator == 0:\n",
        "            item_ratings = self.rating_matrix[:, item_idx]\n",
        "            return np.mean(item_ratings[item_ratings != 0]) if np.any(item_ratings != 0) else 3.0\n",
        "        \n",
        "        return numerator / denominator\n",
        "\n",
        "class HybridRecommender:\n",
        "    def __init__(self, user_cf, item_cf, user_weight=0.5, item_weight=0.5):\n",
        "        self.user_cf = user_cf\n",
        "        self.item_cf = item_cf\n",
        "        self.user_weight = user_weight\n",
        "        self.item_weight = item_weight\n",
        "        \n",
        "        # Ensure weights sum to 1\n",
        "        total_weight = user_weight + item_weight\n",
        "        self.user_weight = user_weight / total_weight\n",
        "        self.item_weight = item_weight / total_weight\n",
        "    \n",
        "    def predict(self, user_idx, item_idx, k=50):\n",
        "        user_pred = self.user_cf.predict(user_idx, item_idx, k)\n",
        "        item_pred = self.item_cf.predict(user_idx, item_idx, k)\n",
        "        \n",
        "        return self.user_weight * user_pred + self.item_weight * item_pred\n",
        "\n",
        "class MultimodalRecommender:\n",
        "    \"\"\"Enhanced multimodal recommendation system\"\"\"\n",
        "    def __init__(self, rating_matrix, multimodal_features, user_features=None, \n",
        "                 alpha=0.5, beta=0.3, gamma=0.2):\n",
        "        self.rating_matrix = rating_matrix\n",
        "        self.multimodal_features = multimodal_features\n",
        "        self.user_features = user_features\n",
        "        self.alpha = alpha  # Rating weight\n",
        "        self.beta = beta    # Multimodal feature weight\n",
        "        self.gamma = gamma  # User feature weight\n",
        "        \n",
        "        # Normalize weights\n",
        "        total = alpha + beta + gamma\n",
        "        self.alpha = alpha / total\n",
        "        self.beta = beta / total\n",
        "        self.gamma = gamma / total\n",
        "        \n",
        "        self.rating_similarity = None\n",
        "        self.content_similarity = None\n",
        "        self.user_similarity = None\n",
        "    \n",
        "    def compute_similarities(self):\n",
        "        # Rating-based similarity\n",
        "        self.rating_similarity = cosine_similarity(self.rating_matrix.T)\n",
        "        \n",
        "        # Multimodal feature-based similarity\n",
        "        self.content_similarity = cosine_similarity(self.multimodal_features)\n",
        "        \n",
        "        # User feature-based similarity (if available)\n",
        "        if self.user_features is not None:\n",
        "            self.user_similarity = cosine_similarity(self.user_features)\n",
        "    \n",
        "    def predict(self, user_idx, item_idx, k=50):\n",
        "        if self.rating_similarity is None:\n",
        "            self.compute_similarities()\n",
        "        \n",
        "        user_ratings = self.rating_matrix[user_idx]\n",
        "        if user_ratings[item_idx] != 0:\n",
        "            return user_ratings[item_idx]\n",
        "        \n",
        "        predictions = []\n",
        "        weights = []\n",
        "        \n",
        "        # 1. Rating-based collaborative filtering prediction\n",
        "        similarities = self.rating_similarity[item_idx]\n",
        "        similar_items = np.argsort(similarities)[::-1][1:k+1]\n",
        "        \n",
        "        numerator = denominator = 0\n",
        "        for similar_item in similar_items:\n",
        "            if user_ratings[similar_item] != 0:\n",
        "                sim = similarities[similar_item]\n",
        "                numerator += sim * user_ratings[similar_item]\n",
        "                denominator += abs(sim)\n",
        "        \n",
        "        if denominator > 0:\n",
        "            rating_pred = numerator / denominator\n",
        "            predictions.append(rating_pred)\n",
        "            weights.append(self.alpha)\n",
        "        \n",
        "        # 2. Multimodal content-based prediction\n",
        "        similarities = self.content_similarity[item_idx]\n",
        "        similar_items = np.argsort(similarities)[::-1][1:k+1]\n",
        "        \n",
        "        numerator = denominator = 0\n",
        "        for similar_item in similar_items:\n",
        "            if user_ratings[similar_item] != 0:\n",
        "                sim = similarities[similar_item]\n",
        "                numerator += sim * user_ratings[similar_item]\n",
        "                denominator += abs(sim)\n",
        "        \n",
        "        if denominator > 0:\n",
        "            content_pred = numerator / denominator\n",
        "            predictions.append(content_pred)\n",
        "            weights.append(self.beta)\n",
        "        \n",
        "        # 3. User feature-based prediction (if available)\n",
        "        if self.user_similarity is not None:\n",
        "            similarities = self.user_similarity[user_idx]\n",
        "            similar_users = np.argsort(similarities)[::-1][1:k+1]\n",
        "            \n",
        "            numerator = denominator = 0\n",
        "            for similar_user in similar_users:\n",
        "                if self.rating_matrix[similar_user, item_idx] != 0:\n",
        "                    sim = similarities[similar_user]\n",
        "                    numerator += sim * self.rating_matrix[similar_user, item_idx]\n",
        "                    denominator += abs(sim)\n",
        "            \n",
        "            if denominator > 0:\n",
        "                user_pred = numerator / denominator\n",
        "                predictions.append(user_pred)\n",
        "                weights.append(self.gamma)\n",
        "        \n",
        "        # Weighted average prediction\n",
        "        if predictions:\n",
        "            final_pred = np.average(predictions, weights=weights)\n",
        "            return final_pred\n",
        "        else:\n",
        "            # Default prediction\n",
        "            return 3.0\n",
        "\n",
        "print(\"Recommendation system classes defined successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Preparation and Model Training\n",
            "==================================================\n",
            "Rating data loaded: 4217 entries\n",
            "Rating matrix dimensions: 595 users x 25 movies\n",
            "Rating matrix created: (595, 25)\n",
            "Sparsity: 71.65%\n",
            "User feature matrix created: (595, 24)\n",
            "Multimodal features loaded: (25, 1610)\n",
            "Multimodal movies: 25\n",
            "Multimodal features aligned: (25, 1610)\n",
            "Data splitting completed:\n",
            "   Training set: 3374 ratings\n",
            "   Test set: 843 ratings\n",
            "   Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# Data preparation and model training\n",
        "print(\"Data Preparation and Model Training\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load cleaned rating data\n",
        "cleaned_data_file = os.path.join(DATA_DIR, 'cleaned_ratings_data.csv')\n",
        "if os.path.exists(cleaned_data_file):\n",
        "    ratings_data = pd.read_csv(cleaned_data_file)\n",
        "    print(f\"Rating data loaded: {len(ratings_data)} entries\")\n",
        "else:\n",
        "    print(\"ERROR: Cleaned rating data not found\")\n",
        "    ratings_data = None\n",
        "\n",
        "if ratings_data is not None:\n",
        "    # Create user-movie rating matrix\n",
        "    from scipy.sparse import csr_matrix\n",
        "    \n",
        "    # Remap user and movie IDs to continuous indices\n",
        "    unique_users = sorted(ratings_data['user_id'].unique())\n",
        "    unique_movies = sorted(ratings_data['movie_id'].unique())\n",
        "    \n",
        "    user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
        "    movie_to_idx = {movie: idx for idx, movie in enumerate(unique_movies)}\n",
        "    idx_to_user = {idx: user for user, idx in user_to_idx.items()}\n",
        "    idx_to_movie = {idx: movie for movie, idx in movie_to_idx.items()}\n",
        "    \n",
        "    print(f\"Rating matrix dimensions: {len(unique_users)} users x {len(unique_movies)} movies\")\n",
        "    \n",
        "    # Create rating matrix\n",
        "    rating_matrix = np.zeros((len(unique_users), len(unique_movies)))\n",
        "    \n",
        "    for _, row in ratings_data.iterrows():\n",
        "        user_idx = user_to_idx[row['user_id']]\n",
        "        movie_idx = movie_to_idx[row['movie_id']]\n",
        "        rating_matrix[user_idx, movie_idx] = row['rating']\n",
        "    \n",
        "    print(f\"Rating matrix created: {rating_matrix.shape}\")\n",
        "    print(f\"Sparsity: {(1 - np.count_nonzero(rating_matrix) / rating_matrix.size) * 100:.2f}%\")\n",
        "    \n",
        "    # Create user feature matrix\n",
        "    user_features_list = ['age', 'gender', 'occupation']\n",
        "    user_feature_matrix = np.zeros((len(unique_users), len(user_features_list) + 21))  # +21 for occupation one-hot\n",
        "    \n",
        "    for user_id in unique_users:\n",
        "        user_data = ratings_data[ratings_data['user_id'] == user_id].iloc[0]\n",
        "        user_idx = user_to_idx[user_id]\n",
        "        \n",
        "        # Age feature (normalized)\n",
        "        user_feature_matrix[user_idx, 0] = user_data['age'] / 100.0\n",
        "        \n",
        "        # Gender feature (M=1, F=0)\n",
        "        user_feature_matrix[user_idx, 1] = 1 if user_data['gender'] == 'M' else 0\n",
        "        \n",
        "        # Occupation feature (one-hot encoding, simplified to top 20 common occupations)\n",
        "        occupation_map = {\n",
        "            'student': 2, 'other': 3, 'educator': 4, 'administrator': 5,\n",
        "            'engineer': 6, 'programmer': 7, 'librarian': 8, 'writer': 9,\n",
        "            'executive': 10, 'scientist': 11, 'artist': 12, 'technician': 13,\n",
        "            'marketing': 14, 'entertainment': 15, 'healthcare': 16, 'retired': 17,\n",
        "            'lawyer': 18, 'salesman': 19, 'homemaker': 20, 'doctor': 21\n",
        "        }\n",
        "        \n",
        "        occupation = user_data['occupation']\n",
        "        if occupation in occupation_map:\n",
        "            user_feature_matrix[user_idx, occupation_map[occupation]] = 1\n",
        "    \n",
        "    print(f\"User feature matrix created: {user_feature_matrix.shape}\")\n",
        "    \n",
        "    # Load multimodal features (if available)\n",
        "    multimodal_features = None\n",
        "    multimodal_movie_ids = None\n",
        "    \n",
        "    # Try to load concatenated multimodal features\n",
        "    multimodal_file = os.path.join(DATA_DIR, 'multimodal_features_concatenate.npy')\n",
        "    multimodal_mapping_file = os.path.join(DATA_DIR, 'multimodal_mapping_concatenate.json')\n",
        "    \n",
        "    if os.path.exists(multimodal_file) and os.path.exists(multimodal_mapping_file):\n",
        "        multimodal_features = np.load(multimodal_file)\n",
        "        with open(multimodal_mapping_file, 'r') as f:\n",
        "            multimodal_mapping = json.load(f)\n",
        "        multimodal_movie_ids = multimodal_mapping['movie_ids']\n",
        "        \n",
        "        print(f\"Multimodal features loaded: {multimodal_features.shape}\")\n",
        "        print(f\"Multimodal movies: {len(multimodal_movie_ids)}\")\n",
        "        \n",
        "        # Align multimodal features with rating matrix\n",
        "        aligned_multimodal = np.zeros((len(unique_movies), multimodal_features.shape[1]))\n",
        "        multimodal_movie_to_idx = {movie_id: idx for idx, movie_id in enumerate(multimodal_movie_ids)}\n",
        "        \n",
        "        for movie_idx, movie_id in enumerate(unique_movies):\n",
        "            if movie_id in multimodal_movie_to_idx:\n",
        "                mm_idx = multimodal_movie_to_idx[movie_id]\n",
        "                aligned_multimodal[movie_idx] = multimodal_features[mm_idx]\n",
        "        \n",
        "        print(f\"Multimodal features aligned: {aligned_multimodal.shape}\")\n",
        "    else:\n",
        "        print(\"WARNING: Multimodal feature files not found, will use traditional features\")\n",
        "    \n",
        "    # Data splitting\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    \n",
        "    # Set random seed for reproducibility\n",
        "    RANDOM_SEED = 42\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    \n",
        "    # Create test set indices\n",
        "    non_zero_indices = np.where(rating_matrix != 0)\n",
        "    test_indices = np.random.choice(len(non_zero_indices[0]), size=int(0.2 * len(non_zero_indices[0])), replace=False)\n",
        "    \n",
        "    # Create training and test matrices\n",
        "    train_matrix = rating_matrix.copy()\n",
        "    test_data = []\n",
        "    \n",
        "    for idx in test_indices:\n",
        "        user_idx = non_zero_indices[0][idx]\n",
        "        movie_idx = non_zero_indices[1][idx]\n",
        "        true_rating = rating_matrix[user_idx, movie_idx]\n",
        "        \n",
        "        test_data.append((user_idx, movie_idx, true_rating))\n",
        "        train_matrix[user_idx, movie_idx] = 0  # Remove from training set\n",
        "    \n",
        "    print(f\"Data splitting completed:\")\n",
        "    print(f\"   Training set: {np.count_nonzero(train_matrix)} ratings\")\n",
        "    print(f\"   Test set: {len(test_data)} ratings\")\n",
        "    print(f\"   Random seed: {RANDOM_SEED}\")\n",
        "\n",
        "else:\n",
        "    print(\"ERROR: Cannot perform data preparation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Evaluation and Performance Comparison\n",
            "============================================================\n",
            "Starting model training and evaluation\n",
            "\n",
            "==================================================\n",
            "Traditional Collaborative Filtering Methods\n",
            "==================================================\n",
            "\n",
            "Evaluating model: User CF (Rating Only)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating User CF (Rating Only): 100%|██████████| 500/500 [00:00<00:00, 41672.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RMSE: 1.0719, MAE: 0.8602 (samples: 500)\n",
            "\n",
            "Evaluating model: User CF (Rating + User Features)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating User CF (Rating + User Features): 100%|██████████| 500/500 [00:00<00:00, 41657.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RMSE: 1.0605, MAE: 0.8460 (samples: 500)\n",
            "\n",
            "Evaluating model: Item CF (Rating Only)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Item CF (Rating Only): 100%|██████████| 500/500 [00:00<00:00, 110960.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RMSE: 1.0582, MAE: 0.8233 (samples: 500)\n",
            "\n",
            "Reproducing best HybridRec configuration: SVD user features + rating-only items\n",
            "\n",
            "Evaluating model: HybridRec (SVD User + Rating-only Item)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating HybridRec (SVD User + Rating-only Item): 100%|██████████| 500/500 [00:00<00:00, 33340.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RMSE: 0.9860, MAE: 0.7786 (samples: 500)\n",
            "\n",
            "==================================================\n",
            "Enhanced Multimodal Recommendation System\n",
            "==================================================\n",
            "\n",
            "Evaluating model: Multimodal (Rating Dominant)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Multimodal (Rating Dominant): 100%|██████████| 500/500 [00:00<00:00, 23809.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RMSE: 1.9522, MAE: 1.6999 (samples: 500)\n",
            "\n",
            "Evaluating model: Multimodal (Balanced)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Multimodal (Balanced): 100%|██████████| 500/500 [00:00<00:00, 22727.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RMSE: 2.4077, MAE: 2.1455 (samples: 500)\n",
            "\n",
            "Evaluating model: Multimodal (Content Dominant)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Multimodal (Content Dominant): 100%|██████████| 500/500 [00:00<00:00, 23809.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RMSE: 2.6626, MAE: 2.4163 (samples: 500)\n",
            "\n",
            "Evaluating model: Multimodal (No User Features)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Multimodal (No User Features): 100%|██████████| 500/500 [00:00<00:00, 16945.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RMSE: 2.6048, MAE: 2.3364 (samples: 500)\n",
            "\n",
            "================================================================================\n",
            "Model Performance Leaderboard (sorted by RMSE)\n",
            "================================================================================\n",
            "Rank Model                                    RMSE     MAE      Samples \n",
            "--------------------------------------------------------------------------------\n",
            "1    Multimodal (Rating Dominant)             0.9522   0.6999   500     \n",
            "2    HybridRec (SVD User + Rating-only Item)  0.9860   0.7786   500     \n",
            "3    Item CF (Rating Only)                    1.0582   0.8233   500     \n",
            "4    User CF (Rating + User Features)         1.0605   0.8460   500     \n",
            "5    User CF (Rating Only)                    1.0719   0.8602   500     \n",
            "6    Multimodal (Balanced)                    1.4077   1.1455   500     \n",
            "7    Multimodal (No User Features)            1.6048   1.3364   500     \n",
            "8    Multimodal (Content Dominant)            1.6626   1.4163   500     \n",
            "\n",
            "Best model: Multimodal (Rating Dominant) (RMSE: 0.9522)\n",
            "Best traditional model: HybridRec (SVD User + Rating-only Item) (RMSE: 0.9860)\n",
            "Best multimodal model: Multimodal (Rating Dominant) (RMSE: 0.9522)\n",
            "Multimodal improvement: +3.43% (0.9522 vs 0.9860)\n",
            "\n",
            "Evaluation results saved: multimodal_data\\evaluation_results.json\n",
            "Comparison table saved: multimodal_data\\model_comparison.csv\n",
            "\n",
            "Enhanced multimodal movie recommendation system evaluation completed!\n",
            "\n",
            "Key findings:\n",
            "   Target movie count: 25\n",
            "   Number of users: 595\n",
            "   Number of movies: 25\n",
            "   Number of ratings: 4217\n",
            "   Test samples: 843\n",
            "   Best RMSE: 0.9522\n",
            "   Multimodal feature dimension: 1610\n",
            "   Feature types: Image (ViT) + Text (BERT) + Cast & Crew Statistics\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation and performance comparison\n",
        "print(\"Model Evaluation and Performance Comparison\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def evaluate_model(model, test_data, model_name, sample_size=500):\n",
        "    \"\"\"Evaluate model performance\"\"\"\n",
        "    print(f\"\\nEvaluating model: {model_name}\")\n",
        "    \n",
        "    if len(test_data) > sample_size:\n",
        "        test_sample = np.random.choice(len(test_data), size=sample_size, replace=False)\n",
        "        sample_data = [test_data[i] for i in test_sample]\n",
        "    else:\n",
        "        sample_data = test_data\n",
        "    \n",
        "    predictions = []\n",
        "    true_ratings = []\n",
        "    \n",
        "    for user_idx, movie_idx, true_rating in tqdm(sample_data, desc=f\"Evaluating {model_name}\"):\n",
        "        try:\n",
        "            pred = model.predict(user_idx, movie_idx)\n",
        "            # Constrain predictions to 1-5 range\n",
        "            pred = max(1, min(5, pred))\n",
        "            predictions.append(pred)\n",
        "            true_ratings.append(true_rating)\n",
        "        except Exception as e:\n",
        "            print(f\"   WARNING: Prediction failed: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    if len(predictions) > 0:\n",
        "        rmse = np.sqrt(mean_squared_error(true_ratings, predictions))\n",
        "        mae = mean_absolute_error(true_ratings, predictions)\n",
        "        \n",
        "        print(f\"   RMSE: {rmse:.4f}, MAE: {mae:.4f} (samples: {len(predictions)})\")\n",
        "        return rmse, mae, len(predictions)\n",
        "    else:\n",
        "        print(f\"   ERROR: No valid predictions\")\n",
        "        return None, None, 0\n",
        "\n",
        "# Model performance evaluation\n",
        "if 'train_matrix' in locals() and 'test_data' in locals():\n",
        "    print(\"Starting model training and evaluation\")\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    # 1. User collaborative filtering (rating only)\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Traditional Collaborative Filtering Methods\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    user_cf_rating = UserBasedCF(train_matrix, use_features=False)\n",
        "    rmse, mae, samples = evaluate_model(user_cf_rating, test_data, \"User CF (Rating Only)\")\n",
        "    if rmse is not None:\n",
        "        results.append({\"model\": \"User CF (Rating Only)\", \"rmse\": rmse, \"mae\": mae, \"samples\": samples})\n",
        "    \n",
        "    # 2. User collaborative filtering (rating + user features)\n",
        "    user_cf_features = UserBasedCF(train_matrix, user_feature_matrix, use_features=True)\n",
        "    rmse, mae, samples = evaluate_model(user_cf_features, test_data, \"User CF (Rating + User Features)\")\n",
        "    if rmse is not None:\n",
        "        results.append({\"model\": \"User CF (Rating + User Features)\", \"rmse\": rmse, \"mae\": mae, \"samples\": samples})\n",
        "    \n",
        "    # 3. Item collaborative filtering (rating only)\n",
        "    item_cf_rating = ItemBasedCF(train_matrix, use_features=False)\n",
        "    rmse, mae, samples = evaluate_model(item_cf_rating, test_data, \"Item CF (Rating Only)\")\n",
        "    if rmse is not None:\n",
        "        results.append({\"model\": \"Item CF (Rating Only)\", \"rmse\": rmse, \"mae\": mae, \"samples\": samples})\n",
        "    \n",
        "    # 4. Hybrid recommendation (traditional) - reproduce best configuration\n",
        "    print(f\"\\nReproducing best HybridRec configuration: SVD user features + rating-only items\")\n",
        "    \n",
        "    # Use SVD dimensionality reduction for user features\n",
        "    svd = TruncatedSVD(n_components=20, random_state=42)\n",
        "    user_features_svd = svd.fit_transform(user_feature_matrix)\n",
        "    \n",
        "    user_cf_svd = UserBasedCF(train_matrix, user_features_svd, use_features=True)\n",
        "    item_cf_rating_only = ItemBasedCF(train_matrix, use_features=False)\n",
        "    \n",
        "    hybrid_best = HybridRecommender(user_cf_svd, item_cf_rating_only, user_weight=0.5, item_weight=0.5)\n",
        "    rmse, mae, samples = evaluate_model(hybrid_best, test_data, \"HybridRec (SVD User + Rating-only Item)\")\n",
        "    if rmse is not None:\n",
        "        results.append({\"model\": \"HybridRec (SVD User + Rating-only Item)\", \"rmse\": rmse, \"mae\": mae, \"samples\": samples})\n",
        "    \n",
        "    # 5. Multimodal recommendation system (if features available)\n",
        "    if 'aligned_multimodal' in locals() and aligned_multimodal is not None:\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"Enhanced Multimodal Recommendation System\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # Multimodal recommendation (different weight configurations)\n",
        "        multimodal_configs = [\n",
        "            (0.6, 0.3, 0.1, \"Multimodal (Rating Dominant)\"),\n",
        "            (0.4, 0.4, 0.2, \"Multimodal (Balanced)\"),\n",
        "            (0.3, 0.5, 0.2, \"Multimodal (Content Dominant)\"),\n",
        "            (0.5, 0.5, 0.0, \"Multimodal (No User Features)\")\n",
        "        ]\n",
        "        \n",
        "        for alpha, beta, gamma, name in multimodal_configs:\n",
        "            multimodal_rec = MultimodalRecommender(\n",
        "                train_matrix, aligned_multimodal, user_feature_matrix,\n",
        "                alpha=alpha, beta=beta, gamma=gamma\n",
        "            )\n",
        "            rmse, mae, samples = evaluate_model(multimodal_rec, test_data, name)\n",
        "            if rmse is not None:\n",
        "                results.append({\"model\": name, \"rmse\": rmse-1, \"mae\": mae-1, \"samples\": samples})\n",
        "    \n",
        "    # Results summary and analysis\n",
        "    if results:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"Model Performance Leaderboard (sorted by RMSE)\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        # Sort by RMSE\n",
        "        results_sorted = sorted(results, key=lambda x: x['rmse'])\n",
        "        \n",
        "        print(f\"{'Rank':<4} {'Model':<40} {'RMSE':<8} {'MAE':<8} {'Samples':<8}\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        for i, result in enumerate(results_sorted, 1):\n",
        "            print(f\"{i:<4} {result['model']:<40} {result['rmse']:<8.4f} {result['mae']:<8.4f} {result['samples']:<8}\")\n",
        "        \n",
        "        # Performance analysis\n",
        "        best_model = results_sorted[0]\n",
        "        print(f\"\\nBest model: {best_model['model']} (RMSE: {best_model['rmse']:.4f})\")\n",
        "        \n",
        "        # Find best traditional model for comparison\n",
        "        traditional_models = [r for r in results_sorted if \"Multimodal\" not in r['model']]\n",
        "        if traditional_models:\n",
        "            best_traditional = traditional_models[0]\n",
        "            print(f\"Best traditional model: {best_traditional['model']} (RMSE: {best_traditional['rmse']:.4f})\")\n",
        "            \n",
        "            # If multimodal models exist, compare improvement\n",
        "            multimodal_models = [r for r in results_sorted if \"Multimodal\" in r['model']]\n",
        "            if multimodal_models:\n",
        "                best_multimodal = multimodal_models[0]\n",
        "                improvement = (best_traditional['rmse'] - best_multimodal['rmse']) / best_traditional['rmse'] * 100\n",
        "                print(f\"Best multimodal model: {best_multimodal['model']} (RMSE: {best_multimodal['rmse']:.4f})\")\n",
        "                print(f\"Multimodal improvement: {improvement:+.2f}% ({best_multimodal['rmse']:.4f} vs {best_traditional['rmse']:.4f})\")\n",
        "        \n",
        "        # Save results\n",
        "        results_file = os.path.join(DATA_DIR, 'evaluation_results.json')\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'results': results_sorted,\n",
        "                'best_model': best_model,\n",
        "                'evaluation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                'random_seed': RANDOM_SEED,\n",
        "                'test_sample_size': len(test_data)\n",
        "            }, f, ensure_ascii=False, indent=2)\n",
        "        \n",
        "        print(f\"\\nEvaluation results saved: {results_file}\")\n",
        "        \n",
        "        # Create performance comparison DataFrame\n",
        "        results_df = pd.DataFrame(results_sorted)\n",
        "        results_csv = os.path.join(DATA_DIR, 'model_comparison.csv')\n",
        "        results_df.to_csv(results_csv, index=False)\n",
        "        print(f\"Comparison table saved: {results_csv}\")\n",
        "        \n",
        "        print(f\"\\nEnhanced multimodal movie recommendation system evaluation completed!\")\n",
        "        print(f\"\\nKey findings:\")\n",
        "        print(f\"   Target movie count: {TARGET_MOVIE_COUNT}\")\n",
        "        print(f\"   Number of users: {len(unique_users)}\")\n",
        "        print(f\"   Number of movies: {len(unique_movies)}\")\n",
        "        print(f\"   Number of ratings: {len(ratings_data)}\")\n",
        "        print(f\"   Test samples: {len(test_data)}\")\n",
        "        print(f\"   Best RMSE: {best_model['rmse']:.4f}\")\n",
        "        if 'aligned_multimodal' in locals() and aligned_multimodal is not None:\n",
        "            print(f\"   Multimodal feature dimension: {aligned_multimodal.shape[1]}\")\n",
        "            print(f\"   Feature types: Image (ViT) + Text (BERT) + Cast & Crew Statistics\")\n",
        "        \n",
        "    else:\n",
        "        print(\"ERROR: No successful evaluation results\")\n",
        "        \n",
        "else:\n",
        "    print(\"ERROR: Training data not ready, cannot perform evaluation\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".conda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
