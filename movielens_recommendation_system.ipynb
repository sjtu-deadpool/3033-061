{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# MovieLens 100k 电影推荐系统 - 第一阶段\n",
        "\n",
        "## 项目概述\n",
        "基于MovieLens 100k数据集构建一个基础的电影推荐系统，采用渐进式开发方法：\n",
        "- **阶段1**: 数据处理 + 协同过滤推荐\n",
        "- **阶段2**: 加入内容特征 + 混合推荐\n",
        "- **阶段3**: 多模态特征融合（如有时间）\n",
        "\n",
        "本notebook专注于第一阶段的实现。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 环境设置和数据加载\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 环境配置与依赖安装\n",
        "# ===========================\n",
        "# 首次运行项目时请执行此cell安装依赖\n",
        "\n",
        "# 方法1：自动安装requirements.txt（推荐）\n",
        "# !pip install -r requirements.txt\n",
        "\n",
        "# 方法2：快速安装核心依赖\n",
        "# !pip install pandas numpy scikit-learn matplotlib seaborn ipykernel\n",
        "\n",
        "# 方法3：使用conda安装（如果使用conda环境）\n",
        "# !conda install pandas numpy scikit-learn matplotlib seaborn jupyter -y\n",
        "\n",
        "print(\"注意: 请根据需要取消注释上面的安装命令并运行\")\n",
        "print(\"建议: 使用方法1安装完整依赖列表\")\n",
        "print(\"提示: 安装完成后可以注释掉本cell避免重复安装\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.conda (Python 3.11.13)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p z:\\Document\\MyProject\\3033-061\\.conda ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# 安装项目依赖\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_requirements():\n",
        "    \"\"\"安装requirements.txt中的依赖包\"\"\"\n",
        "    try:\n",
        "        print(\"正在安装项目依赖...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
        "        print(\"依赖安装完成!\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"依赖安装失败: {e}\")\n",
        "        print(\"请手动运行: pip install -r requirements.txt\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"requirements.txt文件不存在，跳过自动安装\")\n",
        "\n",
        "# 运行依赖安装（首次运行时）\n",
        "install_requirements()\n",
        "\n",
        "# 导入必要的库\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 设置图表样式\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "print(\"环境设置完成!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载MovieLens 100k数据集\n",
        "def load_movielens_data(data_path='ml-100k'):\n",
        "    \"\"\"\n",
        "    加载MovieLens 100k数据集\n",
        "    \n",
        "    Returns:\n",
        "        ratings: 评分数据\n",
        "        movies: 电影数据\n",
        "        users: 用户数据\n",
        "    \"\"\"\n",
        "    print(\"正在加载MovieLens 100k数据集...\")\n",
        "    \n",
        "    # 加载评分数据\n",
        "    ratings = pd.read_csv(\n",
        "        f'{data_path}/u.data', \n",
        "        sep='\\t', \n",
        "        names=['user_id', 'movie_id', 'rating', 'timestamp'],\n",
        "        encoding='latin-1'\n",
        "    )\n",
        "    \n",
        "    # 加载电影数据\n",
        "    movie_columns = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url'] + \\\n",
        "                   [f'genre_{i}' for i in range(19)]\n",
        "    movies = pd.read_csv(\n",
        "        f'{data_path}/u.item', \n",
        "        sep='|', \n",
        "        names=movie_columns,\n",
        "        encoding='latin-1'\n",
        "    )\n",
        "    \n",
        "    # 加载用户数据\n",
        "    users = pd.read_csv(\n",
        "        f'{data_path}/u.user', \n",
        "        sep='|', \n",
        "        names=['user_id', 'age', 'gender', 'occupation', 'zipcode'],\n",
        "        encoding='latin-1'\n",
        "    )\n",
        "    \n",
        "    print(\"数据加载完成!\")\n",
        "    print(f\"   - 评分数据: {len(ratings):,} 条记录\")\n",
        "    print(f\"   - 电影数据: {len(movies):,} 部电影\")\n",
        "    print(f\"   - 用户数据: {len(users):,} 位用户\")\n",
        "    \n",
        "    return ratings, movies, users\n",
        "\n",
        "# 加载数据\n",
        "ratings, movies, users = load_movielens_data()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 数据预处理和探索性分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 数据基本信息\n",
        "print(\"数据集基本信息:\")\n",
        "print(f\"总评分数: {len(ratings):,}\")\n",
        "print(f\"独立用户数: {ratings['user_id'].nunique():,}\")\n",
        "print(f\"独立电影数: {ratings['movie_id'].nunique():,}\")\n",
        "print(f\"评分范围: {ratings['rating'].min()} - {ratings['rating'].max()}\")\n",
        "print(f\"平均评分: {ratings['rating'].mean():.2f}\")\n",
        "\n",
        "# 数据稀疏度\n",
        "sparsity = 1 - len(ratings) / (ratings['user_id'].nunique() * ratings['movie_id'].nunique())\n",
        "print(f\"数据稀疏度: {sparsity*100:.2f}%\")\n",
        "\n",
        "# 显示前几行数据\n",
        "print(\"\\n评分数据样例:\")\n",
        "print(ratings.head())\n",
        "\n",
        "print(\"\\n电影数据样例:\")\n",
        "print(movies[['movie_id', 'title', 'release_date']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建用户-电影评分矩阵\n",
        "def create_rating_matrix(ratings_df):\n",
        "    \"\"\"\n",
        "    创建用户-电影评分矩阵\n",
        "    \n",
        "    Args:\n",
        "        ratings_df: 评分数据DataFrame\n",
        "        \n",
        "    Returns:\n",
        "        rating_matrix: pivot后的评分矩阵\n",
        "    \"\"\"\n",
        "    rating_matrix = ratings_df.pivot_table(\n",
        "        index='user_id', \n",
        "        columns='movie_id', \n",
        "        values='rating', \n",
        "        fill_value=0\n",
        "    )\n",
        "    \n",
        "    print(f\"评分矩阵维度: {rating_matrix.shape}\")\n",
        "    print(f\"非零评分比例: {(rating_matrix != 0).sum().sum() / (rating_matrix.shape[0] * rating_matrix.shape[1]) * 100:.2f}%\")\n",
        "    \n",
        "    return rating_matrix\n",
        "\n",
        "# 创建评分矩阵\n",
        "rating_matrix = create_rating_matrix(ratings)\n",
        "print(\"\\n评分矩阵示例:\")\n",
        "print(rating_matrix.iloc[:5, :5])\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. 数据分割和简单推荐算法实现\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 分割训练集和测试集\n",
        "train_ratings, test_ratings = train_test_split(\n",
        "    ratings, \n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    stratify=ratings['rating']  # 按评分分层抽样\n",
        ")\n",
        "\n",
        "print(\"数据分割完成:\")\n",
        "print(f\"   训练集: {len(train_ratings):,} 条记录 ({len(train_ratings)/len(ratings)*100:.1f}%)\")\n",
        "print(f\"   测试集: {len(test_ratings):,} 条记录 ({len(test_ratings)/len(ratings)*100:.1f}%)\")\n",
        "\n",
        "# 创建训练集评分矩阵\n",
        "train_matrix = create_rating_matrix(train_ratings)\n",
        "print(\"\\n训练集评分矩阵创建完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 基于用户的协同过滤推荐算法\n",
        "class SimpleUserBasedCF:\n",
        "    \"\"\"\n",
        "    简化版基于用户的协同过滤推荐系统\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, rating_matrix):\n",
        "        self.rating_matrix = rating_matrix\n",
        "        self.user_similarity = None\n",
        "        \n",
        "    def compute_user_similarity(self):\n",
        "        \"\"\"计算用户相似度矩阵\"\"\"\n",
        "        print(\"计算用户相似度矩阵...\")\n",
        "        self.user_similarity = cosine_similarity(self.rating_matrix)\n",
        "        print(f\"用户相似度矩阵计算完成! 形状: {self.user_similarity.shape}\")\n",
        "    \n",
        "    def predict_rating(self, user_id, movie_id, k=20):\n",
        "        \"\"\"\n",
        "        预测用户对电影的评分\n",
        "        \n",
        "        Args:\n",
        "            user_id: 用户ID\n",
        "            movie_id: 电影ID\n",
        "            k: 使用最相似的k个用户\n",
        "            \n",
        "        Returns:\n",
        "            predicted_rating: 预测评分\n",
        "        \"\"\"\n",
        "        if self.user_similarity is None:\n",
        "            self.compute_user_similarity()\n",
        "        \n",
        "        try:\n",
        "            user_idx = self.rating_matrix.index.get_loc(user_id)\n",
        "        except KeyError:\n",
        "            return self.rating_matrix.mean().mean()\n",
        "        \n",
        "        if movie_id not in self.rating_matrix.columns:\n",
        "            return self.rating_matrix.iloc[user_idx].mean()\n",
        "        \n",
        "        # 获取该用户与其他用户的相似度\n",
        "        user_similarities = self.user_similarity[user_idx]\n",
        "        \n",
        "        # 获取对该电影有评分的用户\n",
        "        movie_ratings = self.rating_matrix[movie_id]\n",
        "        rated_users = movie_ratings[movie_ratings > 0]\n",
        "        \n",
        "        if len(rated_users) == 0:\n",
        "            return self.rating_matrix.iloc[user_idx].mean()\n",
        "        \n",
        "        # 获取相似用户的评分和相似度\n",
        "        similar_ratings = []\n",
        "        similar_similarities = []\n",
        "        \n",
        "        for similar_user_id in rated_users.index:\n",
        "            if similar_user_id != user_id:\n",
        "                similar_user_idx = self.rating_matrix.index.get_loc(similar_user_id)\n",
        "                similarity = user_similarities[similar_user_idx]\n",
        "                if similarity > 0:\n",
        "                    similar_ratings.append(rated_users[similar_user_id])\n",
        "                    similar_similarities.append(similarity)\n",
        "        \n",
        "        if len(similar_ratings) == 0:\n",
        "            return self.rating_matrix.iloc[user_idx].mean()\n",
        "        \n",
        "        # 选择top-k相似用户\n",
        "        if len(similar_ratings) > k:\n",
        "            top_k_indices = np.argsort(similar_similarities)[-k:]\n",
        "            similar_ratings = np.array(similar_ratings)[top_k_indices]\n",
        "            similar_similarities = np.array(similar_similarities)[top_k_indices]\n",
        "        \n",
        "        # 计算加权平均评分\n",
        "        if np.sum(similar_similarities) == 0:\n",
        "            return np.mean(similar_ratings)\n",
        "        \n",
        "        predicted_rating = np.average(similar_ratings, weights=similar_similarities)\n",
        "        return np.clip(predicted_rating, 1, 5)\n",
        "    \n",
        "    def recommend_movies(self, user_id, n_recommendations=5):\n",
        "        \"\"\"为用户推荐电影\"\"\"\n",
        "        if user_id not in self.rating_matrix.index:\n",
        "            print(f\"用户 {user_id} 不存在于训练数据中\")\n",
        "            return []\n",
        "        \n",
        "        user_ratings = self.rating_matrix.loc[user_id]\n",
        "        unrated_movies = user_ratings[user_ratings == 0].index\n",
        "        \n",
        "        predictions = []\n",
        "        for movie_id in unrated_movies[:100]:  # 限制数量以提高速度\n",
        "            predicted_rating = self.predict_rating(user_id, movie_id)\n",
        "            predictions.append((movie_id, predicted_rating))\n",
        "        \n",
        "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "        return predictions[:n_recommendations]\n",
        "\n",
        "# 创建并训练模型\n",
        "user_cf = SimpleUserBasedCF(train_matrix)\n",
        "user_cf.compute_user_similarity()\n",
        "print(\"\\n基于用户的协同过滤模型创建完成!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. 模型评估和推荐展示\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 模型评估\n",
        "def evaluate_model(model, test_ratings_sample):\n",
        "    \"\"\"评估推荐模型性能\"\"\"\n",
        "    print(\"评估模型性能...\")\n",
        "    \n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    \n",
        "    for _, row in test_ratings_sample.iterrows():\n",
        "        user_id = row['user_id']\n",
        "        movie_id = row['movie_id']\n",
        "        actual_rating = row['rating']\n",
        "        \n",
        "        predicted_rating = model.predict_rating(user_id, movie_id)\n",
        "        \n",
        "        predictions.append(predicted_rating)\n",
        "        actuals.append(actual_rating)\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
        "    mae = mean_absolute_error(actuals, predictions)\n",
        "    \n",
        "    print(\"模型评估完成:\")\n",
        "    print(f\"   RMSE: {rmse:.4f}\")\n",
        "    print(f\"   MAE: {mae:.4f}\")\n",
        "    \n",
        "    return rmse, mae\n",
        "\n",
        "# 使用测试集样本进行评估\n",
        "test_sample = test_ratings.sample(n=500, random_state=42)  # 使用500个样本\n",
        "rmse, mae = evaluate_model(user_cf, test_sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 推荐结果展示\n",
        "def display_recommendations(user_id, model, movies_df, n_recommendations=5):\n",
        "    \"\"\"展示推荐结果\"\"\"\n",
        "    print(f\"为用户 {user_id} 生成电影推荐:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # 显示用户历史高分电影\n",
        "    if user_id in train_matrix.index:\n",
        "        user_ratings = train_matrix.loc[user_id]\n",
        "        high_rated_movies = user_ratings[user_ratings >= 4].sort_values(ascending=False).head(3)\n",
        "        \n",
        "        print(f\"\\n用户 {user_id} 的历史高分电影 (≥4分):\")\n",
        "        for movie_id, rating in high_rated_movies.items():\n",
        "            movie_title = movies_df[movies_df['movie_id'] == movie_id]['title'].iloc[0]\n",
        "            print(f\"   • {movie_title}: {rating}分\")\n",
        "    \n",
        "    # 生成推荐\n",
        "    print(f\"\\n推荐的电影:\")\n",
        "    recommendations = model.recommend_movies(user_id, n_recommendations)\n",
        "    \n",
        "    if recommendations:\n",
        "        for i, (movie_id, predicted_rating) in enumerate(recommendations, 1):\n",
        "            movie_title = movies_df[movies_df['movie_id'] == movie_id]['title'].iloc[0]\n",
        "            print(f\"   {i}. {movie_title} (预测评分: {predicted_rating:.2f})\")\n",
        "    else:\n",
        "        print(\"   无法为该用户生成推荐\")\n",
        "\n",
        "# 选择一个测试用户并展示推荐\n",
        "test_user_id = train_matrix.index[10]  # 选择第11个用户\n",
        "display_recommendations(test_user_id, user_cf, movies)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. 数据可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建数据可视化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('MovieLens 100k 数据分析', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. 评分分布\n",
        "ratings['rating'].hist(bins=5, ax=axes[0,0], color='skyblue', edgecolor='black')\n",
        "axes[0,0].set_title('评分分布')\n",
        "axes[0,0].set_xlabel('评分')\n",
        "axes[0,0].set_ylabel('频次')\n",
        "\n",
        "# 2. 用户评分数量分布\n",
        "user_rating_counts = ratings.groupby('user_id').size()\n",
        "user_rating_counts.hist(bins=30, ax=axes[0,1], color='lightgreen', edgecolor='black')\n",
        "axes[0,1].set_title('用户评分数量分布')\n",
        "axes[0,1].set_xlabel('评分数量')\n",
        "axes[0,1].set_ylabel('用户数')\n",
        "\n",
        "# 3. 电影被评分数量分布\n",
        "movie_rating_counts = ratings.groupby('movie_id').size()\n",
        "movie_rating_counts.hist(bins=30, ax=axes[1,0], color='orange', edgecolor='black')\n",
        "axes[1,0].set_title('电影被评分数量分布')\n",
        "axes[1,0].set_xlabel('被评分次数')\n",
        "axes[1,0].set_ylabel('电影数')\n",
        "\n",
        "# 4. 评分矩阵稀疏性可视化（抽样）\n",
        "sample_matrix = rating_matrix.iloc[:30, :30]\n",
        "sns.heatmap(sample_matrix, ax=axes[1,1], cmap='Blues', cbar=True)\n",
        "axes[1,1].set_title('评分矩阵稀疏性 (30x30样本)')\n",
        "axes[1,1].set_xlabel('电影ID')\n",
        "axes[1,1].set_ylabel('用户ID')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"数据可视化完成!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. 总结和下一步计划\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 第一阶段总结\n",
        "print(\"=\" * 60)\n",
        "print(\"MovieLens 100k 推荐系统 - 第一阶段总结\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "完成的工作:\n",
        "   - 数据加载和预处理\n",
        "   - 用户-电影评分矩阵构建\n",
        "   - 基于用户的协同过滤算法实现\n",
        "   - 模型评估 (RMSE: {rmse:.4f}, MAE: {mae:.4f})\n",
        "   - 推荐结果展示和可视化\n",
        "\n",
        "数据集特征:\n",
        "   • 总评分数: {len(ratings):,}\n",
        "   • 用户数: {ratings['user_id'].nunique():,}\n",
        "   • 电影数: {ratings['movie_id'].nunique():,}\n",
        "   • 数据稀疏度: {sparsity*100:.1f}%\n",
        "   • 平均评分: {ratings['rating'].mean():.2f}\n",
        "\n",
        "下一步计划 (第二阶段):\n",
        "   1. 实现基于物品的协同过滤\n",
        "   2. 添加矩阵分解方法 (SVD)\n",
        "   3. 加入电影内容特征 (流派、年份等)\n",
        "   4. 实现混合推荐系统\n",
        "   5. 优化算法参数和性能\n",
        "   6. 解决冷启动问题\n",
        "\n",
        "技术要点:\n",
        "   • 协同过滤能够发现用户的隐式偏好\n",
        "   • 余弦相似度适合处理稀疏数据\n",
        "   • 需要平衡推荐准确性和多样性\n",
        "   • 数据稀疏性是推荐系统的主要挑战\n",
        "\"\"\")\n",
        "\n",
        "print(\"第一阶段完成! 基础推荐系统框架已建立。\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
