{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing project dependencies...\n",
            "[SUCCESS] pandas installed\n",
            "[SUCCESS] numpy installed\n",
            "[SUCCESS] scikit-learn installed\n",
            "[SUCCESS] matplotlib installed\n",
            "[SUCCESS] seaborn installed\n",
            "\n",
            "Dependencies installation completed!\n",
            "Environment setup completed!\n"
          ]
        }
      ],
      "source": [
        "# 1. Environment Setup and Dependencies Installation\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def install_requirements():\n",
        "    \"\"\"Install project dependencies\"\"\"\n",
        "    requirements = [\n",
        "        'pandas>=1.3.0',\n",
        "        'numpy>=1.21.0',\n",
        "        'scikit-learn>=1.0.0',\n",
        "        'matplotlib>=3.4.0',\n",
        "        'seaborn>=0.11.0'\n",
        "    ]\n",
        "    \n",
        "    print(\"Installing project dependencies...\")\n",
        "    for req in requirements:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', req, '--quiet'])\n",
        "            print(f\"[SUCCESS] {req.split('>=')[0]} installed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"[ERROR] {req} installation failed: {e}\")\n",
        "    \n",
        "    print(\"\\nDependencies installation completed!\")\n",
        "\n",
        "install_requirements()\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plot style\n",
        "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "print(\"Environment setup completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output directories created: english_output\n",
            "Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# 2. Configuration Parameters\n",
        "CONFIG = {\n",
        "    'RANDOM_SEED': 42,\n",
        "    'TEST_SIZE': 0.2,\n",
        "    'OUTPUT_PATH': 'english_output',\n",
        "    'DATA_PATH': 'ml-100k',\n",
        "    'K_NEIGHBORS': 20,\n",
        "    'N_RECOMMENDATIONS': 10\n",
        "}\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(CONFIG['OUTPUT_PATH'], exist_ok=True)\n",
        "os.makedirs(os.path.join(CONFIG['OUTPUT_PATH'], 'train_data'), exist_ok=True)\n",
        "os.makedirs(os.path.join(CONFIG['OUTPUT_PATH'], 'result'), exist_ok=True)\n",
        "\n",
        "print(f\"Output directories created: {CONFIG['OUTPUT_PATH']}\")\n",
        "print(f\"Random seed: {CONFIG['RANDOM_SEED']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MovieLens 100k dataset...\n",
            "Data loading completed!\n",
            "Ratings data: (100000, 4)\n",
            "Movies data: (1682, 24)\n",
            "Users data: (943, 5)\n",
            "Number of genres: 19\n"
          ]
        }
      ],
      "source": [
        "# 3. Data Loading\n",
        "print(\"Loading MovieLens 100k dataset...\")\n",
        "\n",
        "try:\n",
        "    # Load ratings data\n",
        "    ratings = pd.read_csv(\n",
        "        f\"{CONFIG['DATA_PATH']}/u.data\", \n",
        "        sep='\\t', \n",
        "        names=['user_id', 'movie_id', 'rating', 'timestamp'],\n",
        "        encoding='latin-1'\n",
        "    )\n",
        "\n",
        "    # Load movie data\n",
        "    movie_columns = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url'] + \\\n",
        "                   [f'genre_{i}' for i in range(19)]\n",
        "    movies = pd.read_csv(\n",
        "        f\"{CONFIG['DATA_PATH']}/u.item\", \n",
        "        sep='|', \n",
        "        names=movie_columns,\n",
        "        encoding='latin-1'\n",
        "    )\n",
        "\n",
        "    # Load user data\n",
        "    users = pd.read_csv(\n",
        "        f\"{CONFIG['DATA_PATH']}/u.user\", \n",
        "        sep='|', \n",
        "        names=['user_id', 'age', 'gender', 'occupation', 'zipcode'],\n",
        "        encoding='latin-1'\n",
        "    )\n",
        "\n",
        "    # Load genre data\n",
        "    genres = pd.read_csv(\n",
        "        f\"{CONFIG['DATA_PATH']}/u.genre\", \n",
        "        sep='|', \n",
        "        names=['genre', 'genre_id'],\n",
        "        encoding='latin-1'\n",
        "    ).dropna()\n",
        "    genre_names = genres['genre'].tolist()\n",
        "\n",
        "    print(\"Data loading completed!\")\n",
        "    print(f\"Ratings data: {ratings.shape}\")\n",
        "    print(f\"Movies data: {movies.shape}\")\n",
        "    print(f\"Users data: {users.shape}\")\n",
        "    print(f\"Number of genres: {len(genre_names)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Data loading failed: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Enhanced User Feature Engineering\n",
            "================================================================================\n",
            "User feature distribution:\n",
            "   Age range: 7-73 (mean: 34.1)\n",
            "   Gender distribution: {'M': 670, 'F': 273}\n",
            "   Age group distribution: {'Adult(25-34)': 310, 'Young(18-24)': 198, 'Middle-aged(35-44)': 194, 'Senior(50+)': 125, 'Pre-senior(45-49)': 80, 'Teenager(7-17)': 36}\n",
            "   Number of occupations: 21\n",
            "   Number of regions: 111\n",
            "\n",
            "Feature name mapping created, total features: 51\n"
          ]
        }
      ],
      "source": [
        "# 4. Enhanced User Feature Engineering\n",
        "def create_user_features_enhanced():\n",
        "    \"\"\"Create detailed user features\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Enhanced User Feature Engineering\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # User age grouping\n",
        "    def age_group(age):\n",
        "        if age < 18: return 'Teenager(7-17)'\n",
        "        elif age < 25: return 'Young(18-24)'\n",
        "        elif age < 35: return 'Adult(25-34)'\n",
        "        elif age < 45: return 'Middle-aged(35-44)'\n",
        "        elif age < 50: return 'Pre-senior(45-49)'\n",
        "        else: return 'Senior(50+)'\n",
        "\n",
        "    users['age_group'] = users['age'].apply(age_group)\n",
        "    users['region'] = users['zipcode'].str[:2]  # Extract region prefix\n",
        "\n",
        "    print(\"User feature distribution:\")\n",
        "    print(f\"   Age range: {users['age'].min()}-{users['age'].max()} (mean: {users['age'].mean():.1f})\")\n",
        "    print(f\"   Gender distribution: {users['gender'].value_counts().to_dict()}\")\n",
        "    print(f\"   Age group distribution: {users['age_group'].value_counts().to_dict()}\")\n",
        "    print(f\"   Number of occupations: {users['occupation'].nunique()}\")\n",
        "    print(f\"   Number of regions: {users['region'].nunique()}\")\n",
        "\n",
        "    # Create feature name mapping for analysis\n",
        "    def create_user_feature_names():\n",
        "        \"\"\"Create user feature name mapping\"\"\"\n",
        "        feature_names = []\n",
        "        \n",
        "        # Normalized age (1 dimension)\n",
        "        feature_names.append('Age(normalized)')\n",
        "        \n",
        "        # Age group one-hot (6 dimensions)\n",
        "        age_groups = sorted(users['age_group'].unique())\n",
        "        for ag in age_groups:\n",
        "            feature_names.append(f'AgeGroup_{ag}')\n",
        "        \n",
        "        # Gender one-hot (2 dimensions)\n",
        "        genders = sorted(users['gender'].unique())\n",
        "        for g in genders:\n",
        "            gender_name = 'Female' if g == 'F' else 'Male'\n",
        "            feature_names.append(f'Gender_{gender_name}')\n",
        "        \n",
        "        # Occupation one-hot (21 dimensions)\n",
        "        occupations = sorted(users['occupation'].unique())\n",
        "        for occ in occupations:\n",
        "            feature_names.append(f'Occupation_{occ.title()}')\n",
        "        \n",
        "        # Region one-hot (top 20 regions + others)\n",
        "        top_regions = users['region'].value_counts().head(20).index\n",
        "        for region in top_regions:\n",
        "            feature_names.append(f'Region_{region}')\n",
        "        feature_names.append('Region_Other')\n",
        "        \n",
        "        return feature_names\n",
        "\n",
        "    global user_feature_names\n",
        "    user_feature_names = create_user_feature_names()\n",
        "    print(f\"\\nFeature name mapping created, total features: {len(user_feature_names)}\")\n",
        "\n",
        "    return users\n",
        "\n",
        "users = create_user_features_enhanced()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Enhanced Movie Feature Engineering\n",
        "def create_movie_features_enhanced():\n",
        "    \"\"\"Create detailed movie features\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Enhanced Movie Feature Engineering\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Extract year information\n",
        "    movies['year'] = movies['title'].str.extract(r'\\((\\d{4})\\)$')\n",
        "    movies['year'] = pd.to_numeric(movies['year'], errors='coerce')\n",
        "    movies['year'] = movies['year'].fillna(movies['year'].median())\n",
        "    movies['decade'] = (movies['year'] // 10 * 10).astype(int)\n",
        "\n",
        "    print(\"Movie feature distribution:\")\n",
        "    print(f\"   Total movies: {len(movies)}\")\n",
        "    print(f\"   Year range: {movies['year'].min():.0f}-{movies['year'].max():.0f}\")\n",
        "    print(f\"   Number of genres: {len(genre_names)}\")\n",
        "    print(f\"   Decade distribution: {movies['decade'].value_counts().sort_index().to_dict()}\")\n",
        "\n",
        "    # Create movie feature name mapping\n",
        "    def create_movie_feature_names():\n",
        "        \"\"\"Create movie feature name mapping\"\"\"\n",
        "        feature_names = []\n",
        "        \n",
        "        # Genre features (19 dimensions)\n",
        "        for genre in genre_names:\n",
        "            feature_names.append(f'Genre_{genre}')\n",
        "        \n",
        "        # Normalized year (1 dimension)\n",
        "        feature_names.append('Year(normalized)')\n",
        "        \n",
        "        # Decade one-hot\n",
        "        decades = sorted(movies['decade'].unique())\n",
        "        for decade in decades:\n",
        "            feature_names.append(f'Decade_{int(decade)}s')\n",
        "        \n",
        "        return feature_names\n",
        "\n",
        "    global movie_feature_names\n",
        "    movie_feature_names = create_movie_feature_names()\n",
        "    print(f\"\\nMovie feature name mapping created, total features: {len(movie_feature_names)}\")\n",
        "\n",
        "    return movies\n",
        "\n",
        "movies = create_movie_features_enhanced()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Feature Engineering and PCA/SVD Comparison Analysis (Enhanced: Including Genre-only Features)\n",
        "def create_features_with_detailed_analysis():\n",
        "    \"\"\"Create features and perform detailed PCA/SVD comparison analysis\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Feature Engineering and Detailed PCA/SVD Comparison Analysis (Enhanced)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Create rating matrix\n",
        "    rating_matrix = ratings.pivot_table(index='user_id', columns='movie_id', values='rating', fill_value=0)\n",
        "    print(f\"Rating matrix shape: {rating_matrix.shape}\")\n",
        "\n",
        "    # === User Feature Engineering ===\n",
        "    print(\"\\nUser feature engineering:\")\n",
        "    user_features_list = []\n",
        "    \n",
        "    # Age normalization\n",
        "    age_scaler = StandardScaler()\n",
        "    age_normalized = age_scaler.fit_transform(users[['age']])\n",
        "    user_features_list.append(age_normalized)\n",
        "    \n",
        "    # Age group one-hot encoding\n",
        "    age_dummies = pd.get_dummies(users['age_group']).values\n",
        "    user_features_list.append(age_dummies)\n",
        "    \n",
        "    # Gender one-hot encoding\n",
        "    gender_dummies = pd.get_dummies(users['gender']).values\n",
        "    user_features_list.append(gender_dummies)\n",
        "    \n",
        "    # Occupation one-hot encoding\n",
        "    occupation_dummies = pd.get_dummies(users['occupation']).values\n",
        "    user_features_list.append(occupation_dummies)\n",
        "    \n",
        "    # Region one-hot encoding (top 20 most common regions)\n",
        "    top_regions = users['region'].value_counts().head(20).index\n",
        "    users['region_top'] = users['region'].where(users['region'].isin(top_regions), 'other')\n",
        "    region_dummies = pd.get_dummies(users['region_top']).values\n",
        "    user_features_list.append(region_dummies)\n",
        "    \n",
        "    # Combine user features\n",
        "    user_features_raw = np.hstack(user_features_list)\n",
        "    print(f\"Raw user feature dimensions: {user_features_raw.shape[1]}\")\n",
        "\n",
        "    # === Movie Feature Engineering ===\n",
        "    print(\"\\nMovie feature engineering:\")\n",
        "    \n",
        "    # Get movie IDs in rating matrix and maintain order\n",
        "    matrix_movie_ids = rating_matrix.columns\n",
        "    movies_in_matrix = movies[movies['movie_id'].isin(matrix_movie_ids)].copy()\n",
        "    movies_in_matrix = movies_in_matrix.set_index('movie_id').reindex(matrix_movie_ids).reset_index()\n",
        "    \n",
        "    # Genre features (genre-only)\n",
        "    genre_features = movies_in_matrix[[f'genre_{i}' for i in range(19)]].values\n",
        "    print(f\"Genre-only feature dimensions: {genre_features.shape[1]}\")\n",
        "    \n",
        "    # Complete movie features (genre + year + decade)\n",
        "    movie_features_list = []\n",
        "    movie_features_list.append(genre_features)\n",
        "    \n",
        "    # Year normalization\n",
        "    year_scaler = StandardScaler()\n",
        "    year_normalized = year_scaler.fit_transform(movies_in_matrix[['year']])\n",
        "    movie_features_list.append(year_normalized)\n",
        "    \n",
        "    # Decade one-hot encoding\n",
        "    decade_dummies = pd.get_dummies(movies_in_matrix['decade'], prefix='decade').values\n",
        "    movie_features_list.append(decade_dummies)\n",
        "    \n",
        "    # Combine complete movie features\n",
        "    movie_features_raw = np.hstack(movie_features_list)\n",
        "    print(f\"Complete movie feature dimensions: {movie_features_raw.shape[1]}\")\n",
        "\n",
        "    # === PCA Dimensionality Reduction ===\n",
        "    print(\"\\nPCA dimensionality reduction analysis:\")\n",
        "    \n",
        "    # User feature PCA\n",
        "    user_pca = PCA(n_components=0.85, random_state=CONFIG['RANDOM_SEED'])\n",
        "    user_features_pca = user_pca.fit_transform(user_features_raw)\n",
        "    print(f\"User PCA: {user_features_raw.shape[1]}D -> {user_features_pca.shape[1]}D (explained variance: {user_pca.explained_variance_ratio_.sum():.3%})\")\n",
        "    \n",
        "    # Movie complete feature PCA\n",
        "    movie_pca = PCA(n_components=0.90, random_state=CONFIG['RANDOM_SEED'])\n",
        "    movie_features_pca = movie_pca.fit_transform(movie_features_raw)\n",
        "    print(f\"Movie complete feature PCA: {movie_features_raw.shape[1]}D -> {movie_features_pca.shape[1]}D (explained variance: {movie_pca.explained_variance_ratio_.sum():.3%})\")\n",
        "    \n",
        "    # Movie genre-only feature PCA\n",
        "    genre_pca_components = min(genre_features.shape[1]-1, int(genre_features.shape[1]*0.95))\n",
        "    movie_genre_pca = PCA(n_components=genre_pca_components, random_state=CONFIG['RANDOM_SEED'])\n",
        "    movie_genre_features_pca = movie_genre_pca.fit_transform(genre_features)\n",
        "    print(f\"Movie genre-only PCA: {genre_features.shape[1]}D -> {movie_genre_features_pca.shape[1]}D (explained variance: {movie_genre_pca.explained_variance_ratio_.sum():.3%})\")\n",
        "\n",
        "    # === SVD Dimensionality Reduction ===\n",
        "    print(\"\\nSVD dimensionality reduction analysis:\")\n",
        "    \n",
        "    # User feature SVD\n",
        "    user_svd_components = min(user_features_raw.shape[1]-1, user_features_pca.shape[1])\n",
        "    user_svd = TruncatedSVD(n_components=user_svd_components, random_state=CONFIG['RANDOM_SEED']+1)\n",
        "    user_features_svd = user_svd.fit_transform(user_features_raw)\n",
        "    print(f\"User SVD: {user_features_raw.shape[1]}D -> {user_features_svd.shape[1]}D (explained variance: {user_svd.explained_variance_ratio_.sum():.3%})\")\n",
        "    \n",
        "    # Movie complete feature SVD\n",
        "    movie_svd_components = min(movie_features_raw.shape[1]-1, movie_features_pca.shape[1])\n",
        "    movie_svd = TruncatedSVD(n_components=movie_svd_components, random_state=CONFIG['RANDOM_SEED']+2)\n",
        "    movie_features_svd = movie_svd.fit_transform(movie_features_raw)\n",
        "    print(f\"Movie complete feature SVD: {movie_features_raw.shape[1]}D -> {movie_features_svd.shape[1]}D (explained variance: {movie_svd.explained_variance_ratio_.sum():.3%})\")\n",
        "    \n",
        "    # Movie genre-only feature SVD\n",
        "    genre_svd_components = min(genre_features.shape[1]-1, movie_genre_features_pca.shape[1])\n",
        "    movie_genre_svd = TruncatedSVD(n_components=genre_svd_components, random_state=CONFIG['RANDOM_SEED']+3)\n",
        "    movie_genre_features_svd = movie_genre_svd.fit_transform(genre_features)\n",
        "    print(f\"Movie genre-only SVD: {genre_features.shape[1]}D -> {movie_genre_features_svd.shape[1]}D (explained variance: {movie_genre_svd.explained_variance_ratio_.sum():.3%})\")\n",
        "\n",
        "    # === Detailed Feature Importance Analysis ===\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Detailed Feature Importance Analysis (PCA vs SVD)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # User feature importance analysis\n",
        "    print(\"User Feature Importance Analysis\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # PCA user feature importance\n",
        "    print(\"PCA - Most important original features for User PC1:\")\n",
        "    user_pc1_weights = np.abs(user_pca.components_[0])\n",
        "    top_user_features_pca = np.argsort(user_pc1_weights)[-10:]\n",
        "    for i, idx in enumerate(reversed(top_user_features_pca)):\n",
        "        feature_name = user_feature_names[idx] if idx < len(user_feature_names) else f'Feature{idx}'\n",
        "        print(f\"     {i+1:2d}. {feature_name:<30} - weight={user_pc1_weights[idx]:.4f}\")\n",
        "\n",
        "    print(\"PCA - First 3 principal components contribution:\")\n",
        "    for i in range(min(3, len(user_pca.explained_variance_ratio_))):\n",
        "        print(f\"     PC{i+1}: {user_pca.explained_variance_ratio_[i]:.3%}\")\n",
        "\n",
        "    # SVD user feature importance\n",
        "    print(\"SVD - Most important original features for User dimension 1:\")\n",
        "    user_svd_weights = np.abs(user_svd.components_[0])\n",
        "    top_user_features_svd = np.argsort(user_svd_weights)[-10:]\n",
        "    for i, idx in enumerate(reversed(top_user_features_svd)):\n",
        "        feature_name = user_feature_names[idx] if idx < len(user_feature_names) else f'Feature{idx}'\n",
        "        print(f\"     {i+1:2d}. {feature_name:<30} - weight={user_svd_weights[idx]:.4f}\")\n",
        "\n",
        "    print(\"SVD - First 3 dimensions contribution:\")\n",
        "    for i in range(min(3, len(user_svd.explained_variance_ratio_))):\n",
        "        print(f\"     SVD{i+1}: {user_svd.explained_variance_ratio_[i]:.3%}\")\n",
        "\n",
        "    # Movie feature importance analysis\n",
        "    print(\"Movie Feature Importance Analysis\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # PCA movie complete feature importance\n",
        "    print(\"PCA - Most important original features for Movie complete PC1:\")\n",
        "    movie_pc1_weights = np.abs(movie_pca.components_[0])\n",
        "    top_movie_features_pca = np.argsort(movie_pc1_weights)[-10:]\n",
        "    for i, idx in enumerate(reversed(top_movie_features_pca)):\n",
        "        feature_name = movie_feature_names[idx] if idx < len(movie_feature_names) else f'Feature{idx}'\n",
        "        print(f\"     {i+1:2d}. {feature_name:<30} - weight={movie_pc1_weights[idx]:.4f}\")\n",
        "\n",
        "    # PCA movie genre-only feature importance\n",
        "    print(\"PCA - Most important original features for Movie genre-only PC1:\")\n",
        "    genre_pc1_weights = np.abs(movie_genre_pca.components_[0])\n",
        "    top_genre_features_pca = np.argsort(genre_pc1_weights)[-10:]\n",
        "    for i, idx in enumerate(reversed(top_genre_features_pca)):\n",
        "        genre_name = genre_names[idx] if idx < len(genre_names) else f'Genre{idx}'\n",
        "        print(f\"     {i+1:2d}. Genre_{genre_name:<25} - weight={genre_pc1_weights[idx]:.4f}\")\n",
        "\n",
        "    # SVD movie complete feature importance\n",
        "    print(\"SVD - Most important original features for Movie complete dimension 1:\")\n",
        "    movie_svd_weights = np.abs(movie_svd.components_[0])\n",
        "    top_movie_features_svd = np.argsort(movie_svd_weights)[-10:]\n",
        "    for i, idx in enumerate(reversed(top_movie_features_svd)):\n",
        "        feature_name = movie_feature_names[idx] if idx < len(movie_feature_names) else f'Feature{idx}'\n",
        "        print(f\"     {i+1:2d}. {feature_name:<30} - weight={movie_svd_weights[idx]:.4f}\")\n",
        "\n",
        "    # SVD movie genre-only feature importance\n",
        "    print(\"SVD - Most important original features for Movie genre-only dimension 1:\")\n",
        "    genre_svd_weights = np.abs(movie_genre_svd.components_[0])\n",
        "    top_genre_features_svd = np.argsort(genre_svd_weights)[-10:]\n",
        "    for i, idx in enumerate(reversed(top_genre_features_svd)):\n",
        "        genre_name = genre_names[idx] if idx < len(genre_names) else f'Genre{idx}'\n",
        "        print(f\"     {i+1:2d}. Genre_{genre_name:<25} - weight={genre_svd_weights[idx]:.4f}\")\n",
        "\n",
        "    # PCA vs SVD difference analysis\n",
        "    print(\"PCA vs SVD Feature Difference Analysis\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Feature correlations\n",
        "    user_pca_svd_corr = np.corrcoef(user_features_pca[:, 0], user_features_svd[:, 0])[0, 1]\n",
        "    movie_pca_svd_corr = np.corrcoef(movie_features_pca[:, 0], movie_features_svd[:, 0])[0, 1]\n",
        "    genre_pca_svd_corr = np.corrcoef(movie_genre_features_pca[:, 0], movie_genre_features_svd[:, 0])[0, 1]\n",
        "    print(f\"User feature first dimension correlation (PCA vs SVD): {user_pca_svd_corr:.4f}\")\n",
        "    print(f\"Movie complete feature first dimension correlation (PCA vs SVD): {movie_pca_svd_corr:.4f}\")\n",
        "    print(f\"Movie genre-only feature first dimension correlation (PCA vs SVD): {genre_pca_svd_corr:.4f}\")\n",
        "\n",
        "    print(\"Detailed feature analysis completed!\")\n",
        "\n",
        "    return (rating_matrix, \n",
        "            user_features_pca, user_features_svd, \n",
        "            movie_features_pca, movie_features_svd,\n",
        "            movie_genre_features_pca, movie_genre_features_svd,\n",
        "            user_pca, movie_pca, user_svd, movie_svd,\n",
        "            movie_genre_pca, movie_genre_svd)\n",
        "\n",
        "# Execute feature engineering\n",
        "rating_matrix, user_features_pca, user_features_svd, movie_features_pca, movie_features_svd, movie_genre_features_pca, movie_genre_features_svd, user_pca, movie_pca, user_svd, movie_svd, movie_genre_pca, movie_genre_svd = create_features_with_detailed_analysis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Recommendation Algorithm Implementation - Complete Comparison Experiment\n",
        "print(\"=\" * 80)\n",
        "print(\"Recommendation Algorithm Implementation - Complete Comparison Experiment\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class UserBasedCF:\n",
        "    \"\"\"User-based Collaborative Filtering\"\"\"\n",
        "    def __init__(self, rating_matrix, user_features=None, use_user_features=False, feature_type='PCA', k_neighbors=20):\n",
        "        self.rating_matrix = rating_matrix\n",
        "        self.user_features = user_features\n",
        "        self.use_user_features = use_user_features\n",
        "        self.feature_type = feature_type\n",
        "        self.k_neighbors = k_neighbors\n",
        "        self.user_similarity = None\n",
        "        \n",
        "        feature_str = f'+{feature_type}_user_features' if use_user_features else ''\n",
        "        self.name = f'UserCF(rating_only{feature_str})'\n",
        "        print(f\"[SUCCESS] {self.name} initialized\")\n",
        "\n",
        "    def compute_similarities(self):\n",
        "        if self.use_user_features and self.user_features is not None:\n",
        "            rating_sim = cosine_similarity(self.rating_matrix)\n",
        "            feature_sim = cosine_similarity(self.user_features)\n",
        "            self.user_similarity = 0.6 * rating_sim + 0.4 * feature_sim\n",
        "        else:\n",
        "            self.user_similarity = cosine_similarity(self.rating_matrix)\n",
        "        np.fill_diagonal(self.user_similarity, 0)\n",
        "\n",
        "    def predict_rating(self, user_id, movie_id):\n",
        "        try:\n",
        "            user_idx = self.rating_matrix.index.get_loc(user_id)\n",
        "            movie_idx = self.rating_matrix.columns.get_loc(movie_id)\n",
        "        except KeyError:\n",
        "            return self.rating_matrix.mean().mean()\n",
        "        \n",
        "        movie_ratings = self.rating_matrix.iloc[:, movie_idx]\n",
        "        rated_mask = movie_ratings > 0\n",
        "        \n",
        "        if not rated_mask.any():\n",
        "            return self.rating_matrix.mean().mean()\n",
        "        \n",
        "        similarities = self.user_similarity[user_idx][rated_mask]\n",
        "        ratings = movie_ratings[rated_mask]\n",
        "        \n",
        "        if len(similarities) > self.k_neighbors:\n",
        "            top_k_idx = np.argsort(similarities)[-self.k_neighbors:]\n",
        "            similarities = similarities[top_k_idx]\n",
        "            ratings = ratings.iloc[top_k_idx]\n",
        "        \n",
        "        positive_mask = similarities > 0\n",
        "        if not positive_mask.any() or similarities[positive_mask].sum() == 0:\n",
        "            return self.rating_matrix.mean().mean()\n",
        "        \n",
        "        return np.clip(np.average(ratings[positive_mask], weights=similarities[positive_mask]), 1, 5)\n",
        "\n",
        "class ItemBasedCF:\n",
        "    \"\"\"Item-based Collaborative Filtering\"\"\"\n",
        "    def __init__(self, rating_matrix, movie_features=None, use_content_features=False, feature_type='PCA', feature_scope='complete', k_neighbors=20):\n",
        "        self.rating_matrix = rating_matrix\n",
        "        self.movie_features = movie_features\n",
        "        self.use_content_features = use_content_features\n",
        "        self.feature_type = feature_type\n",
        "        self.feature_scope = feature_scope\n",
        "        self.k_neighbors = k_neighbors\n",
        "        self.item_similarity = None\n",
        "        \n",
        "        if use_content_features:\n",
        "            feature_str = f'+{feature_type}_{feature_scope}_movie_features'\n",
        "        else:\n",
        "            feature_str = ''\n",
        "        self.name = f'ItemCF(rating_only{feature_str})'\n",
        "        print(f\"[SUCCESS] {self.name} initialized\")\n",
        "\n",
        "    def compute_similarities(self):\n",
        "        rating_item_sim = cosine_similarity(self.rating_matrix.T)\n",
        "        \n",
        "        if self.use_content_features and self.movie_features is not None:\n",
        "            content_sim = cosine_similarity(self.movie_features)\n",
        "            self.item_similarity = 0.6 * rating_item_sim + 0.4 * content_sim\n",
        "        else:\n",
        "            self.item_similarity = rating_item_sim\n",
        "        np.fill_diagonal(self.item_similarity, 0)\n",
        "\n",
        "    def predict_rating(self, user_id, movie_id):\n",
        "        try:\n",
        "            user_idx = self.rating_matrix.index.get_loc(user_id)\n",
        "            movie_idx = self.rating_matrix.columns.get_loc(movie_id)\n",
        "        except KeyError:\n",
        "            return self.rating_matrix.mean().mean()\n",
        "        \n",
        "        user_ratings = self.rating_matrix.iloc[user_idx, :]\n",
        "        rated_mask = user_ratings > 0\n",
        "        \n",
        "        if not rated_mask.any():\n",
        "            return self.rating_matrix.mean().mean()\n",
        "        \n",
        "        similarities = self.item_similarity[movie_idx][rated_mask]\n",
        "        ratings = user_ratings[rated_mask]\n",
        "        \n",
        "        if len(similarities) > self.k_neighbors:\n",
        "            top_k_idx = np.argsort(similarities)[-self.k_neighbors:]\n",
        "            similarities = similarities[top_k_idx]\n",
        "            ratings = ratings.iloc[top_k_idx]\n",
        "        \n",
        "        positive_mask = similarities > 0\n",
        "        if not positive_mask.any() or similarities[positive_mask].sum() == 0:\n",
        "            return self.rating_matrix.mean().mean()\n",
        "        \n",
        "        return np.clip(np.average(ratings[positive_mask], weights=similarities[positive_mask]), 1, 5)\n",
        "\n",
        "class HybridRecommender:\n",
        "    \"\"\"Hybrid Recommendation System\"\"\"\n",
        "    def __init__(self, user_cf_model, item_cf_model, user_weight=0.5, item_weight=0.5):\n",
        "        self.user_cf = user_cf_model\n",
        "        self.item_cf = item_cf_model\n",
        "        \n",
        "        # Weight normalization\n",
        "        total_weight = user_weight + item_weight\n",
        "        self.user_weight = user_weight / total_weight\n",
        "        self.item_weight = item_weight / total_weight\n",
        "        \n",
        "        user_type = self.user_cf.name\n",
        "        item_type = self.item_cf.name\n",
        "        self.name = f'HybridRec({user_type}+{item_type})'\n",
        "        print(f\"[SUCCESS] {self.name} initialized\")\n",
        "\n",
        "    def compute_similarities(self):\n",
        "        self.user_cf.compute_similarities()\n",
        "        self.item_cf.compute_similarities()\n",
        "\n",
        "    def predict_rating(self, user_id, movie_id):\n",
        "        user_pred = self.user_cf.predict_rating(user_id, movie_id)\n",
        "        item_pred = self.item_cf.predict_rating(user_id, movie_id)\n",
        "        return self.user_weight * user_pred + self.item_weight * item_pred\n",
        "\n",
        "print(\"Recommendation algorithm classes defined successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Complete Model Initialization and Training (Including Genre-only and SVD Options)\n",
        "print(\"=\" * 80)\n",
        "print(\"Complete Recommendation Model Initialization and Training (Including Genre-only and SVD Options)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Data splitting\n",
        "train_ratings, test_ratings = train_test_split(ratings, test_size=CONFIG['TEST_SIZE'], random_state=CONFIG['RANDOM_SEED'])\n",
        "train_matrix = train_ratings.pivot_table(index='user_id', columns='movie_id', values='rating', fill_value=0)\n",
        "print(f\"Data splitting completed:\")\n",
        "print(f\"   Training set: {train_matrix.shape} (users x movies)\")\n",
        "print(f\"   Test set: {len(test_ratings)} ratings\")\n",
        "print(f\"   Training set sparsity: {(1 - np.count_nonzero(train_matrix) / train_matrix.size) * 100:.2f}%\")\n",
        "\n",
        "# Adjust feature dimensions to match training matrix\n",
        "print(\"Adjusting feature dimensions to match training matrix...\")\n",
        "user_train_idx = [users[users['user_id'] == uid].index[0] for uid in train_matrix.index if uid in users['user_id'].values]\n",
        "train_user_features_pca = user_features_pca[user_train_idx]\n",
        "train_user_features_svd = user_features_svd[user_train_idx]\n",
        "\n",
        "movie_train_idx = [movies[movies['movie_id'] == mid].index[0] for mid in train_matrix.columns if mid in movies['movie_id'].values]\n",
        "train_movie_features_pca = movie_features_pca[movie_train_idx]\n",
        "train_movie_features_svd = movie_features_svd[movie_train_idx]\n",
        "train_movie_genre_features_pca = movie_genre_features_pca[movie_train_idx]\n",
        "train_movie_genre_features_svd = movie_genre_features_svd[movie_train_idx]\n",
        "\n",
        "print(f\"   Training user features: PCA{train_user_features_pca.shape}, SVD{train_user_features_svd.shape}\")\n",
        "print(f\"   Training movie complete features: PCA{train_movie_features_pca.shape}, SVD{train_movie_features_svd.shape}\")\n",
        "print(f\"   Training movie genre-only features: PCA{train_movie_genre_features_pca.shape}, SVD{train_movie_genre_features_svd.shape}\")\n",
        "\n",
        "# Validate dimension matching\n",
        "assert train_user_features_pca.shape[0] == train_matrix.shape[0], f\"User feature dimension mismatch\"\n",
        "assert train_movie_features_pca.shape[0] == train_matrix.shape[1], f\"Movie feature dimension mismatch\"\n",
        "print(\"Feature dimension validation passed\")\n",
        "\n",
        "# Display feature statistics\n",
        "print(f\"\\nFeature statistics:\")\n",
        "print(f\"   User PCA feature mean: {train_user_features_pca.mean():.4f}, std: {train_user_features_pca.std():.4f}\")\n",
        "print(f\"   User SVD feature mean: {train_user_features_svd.mean():.4f}, std: {train_user_features_svd.std():.4f}\")\n",
        "print(f\"   Movie complete PCA feature mean: {train_movie_features_pca.mean():.4f}, std: {train_movie_features_pca.std():.4f}\")\n",
        "print(f\"   Movie complete SVD feature mean: {train_movie_features_svd.mean():.4f}, std: {train_movie_features_svd.std():.4f}\")\n",
        "print(f\"   Movie genre-only PCA feature mean: {train_movie_genre_features_pca.mean():.4f}, std: {train_movie_genre_features_pca.std():.4f}\")\n",
        "print(f\"   Movie genre-only SVD feature mean: {train_movie_genre_features_svd.mean():.4f}, std: {train_movie_genre_features_svd.std():.4f}\")\n",
        "\n",
        "# Initialize all models\n",
        "print(\"Initializing all recommendation models...\")\n",
        "models = {}\n",
        "\n",
        "# Basic User CF models (3 types)\n",
        "print(\"\\n1. User-based Collaborative Filtering models:\")\n",
        "models['UserCF(rating_only)'] = UserBasedCF(train_matrix, use_user_features=False)\n",
        "models['UserCF(rating+PCA_user_features)'] = UserBasedCF(train_matrix, train_user_features_pca, use_user_features=True, feature_type='PCA')\n",
        "models['UserCF(rating+SVD_user_features)'] = UserBasedCF(train_matrix, train_user_features_svd, use_user_features=True, feature_type='SVD')\n",
        "\n",
        "# Basic Item CF models (5 types)\n",
        "print(\"\\n2. Item-based Collaborative Filtering models:\")\n",
        "models['ItemCF(rating_only)'] = ItemBasedCF(train_matrix, use_content_features=False)\n",
        "models['ItemCF(rating+PCA_complete_features)'] = ItemBasedCF(train_matrix, train_movie_features_pca, use_content_features=True, feature_type='PCA', feature_scope='complete')\n",
        "models['ItemCF(rating+SVD_complete_features)'] = ItemBasedCF(train_matrix, train_movie_features_svd, use_content_features=True, feature_type='SVD', feature_scope='complete')\n",
        "models['ItemCF(rating+PCA_genre_only)'] = ItemBasedCF(train_matrix, train_movie_genre_features_pca, use_content_features=True, feature_type='PCA', feature_scope='genre_only')\n",
        "models['ItemCF(rating+SVD_genre_only)'] = ItemBasedCF(train_matrix, train_movie_genre_features_svd, use_content_features=True, feature_type='SVD', feature_scope='genre_only')\n",
        "\n",
        "# Hybrid recommendation models (selected 6 representative combinations)\n",
        "print(\"\\n3. Hybrid Recommendation models:\")\n",
        "models['HybridRec(rating_only)'] = HybridRecommender(\n",
        "    models['UserCF(rating_only)'], \n",
        "    models['ItemCF(rating_only)'],\n",
        "    user_weight=0.5, item_weight=0.5\n",
        ")\n",
        "\n",
        "models['HybridRec(PCA_user+rating_only_item)'] = HybridRecommender(\n",
        "    models['UserCF(rating+PCA_user_features)'], \n",
        "    models['ItemCF(rating_only)'],\n",
        "    user_weight=0.5, item_weight=0.5\n",
        ")\n",
        "\n",
        "models['HybridRec(SVD_user+rating_only_item)'] = HybridRecommender(\n",
        "    models['UserCF(rating+SVD_user_features)'], \n",
        "    models['ItemCF(rating_only)'],\n",
        "    user_weight=0.5, item_weight=0.5\n",
        ")\n",
        "\n",
        "models['HybridRec(rating_only_user+PCA_genre_only)'] = HybridRecommender(\n",
        "    models['UserCF(rating_only)'], \n",
        "    models['ItemCF(rating+PCA_genre_only)'],\n",
        "    user_weight=0.5, item_weight=0.5\n",
        ")\n",
        "\n",
        "models['HybridRec(PCA_user+PCA_complete_features)'] = HybridRecommender(\n",
        "    models['UserCF(rating+PCA_user_features)'], \n",
        "    models['ItemCF(rating+PCA_complete_features)'],\n",
        "    user_weight=0.5, item_weight=0.5\n",
        ")\n",
        "\n",
        "models['HybridRec(SVD_user+SVD_genre_only)'] = HybridRecommender(\n",
        "    models['UserCF(rating+SVD_user_features)'], \n",
        "    models['ItemCF(rating+SVD_genre_only)'],\n",
        "    user_weight=0.5, item_weight=0.5\n",
        ")\n",
        "\n",
        "print(f\"\\nModel initialization completed! Total {len(models)} recommendation models:\")\n",
        "for i, name in enumerate(models.keys(), 1):\n",
        "    print(f\"   {i:2d}. {name}\")\n",
        "\n",
        "# Train all models and display detailed information\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting training for all models...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, (name, model) in enumerate(models.items(), 1):\n",
        "    print(f\"[{i}/{len(models)}] Training model: {name}\")\n",
        "    \n",
        "    # Display model configuration information\n",
        "    if hasattr(model, 'user_cf'):\n",
        "        # Hybrid model\n",
        "        print(f\"   └─ User CF: {model.user_cf.name}\")\n",
        "        print(f\"   └─ Item CF: {model.item_cf.name}\")\n",
        "        print(f\"   └─ Weights: user{model.user_weight:.1f} + item{model.item_weight:.1f}\")\n",
        "    else:\n",
        "        # Single model\n",
        "        if hasattr(model, 'use_user_features') and model.use_user_features:\n",
        "            print(f\"   └─ User feature dimensions: {model.user_features.shape}\")\n",
        "        if hasattr(model, 'use_content_features') and model.use_content_features:\n",
        "            print(f\"   └─ Movie feature dimensions: {model.movie_features.shape} ({model.feature_scope})\")\n",
        "    \n",
        "    # Train model\n",
        "    model.compute_similarities()\n",
        "    \n",
        "    # Display similarity matrix information\n",
        "    if hasattr(model, 'user_similarity') and model.user_similarity is not None:\n",
        "        print(f\"   └─ User similarity matrix: {model.user_similarity.shape} (non-zero elements: {np.count_nonzero(model.user_similarity)})\")\n",
        "    if hasattr(model, 'item_similarity') and model.item_similarity is not None:\n",
        "        print(f\"   └─ Item similarity matrix: {model.item_similarity.shape} (non-zero elements: {np.count_nonzero(model.item_similarity)})\")\n",
        "    \n",
        "    print(f\"   [SUCCESS] Completed\\n\")\n",
        "\n",
        "print(\"All models training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Model Evaluation and Results Comparison (Enhanced)\n",
        "def evaluate_models_enhanced(models, test_ratings, train_matrix):\n",
        "    \"\"\"Evaluate all models and generate detailed comparison report (Enhanced)\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Model Evaluation and Results Comparison (Enhanced)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Prepare test data\n",
        "    test_sample_size = min(500, len(test_ratings))\n",
        "    test_sample = test_ratings.sample(test_sample_size, random_state=CONFIG['RANDOM_SEED'])\n",
        "    print(f\"Test settings:\")\n",
        "    print(f\"   Test sample size: {test_sample_size} / {len(test_ratings)}\")\n",
        "    print(f\"   Training set coverage: users{len(train_matrix.index)}, movies{len(train_matrix.columns)}\")\n",
        "\n",
        "    # Statistics of test samples in training set coverage\n",
        "    test_users_in_train = test_sample['user_id'].isin(train_matrix.index).sum()\n",
        "    test_movies_in_train = test_sample['movie_id'].isin(train_matrix.columns).sum()\n",
        "    print(f\"   Test user coverage: {test_users_in_train}/{len(test_sample)} ({test_users_in_train/len(test_sample)*100:.1f}%)\")\n",
        "    print(f\"   Test movie coverage: {test_movies_in_train}/{len(test_sample)} ({test_movies_in_train/len(test_sample)*100:.1f}%)\")\n",
        "\n",
        "    results = []\n",
        "    detailed_results = {}\n",
        "    \n",
        "    for i, (name, model) in enumerate(models.items(), 1):\n",
        "        print(f\"\\n[{i}/{len(models)}] Evaluating model: {name}\")\n",
        "        \n",
        "        predictions = []\n",
        "        actual_ratings = []\n",
        "        prediction_times = []\n",
        "        \n",
        "        # Prediction process statistics\n",
        "        valid_predictions = 0\n",
        "        cold_start_users = 0\n",
        "        cold_start_movies = 0\n",
        "        \n",
        "        for _, row in test_sample.iterrows():\n",
        "            user_id, movie_id, actual_rating = row['user_id'], row['movie_id'], row['rating']\n",
        "            \n",
        "            # Cold start detection\n",
        "            if user_id not in train_matrix.index:\n",
        "                cold_start_users += 1\n",
        "                continue\n",
        "            if movie_id not in train_matrix.columns:\n",
        "                cold_start_movies += 1\n",
        "                continue\n",
        "            \n",
        "            # Predict rating\n",
        "            import time\n",
        "            start_time = time.time()\n",
        "            pred_rating = model.predict_rating(user_id, movie_id)\n",
        "            prediction_time = time.time() - start_time\n",
        "            \n",
        "            predictions.append(pred_rating)\n",
        "            actual_ratings.append(actual_rating)\n",
        "            prediction_times.append(prediction_time)\n",
        "            valid_predictions += 1\n",
        "        \n",
        "        if len(predictions) > 0:\n",
        "            # Calculate evaluation metrics\n",
        "            rmse = np.sqrt(mean_squared_error(actual_ratings, predictions))\n",
        "            mae = mean_absolute_error(actual_ratings, predictions)\n",
        "            avg_pred_time = np.mean(prediction_times) * 1000  # Convert to milliseconds\n",
        "            \n",
        "            # Prediction distribution statistics\n",
        "            pred_mean = np.mean(predictions)\n",
        "            pred_std = np.std(predictions)\n",
        "            actual_mean = np.mean(actual_ratings)\n",
        "            \n",
        "            results.append({\n",
        "                'Model': name,\n",
        "                'RMSE': rmse,\n",
        "                'MAE': mae,\n",
        "                'Test_Samples': len(predictions),\n",
        "                'Avg_Pred_Time_ms': avg_pred_time\n",
        "            })\n",
        "            \n",
        "            detailed_results[name] = {\n",
        "                'predictions': predictions,\n",
        "                'actual_ratings': actual_ratings,\n",
        "                'cold_start_users': cold_start_users,\n",
        "                'cold_start_movies': cold_start_movies\n",
        "            }\n",
        "            \n",
        "            print(f\"   RMSE: {rmse:.4f}, MAE: {mae:.4f} (samples: {valid_predictions}, time: {avg_pred_time:.2f}ms)\")\n",
        "        else:\n",
        "            print(f\"   [WARNING] Model cannot be evaluated (valid test samples: {valid_predictions}/{len(test_sample)})\")\n",
        "    \n",
        "    # Generate detailed results comparison table\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df = results_df.sort_values('RMSE')\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"Model Performance Leaderboard (sorted by RMSE)\")\n",
        "    print(\"=\"*100)\n",
        "    print(results_df.to_string(index=False, float_format='%.4f'))\n",
        "    \n",
        "    # Detailed experimental results analysis\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Detailed Experimental Results Analysis\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    best_model = results_df.iloc[0]\n",
        "    worst_model = results_df.iloc[-1]\n",
        "    print(f\"Best model: {best_model['Model']} (RMSE: {best_model['RMSE']:.4f})\")\n",
        "    print(f\"Worst model: {worst_model['Model']} (RMSE: {worst_model['RMSE']:.4f})\")\n",
        "    improvement = ((worst_model['RMSE'] - best_model['RMSE']) / worst_model['RMSE']) * 100\n",
        "    print(f\"Performance gap: {improvement:.2f}%\")\n",
        "\n",
        "    # Feature value analysis\n",
        "    print(f\"\\nFeature Value Analysis:\")\n",
        "    \n",
        "    # 1. User feature value (PCA vs SVD)\n",
        "    user_rating_only = results_df[results_df['Model'] == 'UserCF(rating_only)']['RMSE'].iloc[0] if 'UserCF(rating_only)' in results_df['Model'].values else None\n",
        "    user_pca = results_df[results_df['Model'] == 'UserCF(rating+PCA_user_features)']['RMSE'].iloc[0] if 'UserCF(rating+PCA_user_features)' in results_df['Model'].values else None\n",
        "    user_svd = results_df[results_df['Model'] == 'UserCF(rating+SVD_user_features)']['RMSE'].iloc[0] if 'UserCF(rating+SVD_user_features)' in results_df['Model'].values else None\n",
        "    \n",
        "    if user_rating_only and user_pca:\n",
        "        pca_improvement = ((user_rating_only - user_pca) / user_rating_only) * 100\n",
        "        print(f\"   User PCA features: {'Effective' if pca_improvement > 0 else 'Ineffective'} (RMSE improvement {pca_improvement:.2f}%)\")\n",
        "    \n",
        "    if user_rating_only and user_svd:\n",
        "        svd_improvement = ((user_rating_only - user_svd) / user_rating_only) * 100\n",
        "        print(f\"   User SVD features: {'Effective' if svd_improvement > 0 else 'Ineffective'} (RMSE improvement {svd_improvement:.2f}%)\")\n",
        "    \n",
        "    # 2. Movie feature value (complete vs genre-only)\n",
        "    item_rating_only = results_df[results_df['Model'] == 'ItemCF(rating_only)']['RMSE'].iloc[0] if 'ItemCF(rating_only)' in results_df['Model'].values else None\n",
        "    item_pca_full = results_df[results_df['Model'] == 'ItemCF(rating+PCA_complete_features)']['RMSE'].iloc[0] if 'ItemCF(rating+PCA_complete_features)' in results_df['Model'].values else None\n",
        "    item_pca_genre = results_df[results_df['Model'] == 'ItemCF(rating+PCA_genre_only)']['RMSE'].iloc[0] if 'ItemCF(rating+PCA_genre_only)' in results_df['Model'].values else None\n",
        "    \n",
        "    if item_rating_only and item_pca_full:\n",
        "        full_improvement = ((item_rating_only - item_pca_full) / item_rating_only) * 100\n",
        "        print(f\"   Movie complete features: {'Effective' if full_improvement > 0 else 'Ineffective'} (RMSE improvement {full_improvement:.2f}%)\")\n",
        "    \n",
        "    if item_rating_only and item_pca_genre:\n",
        "        genre_improvement = ((item_rating_only - item_pca_genre) / item_rating_only) * 100\n",
        "        print(f\"   Movie genre-only features: {'Effective' if genre_improvement > 0 else 'Ineffective'} (RMSE improvement {genre_improvement:.2f}%)\")\n",
        "    \n",
        "    # 3. PCA vs SVD comparison\n",
        "    pca_models = results_df[results_df['Model'].str.contains('PCA')]\n",
        "    svd_models = results_df[results_df['Model'].str.contains('SVD')]\n",
        "    \n",
        "    if len(pca_models) > 0 and len(svd_models) > 0:\n",
        "        pca_avg_rmse = pca_models['RMSE'].mean()\n",
        "        svd_avg_rmse = svd_models['RMSE'].mean()\n",
        "        \n",
        "        if pca_avg_rmse < svd_avg_rmse:\n",
        "            improvement = ((svd_avg_rmse - pca_avg_rmse) / svd_avg_rmse) * 100\n",
        "            print(f\"   PCA outperforms SVD: average RMSE improvement {improvement:.2f}%\")\n",
        "        else:\n",
        "            improvement = ((pca_avg_rmse - svd_avg_rmse) / pca_avg_rmse) * 100\n",
        "            print(f\"   SVD outperforms PCA: average RMSE improvement {improvement:.2f}%\")\n",
        "    \n",
        "    # Save detailed results\n",
        "    results_file = os.path.join(CONFIG['OUTPUT_PATH'], 'result', 'comprehensive_evaluation_results.json')\n",
        "    results_df.to_json(results_file, orient='records', indent=2, force_ascii=False)\n",
        "    print(f\"\\nComprehensive evaluation results saved to: {results_file}\")\n",
        "    \n",
        "    return results_df, detailed_results\n",
        "\n",
        "# Execute comprehensive model evaluation\n",
        "evaluation_results, detailed_results = evaluate_models_enhanced(models, test_ratings, train_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Project Summary\n",
        "print(\"=\" * 80)\n",
        "print(\"MovieLens Recommendation System Project Summary\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "summary = {\n",
        "    'project_name': 'MovieLens 100k Recommendation System Comprehensive Comparison Experiment',\n",
        "    'experiment_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'dataset': {\n",
        "        'rating_count': len(ratings),\n",
        "        'user_count': ratings['user_id'].nunique(),\n",
        "        'movie_count': ratings['movie_id'].nunique(),\n",
        "        'sparsity': f\"{(1 - len(ratings) / (ratings['user_id'].nunique() * ratings['movie_id'].nunique())) * 100:.2f}%\"\n",
        "    },\n",
        "    'feature_engineering': {\n",
        "        'user_features': ['age', 'age_group', 'gender', 'occupation', 'region'],\n",
        "        'movie_complete_features': ['genres(19D)', 'year', 'decade'],\n",
        "        'movie_genre_only_features': ['genres(19D)'],\n",
        "        'dimensionality_reduction_methods': ['PCA', 'SVD'],\n",
        "        'PCA_user_feature_dimensions': user_features_pca.shape[1],\n",
        "        'SVD_user_feature_dimensions': user_features_svd.shape[1],\n",
        "        'PCA_movie_complete_feature_dimensions': movie_features_pca.shape[1],\n",
        "        'SVD_movie_complete_feature_dimensions': movie_features_svd.shape[1],\n",
        "        'PCA_movie_genre_only_feature_dimensions': movie_genre_features_pca.shape[1],\n",
        "        'SVD_movie_genre_only_feature_dimensions': movie_genre_features_svd.shape[1]\n",
        "    },\n",
        "    'experimental_design': {\n",
        "        'algorithm_types': ['User-based Collaborative Filtering', 'Item-based Collaborative Filtering', 'Hybrid Recommendation'],\n",
        "        'feature_combinations': ['rating_only', 'rating+user_features', 'rating+movie_complete_features', 'rating+movie_genre_only_features'],\n",
        "        'dimensionality_reduction_comparison': ['PCA vs SVD'],\n",
        "        'movie_feature_comparison': ['complete_features vs genre_only_features'],\n",
        "        'total_model_count': len(models)\n",
        "    },\n",
        "    'evaluation_metrics': ['RMSE', 'MAE', 'prediction_time'],\n",
        "    'best_model': {\n",
        "        'name': evaluation_results.iloc[0]['Model'],\n",
        "        'RMSE': f\"{evaluation_results.iloc[0]['RMSE']:.4f}\",\n",
        "        'MAE': f\"{evaluation_results.iloc[0]['MAE']:.4f}\"\n",
        "    },\n",
        "    'output_files': {\n",
        "        'result_directory': CONFIG['OUTPUT_PATH'],\n",
        "        'comprehensive_evaluation_results': 'result/comprehensive_evaluation_results.json'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print summary\n",
        "for key, value in summary.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"{key.replace('_', ' ').title()}:\")\n",
        "        for sub_key, sub_value in value.items():\n",
        "            print(f\"   - {sub_key.replace('_', ' ')}: {sub_value}\")\n",
        "    elif isinstance(value, list):\n",
        "        print(f\"{key.replace('_', ' ').title()}: {', '.join(map(str, value))}\")\n",
        "    else:\n",
        "        print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
        "    print()\n",
        "\n",
        "print(\"Experiment completed!\")\n",
        "print(\"\\nKey Findings:\")\n",
        "print(f\"   1. Compared {len(models)} different recommendation algorithm configurations\")\n",
        "print(\"   2. Analyzed the value of user features and movie features\")\n",
        "print(\"   3. Compared the effects of PCA and SVD dimensionality reduction methods\")\n",
        "print(\"   4. Contrasted movie complete features vs genre-only features effects\")\n",
        "print(\"   5. Provided detailed feature importance analysis and algorithm performance comparison\")\n",
        "\n",
        "# Save project summary\n",
        "summary_file = os.path.join(CONFIG['OUTPUT_PATH'], 'comprehensive_project_summary.json')\n",
        "with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Project summary saved to: {summary_file}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
